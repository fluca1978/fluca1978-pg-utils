#+TITLE:     PostgreSQL 9.6
#+AUTHOR:    Luca Ferrari
#+EMAIL:     fluca1978@gmail.com
#+DATE:      <2017-08-25 ven>
#+LANGUAGE:  it

#+OPTIONS:   H:3 num:t toc:t \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+INFOJS_OPT: view:nil toc:nil ltoc:t mouse:underline buttons:0 path:http://orgmode.org/org-info.js
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+LINK_UP:
#+LINK_HOME:

#+startup: beamer
#+LaTeX_CLASS: beamer
#+latex_header: \mode<beamer>{\usetheme{Madrid}}
#+latex_header: \AtBeginSection[]{\begin{frame}<beamer>\frametitle{Outline}\tableofcontents[currentsection]\end{frame}}

#+BEAMER_HEADER: \subtitle{il database Open Source piu' avanzato del pianeta}
#+BEAMER_HEADER: \institute[ITPUG]{Italian PostgreSQL Users' Group (ITPUG)\\\url{http://www.itpug.org}}
#+BEAMER_HEADER: \institute[fluca1978]{fluca1978\\\url{https://fluca1978.github.io}}
#+BEAMER_HEADER: \titlegraphic{\includegraphics[height=3cm]{./images/logo.png}}




* Introduzione
** Il progetto PostgreSQL
*** Cos'è?
   PostgreSQL è un *Object Relational Database Management System* (ORDBMS).

**** O-RDBMS                                                   :B_definition:
   *Object* non è da intendersi relativamente al paradigma /OOP/ quanto al fatto
   che un utente /puo' estendere il database con i propri "oggetti"/.
**** End of block                                           :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:

Ad esempio, PostgreSQL non supporta i /query-hints/ tanto famosi in altri sistemi
commerciali: per gli sviluppatori questa funzionalità non ha senso e non è mai stata
(e mai verrà) implementata.

#+begin_quote
Approccio simile a quello di OpenBSD!
#+end_quote

   PostgreSQL è il naturale discendente di *Ingres* (dopo, /post/, gres), un database
   accademico/sperimentale inventato dal prof. Michael Stonebreaker e commercializzato
   indicativamente nello stesso spazio temporale di Oracle (1989 circa).

   Tutto inizia alla Berkely University of California.

*** Quand'è?

   | Nome          | Anno di produzione | Note                             |
   |---------------+--------------------+----------------------------------|
   | POSTGRES      |               1989 | successore di Ingres             |
   | POSTGRES95    |               1994 | viene aggiunto un interprete SQL |
   | Postgres 1    |               1995 |                                  |
   | PostgreSQL 6  |               1997 |                                  |
   | PostgreSQL 7  |               2000 | foreign keys, join e no-crash    |
   | PostgreSQL 8  |               2005 | port Windows nativo              |
   | PostgreSQL 9  |               2010 | Replication                      |
   | PostgreSQL 10 |               2017 | ...                              |

   #+begin_quotation
The copyright of Postgres 1.0 has been loosened to be freely modifiable
and modifiable for any purpose.  Please read the COPYRIGHT file.
Thanks to Professor Michael Stonebraker for making this possible.
--- Release 1.0
#+end_quotation

*** Di chi è?
   PostgreSQL non è guidato da nessun vendor e di conseguenza _non ha una
   lista di clienti da soddisfare_. Questo significa che
   una feature sarà implementata in PostgreSQL solo se ha senso dal punto di
   vista /tecnico/ e /scientifico/.

**** Approccio culturale                                       :B_definition:
    PostgreSQL is a *non-commercial, all volunteer, free software project*,
    and as such *there is no formal list of feature requirements*
    required for development.
    We really do follow the mantra of
    letting developers scratch their own itches.
**** End of block                                           :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:
Ad esempio, PostgreSQL non supporta i /query-hints/ tanto famosi in altri sistemi
commerciali: per gli sviluppatori questa funzionalità non ha senso e non è mai stata
(e mai verrà) implementata.

#+begin_quote
Approccio simile a quello di OpenBSD!
#+end_quote

*** Per chi è?
Licenza *BSD* (anche per il logo):


#+begin_src
PostgreSQL Database Management System
(formerly known as Postgres, then as Postgres95)

Portions Copyright (c) 1996-2017, PostgreSQL Global Development Group

Portions Copyright (c) 1994, The Regents of the University of California

Permission to use, copy, modify, and distribute this software and its
documentation for any purpose, without fee, and without a written agreement
is hereby granted, provided that the above copyright notice and this
paragraph and the following two paragraphs appear in all copies.
#+end_src

*** Quanto costa?
   Il progetto è /Open Source/ ed è /Free/.

   Esistono diverse varianti commerciali che si differenziano dalla versione
   /mainstream/ per funzionalità (es. replica multi-master, query multi-nodo, ecc.)
   e per un /costo/ che dipende direttamente dal vendor.

   Molti degli sviluppatori della versione mainstream sono in realtà _anche_ sviluppatori
   di un qualche vendor.

*** Qual'era?
   In PostgreSQL i numeri di versione */erano/* a tre cifre separati da punto:
   - */release brand/* (es. 7, no-crash, 8 MS Windows portability, 9 Replication)
   - */year release/*  (da quanti anni si ha questo brand)
   - */minor release/* (rilasciata circa ogni quattro mesi o in presenza di gravi
     problemi di sicurezza o consistenza)

**** Major version vs Minor Version                               :B_theorem:
    - *9.5*.1 # major version 9.5, minor version 1
      - 9.5.1 compatibile con 9.5.2, 9.5.3, ...
    - *9.6*.2 # major version 9.6, minor version 2
      - incompatibile con 9.5.x!

**** End of block                                           :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:
   Le prime due cifre rappresentavano una *major version* e quindi erano segnale di
   possibile incompatibilità.

*** Qual'é?
   Dalla versione 10 la numerazione è diventata a due sole cifre.

   La cifra prima del punto rappresenta la /major version/.

   *Questo rappresenta una incompatibilità semantica con il passato*: gli script
   che facevano affidamento alla versione devono modificare la propria logica!

   L'unico metodo affidabile è quello di considerare che ogni cifra viene
   usata con un formato ~printf(2)~ pari a ~%02d~ e che il numero
   dell'anno da ora in avanti è sempre zero.

   | Versione | Major | Minor | Internal |
   |----------+-------+-------+----------|
   |    9.5.1 |   9.5 |     1 |   090501 |
   |    9.6.4 |   9.6 |     4 |   090604 |
   |----------+-------+-------+----------|
   |     10.0 |    10 |     0 |   100000 |
   |     10.1 |    10 |     1 |   100001 |

*** Quanto dura?
   Ogni /major release/ di PostgreSQL viene manutenuta per *5 anni* dalla data di primo rilascio.
   Una volta che una release raggiunge la *End Of Life* nessun pacchetto binario sarà piu' rilasciato
   ma potrebbe essere aggiornato (in retrocompatibilità) l'albero dei sorgenti (a discrezione degli
   sviluppatori e senza alcuna garanzia).

   Ecco un esempio delle prossime "scadenze":

| Version | First release date  | 	EOL date       |
|---------+---------------------+------------------|
|     9.6 | 	September 2016 	 | September 2021   |
|     9.5 | 	January 2016 	   | January 2021     |
|     9.4 | 	December 2014 	  | December 2019    |
|     9.3 | 	September 2013 	 | September 2018   |
|     9.2 | 	September 2012 	 | *September 2017* |

*** Quanto è?
   E' difficile /spaventare/ una istanza PostgreSQL!

| Dato                        | Limite massimo                       |
|-----------------------------+--------------------------------------|
| Maximum Database Size	     | Unlimited                            |
| Maximum Table Size	        | 32 TB                                |
| Maximum Row Size	          | 1.6 TB                               |
| Maximum Field Size	        | 1 GB                                 |
| Maximum Rows per Table	    | Unlimited                            |
| Maximum Columns per Table	 | 250 - 1600 depending on column types |
| Maximum Indexes per Table	 | Unlimited                            |

*** Chi lo usa?

   Alcuni esempi:

#+ATTR_LATEX: :width 0.2\textwidth
 [[./images/debian.png]]
 [[./images/redhat.png]]
[[./images/cisco.png]]
[[./images/skype.png]]

*** Chi lo sviluppa?
   *Chiunque*, anche tu! Non esiste un /benevolent dictator/!

   Tre livelli principali di sviluppatori:
   1. *core team*: 5 membri storici che si occupano di gestire il ciclo di rilascio e tutte le questioni
      "spinose" (mancanza di consenso, disciplina, ecc)
      - Peter Eisentraut
      - Magnus Hagander
      - Tom Lane
      - Bruce Momjian
      - Dave Page
   2. *major contributors*: /sviluppatori fidati/ (commit access) che lavorano abitualmente alle funzionalità del
      progetto
   3. *contributor*: chiunque fornisca una patch, una proposta, una traduzione, ...


   - *hacker emeritus*: chi ha lavorato in passato al progetto con particolare successo
      (Josh Berkus, Marc G. Fournier, Thomas G. Lockhart, Vadim B. Mikheev, Jan Wieck)

*** Come si sviluppa?
   Si utilizza ~git~ (migrato da CVS intorno al 2009).

   #+begin_src sh
% git clone git://git.postgresql.org/git/postgresql.git

Cloning into 'postgresql'...
...
% du -hs postgresql
356M    postgresql
% git rev-list --all --count
59672
   #+end_src

   - Linguaggio di programmazione principale: ~C~, stile BSD (~style(9)~).
   - Strumenti di sviluppo ben noti: ~gcc~, ~gmake~, ~autoconf~, ecc.
   - Strumenti (anche Perl) ad-hoc per mantenere il codice: ~pgindent~, ~git_changelog~,
     ~make_ctags~, ecc.

*** Da quanto si sviluppa?
   Da molto tempo (oltre 30 anni), ma non si torna prima della versione 1.01 di *Postgres95*,
   ramo di sviluppo 6 del Postgres "attuale":

   #+begin_src sh
% git log `git rev-list --max-parents=0 HEAD`

commit d31084e9d1118b25fd16580d9d8c2924b5740dff
Author: Marc G. Fournier <scrappy@hub.org>
Date:   Tue Jul 9 06:22:35 1996 +0000

    Postgres95 1.01 Distribution - Virgin Sources
   #+end_src

** Concetti Generali
*** Terminologia
- Ogni istanza di PostgreSQL gestisce un *cluster*.

- Un cluster è formato da uno o piu' *database*, ogni database può essere a sua volta
  scomposto in uno o piu' *schema* (/namespace logico/),
  che a sua volta può contenere uno o piu' *oggetti* (/tabelle, trigger, indici, funzioni/, ...).
  Ogni *database* è totalmente isolato dall'altro.

- Ogni oggetto può appartenere ad uno e un solo *tablespace* (/spazio fisico/).

- Il *cluster* mantiene anche le informazioni relative agli utenti e ai permessi.
  Gli utenti vengono chiamati *ruoli* e rappresentano sia singole utenze che gruppi
  (quindi un ruolo può contenere altri ruoli).

In linea con la filosofia Unix, PostgreSQL vuole svolgere un compito solo nel miglior modo possibile: gestire
i dati. E' compito del DBA documentarsi e aggiungere le estensioni necessarie a seconda del caso d'uso (es. pooling).

*** Cluster di Database
Un singolo cluster quindi può gestire un albero di oggetti a granularità molto specifica:

  - /database 1/
    - /schema ~public~/ (default)
    - /schema 1/
      - /tabelle, trigger, indici/ -> /tablespace disco SSD/
      - /tabelle, trigger, indici/ -> /tablespace disco lento/
    - /schema 2/
      - /tabelle, trigger, indici/ -> /tablespace disco SSD/
      - /tabelle, trigger, indici/ -> /tablespace disco lento/
  - /database 2/
    - /schema ~public~/ (default)
    - /schema 1/
      - /tabelle, trigger, indici/ -> /tablespace disco SSD/
      - /tabelle, trigger, indici/ -> /tablespace disco lento/
    - /schema 2/
      - /tabelle, trigger, indici/ -> /tablespace disco SSD/
      - /tabelle, trigger, indici/ -> /tablespace disco lento/

*** Analogia tra Cluster e OS
L'isolamento e la gestione di un cluster ricorda molto quella di un sistema operativo:

| PostgreSQL                                | Unix                             |
|-------------------------------------------+----------------------------------|
| cluster                                   | OS                               |
| ruolo                                     | utente                           |
| tablespace                                | mount point                      |
|-------------------------------------------+----------------------------------|
| database                                  | home directory                   |
| schema                                    | sottodirectory  (es ~$HOME/bin~) |
| oggetto (tabella, trigger, funzione, ...) | file, script                     |

*** Schema a Processi: Connessioni
PostgreSQL utilizza uno *schema a processi*: /ogni connessione viene gestita da un sottoprocesso creato ad-hoc/.


*** Processi vs Thread
Ci sono svariate ragioni per preferire uno schema a processi rispetto ad uno a thread: *isolamento* e *portabilità*
sono le principali.

*** End of block                                               :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:
Il processo principale è denominato *postmaster*; ogni volta che questo riceve una richiesta di connessione si effettua una /fork/
di un processo *postgres* (denominato anche *backend*) delegato a gestire la connessione.

*** Connessioni
    Una connessione può essere *TCP/IP* oppure su *socket locale*.
*** Schema a Processi: IPC
   Siccome ogni processo è /fisicamente/ isolato, ma piu' connessioni possono dover condividere i dati, PostgreSQL
   utilizza un'area *shared memory* ove mantiene i dati. Tale zona di memoria è visibile a tutti i processi *postgres*.



   La shared memory viene organizzata in */pagine dati/* che rappresentano la copia in memoria dei dati persistenti su disco.
   Vi sono una serie di processi di utilità che si occupano di scaricare/caricare i dati dalla /shared memory/ e dal disco.
*** File System
   PostgreSQL si appoggia al *filesystem* per lo stoccaggio dei dati in maniera persistenza.

   Questo offre diversi vantaggi, fra i quali la possibilità di un tuning molto raffinato
   circa le opzioni di funzionamento del filesystem (replica, journaling, ecc.).

   Dall'altra parte, il filesystem deve essere *affidabile*, pena il rischio di perdita dati.
* Installazione
** Installazione
*** Tipologie di installazione
   E' possibile installare PostgreSQL:
   - mediante installer ufficiale
   - mediante pacchetti binari della propria installazione
   - compilando l'albero dei sorgenti

*** Macchina Virtuale                                          :B_definition:
   Tutte le prove qui mostrate sono state effettuate su una macchina virtuale con
   quattro dischi da 2GB utilizzati come spazio dati:
   #+begin_src sh
   $ uname -a
   FreeBSD olivia 11.1-RELEASE FreeBSD 11.1-RELEASE
   $ mount
   /dev/ada1p1 on /mnt/data1 (ufs, local, soft-updates)
   /dev/ada2p1 on /mnt/data2 (ufs, local, soft-updates)
   /dev/ada3p1 on /mnt/data3 (ufs, local, soft-updates)
   /dev/ada4p1 on /mnt/data4 (ufs, local, soft-updates)
   #+end_src
*** End of block                                               :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:

*** Installazione
Compilazione dai ports:
#+begin_src sh
# cd /usr/ports/databases/postgresql96-server
# make PREFIX=/opt/postgresql-9.6 BATCH=yes install clean
#+end_src

oppure il pacchetto binario:

#+begin_src sh
# pkg install postgresql96-server-9.6.5_1
#+end_src

In FreeBSD il database viene gestito dall'utente di sistema ~postgres~:

#+begin_src sh
# id postgres
uid=770(postgres) gid=770(postgres) groups=770(postgres)
#+end_src

altri sistemi operativi creano utenti simili (~psql~, ~pgsql~, ecc.).

*** Configurazione avvio servizio (OS)
I parametri di configurazione dipendono ovviamente dal sistema operativo, ad
esempio su FreeBSD le variabili di ~rc.conf~ sono visibili da
~/usr/local/etc/rc.d/postgresql~:

#+begin_src sh
#  postgresql_enable="YES"
#  postgresql_data="/var/db/postgres/data96"
#  postgresql_flags="-w -s -m fast"
#  postgresql_initdb_flags="--encoding=utf-8 --lc-collate=C"
#  postgresql_class="default"
#  postgresql_profiles=""
#+end_src

** Layout su disco
*** PGDATA
PostgreSQL utilizza il filesystem del sistema operativo per salvare i dati in modo
persistente.

In particolare una directory specifica, denominata *PGDATA*, viene usata per contenere
tutti gli oggetti PostgreSQL. Tale directory deve essere inizializzata opportunamente
(creazione struttura directory, impostazione dei permessi, ecc.)
tramite il programma ~initdb~.

*** Importanza di PGDATA
   Un cluster può servire *una sola PGDATA* alla volta.
   La directory PGDATA deve essere protetta opportunamente da accessi involontari
   di altri utenti del sistema.
*** End of block                                               :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:

*** initdb
Creazione di una directory per la memorizzazione del database (alcuni
sistemi operativi lo fanno automaticamente al momento dell'installazione
binaria):

#+begin_src sh
# mkdir /mnt/data1/pgdata
  && chown postgres:postgres /mnt/data1/pgdata
$ initdb --data-checksum --encoding="UTF-8"
         --pwprompt
         -D /mnt/data1/pgdata/
#+end_src

~initdb~ deve essere eseguito da un utente non privilegiato, le opzioni indicano:
- ~--data-checksum~: abilita il controllo sulle pagine dati del database;
- ~--encoding~: default encoding di ogni database se non sovrascritto;
- ~--pwprompt~: richiede la password del superutente di PostgreSQL (comodo per non impostarlo dopo);
- *~-D~*: l'opzione principale, indica *dove si troveranno i dati*.

*** $PGDATA
La directory ~$PGDATA~ contiene diversi file e directory, in particolare:
- ~PG_VERSION~: file di testo con la versione che serve il cluster;
- *~postgresql.conf~*: configurazione principale del cluster;
- *~pg_hba.conf~*: file di accesso al database;
- *~base~*: directory sotto la quale si troveranno tutti i database;
- *~global~*: directory che contiene dati inter-database (es. cataloghi di sistema);
- ~pg_stat~ e ~pg_stat_tmp~: informazioni per le statistiche di sistema;
- *~pg_tblscp~*: link ai vari tablespace (oggetti fuori da ~base~);
- *~pg_xlog~* e ~pg_clog~: rispettivamente WAL e commit log.

Per altre informazioni vedere [[https://www.postgresql.org/docs/9.6/static/storage-file-layout.html][Storage File System Layout]].
*** File fisici su disco
Ogni /oggetto/ con dei dati (es. tabella) viene memorizzato su disco in un file
con nome pari al suo /Object IDentifier/ (~OID~) numerico. Questo ha il vantaggio di:
- essere indipendente dal nome /logico/ e dalla relativa codifica e charset;
- essere /univoco/ indipendentemente da quante volte si cambia nome all'oggetto nel database.

Ogni file dato viene /spezzato/ in chunk da ~1 GB~ massimo, quindi dello stesso oggetto si possono
avere piu' file nominati con ~oid~, ~oid.1~, ~oid.2~, ecc.

Solitamente i file crescono in dimensione di ~8 kB~ alla volta (ossia della dimensione di una pagina dati).

*** oid2name
L'utility ~oid2name~ (modulo /contrib/) consente di esplorare
la struttura dati su disco.
#+begin_src sh
% oid2name -H localhost -U postgres
Password:
All databases:
    Oid  Database Name  Tablespace
----------------------------------
  12758       postgres  pg_default
  12757      template0  pg_default
      1      template1  pg_default
#+end_src

Gli /oid/ visualizzati in questo caso corrispondono al nome *fisico su disco*
dei database:

#+begin_src sh
% sudo ls /mnt/data1/pgdata/base
1       12757   12758
#+end_src

*** oid2name (2)
 Esploriamo il database ~template1~ su disco e cerchiamo di capire
 cosa contiene:

#+begin_src sh
% sudo stat /mnt/data1/pgdata/base/1/12618
107 65870 -rw------- 1 postgres postgres 145910 8192
#+end_src

A cosa corrisponde l'oggetto file ~12618~?

#+begin_src sh
% oid2name -H localhost -U postgres -d template1 -o 12618
Password:
From database "template1":
  Filenode  Table Name
----------------------
     12618  sql_sizing
#+end_src

*ATTENZIONE: si deve specificare a quale database si fa riferimento, poiché
gli stessi oid possono essere riciclati in database differenti*

*** oid2name (3)
E se si vuole trovare una tabella dato il suo nome?

 #+begin_src sh
% oid2name -H localhost -U postgres -d template1 -t sql_sizing
Password:
From database "template1":
  Filenode  Table Name
----------------------
     12618  sql_sizing
 #+end_src

~oid2name~ va ad interrogare il catalogo di sistema per trovare le informazioni
necessarie.

** Connessioni
*** Connessione al servizio
Il file ~pg_hba.conf~ contiene le informazioni su quali metodi di autenticazione,
quali utenti, quali host remoti e quali database sono accessibili per la connessione.
Si può editare questo file prima di avviare il servizio (se si è impostata una password
per ~postgres~ superuser) o anche in seguito.

#+begin_src sh
# tipo  database   utente   da dove       metodo
local   all        all                    trust
host    all        all      127.0.0.1/32    md5
#+end_src

*** pg_hba.conf vs sudoers
    Il file ~pg_hba.conf~ è simile al file ~sudoers~, e come tale
    va gestito scrupolosamente.
    La parola ~all~ indica tutti gli utenti/database (a seconda di dove è messa).
    *Il metodo ~trust~ non richiede autenticazione e non va usato!*
*** End of block                                               :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:

*** Avvio del servizio
Una volta che i primi pezzi sono al loro posto, è possibile avviare il servizio:

#+begin_src sh
# service postgresql start
#+end_src

e se tutto va a buon fine...
#+begin_src sh
# psql -h localhost -U postgres -l
Password for user postgres:
   Name    |  Owner   | Encoding |
-----------+----------+----------+
 postgres  | postgres | UTF8     |
 template0 | postgres | UTF8     |
 template1 | postgres | UTF8     |
(3 rows)
#+end_src

*** Database template
Quando viene inizializzata ~PGDATA~ il sistema crea due database chaimati /template/:
- ~template0~: la copia principale del template;
- *~template1~*: la copia usata in default.

Ogni votla che viene creato un nuovo database *le impostazioni di base sono copiate da ~template1~*
(che funge da /skel/ directory).

E' facoltà del DBA impostare ~template1~ opportunamente per far si che la creazione di nuovi database
abbia una base comune riconosciuta (es. schemi, linguaggi, ecc.).

~template0~ è la copia di sicurezza del template, qualora si "sporchi" troppo ~template1~.

*** Database templating
I due database template non svolgono alcuna funzione particolare se non quella di essere
usati come possibili punti di origine di un nuovo database. In default, se non specificato, PostgreSQL
copia ~template1~, mentre ~template0~ dovrebbe essere lasciato /vergine/ per operazioni particolari
quali restore (può servire un database vuoto a cui collegarsi).

*** Creare i propri template
    E' possibile creare quanti database template si vuole e istruire il comando
    ~CREATE DATABASE~ per usare altri template oltre ~template1~. Si noti però
    che un database template non accetta connessioni durante la creazione, quindi
    questo *non è un meccanismo di /clonazione/ dei database!*
*** End of block                                               :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:

** Terminale psql
*** psql
Il pacchetto /client/ contiene un interprete da riga di comando, denominato ~psql~
che consente di collegarsi al database e svolgere /tutti/ i compiti necessari.

#+begin_src sh
% psql -h localhost -U postgres template1
Password for user postgres:
psql (9.6.5)
Type "help" for help.

template1=#
template1=# \q
%
#+end_src

I parametri di linea comando sono:
- ~-h~: host a cui collegarsi (hostname, indirizzo ip);
- ~-U~: utente con cui collegarsi (/ruolo/ PostgreSQL);
- database a cui collegarsi (es. ~template1~).

*** psql: connection URI
Oltre a specificare ogni singolo parametro della conessione tramite opzioni di comando,
~psql~ consente di utilizzare un URI per la connessione, ad esempio:

#+begin_src sh
% psql postgresql://postgres@localhost:5432/template1
Password:
psql (9.6.5)
Type "help" for help.

template1=#
#+end_src

Parametri ulteriori possono essere specificati nell'URL (dopo ~?~),
come ad esempio:

#+begin_src sh
postgresql://postgres@localhost/template1?sslmode=require
#+end_src

*** psql: prompt

In modo simile alla shell, il prompt di ~psql~ mostra:
- il database al quale si è collegati (~template1~);
- un ~#~ se si è superuser o ~>~ se si è utenti normali.

Si esce da ~psql~ con ~\q~.

*** Quale versione del server?
~psql~ mostra all'avvio la propria versione (client) ma con una query
è possibile capire anche la versione del server:

#+begin_src SQL
template1=# SELECT version();
 PostgreSQL 9.6.5 on amd64-portbld-freebsd11.0, ...
(1 row)
#+end_src


La funzione speciale ~version()~ viene compilata al momento
del build del pacchetto binario.


*** psql, ruoli, database
In default ~psql~ cerca di collegarsi a un database che ha lo stesso nome
utente dell'utente che esegue il comando stesso, con un ruolo che ha
lo stesso nome.
In altre parole:

#+begin_src sh
% id -p
uid     luca

% psql
psql: FATAL:  role "luca" does not exist
#+end_src

corrisponde a:

#+begin_src sh
% psql -h localhost -U luca luca
#+end_src

*** psql: ruoli, database e variabili di ambiente
 In realtà quando non viene specificato un utente e/o un database
 ~psql~ cerca di collegarsi a quanto stabilito dalle variabili
 di ambiente ~PGUSER~ e ~PGDATABASE~ (e le relative ~PGHOST~ e ~PGPORT~):

#+begin_src sh
% export PGUSER=foo PGDATABASE=myDB
% psql
psql: FATAL:  no pg_hba.conf entry for host "[local]",
              user "foo",
              database "myDB", SSL off
#+end_src

*** psql: aiuto
All'interno di ~psql~ ci sono due tipologie di aiuto:
- /aiuto sui comandi SQL/: si ottiene con ~\h~
  - ~\h~ senza argomenti mostra tutti i comandi SQL disponibili;
  - ~\h COMANDO~ mostra l'aiuto del comando SQL specificato;
- /aiuto su ~psql~/: si ottiene con ~\?~ e mostra tutti i comandi
  speciali di ~psql~. Tutti i comandi ~psql~ iniziano con backslash
  (es. ~\d~).

*** psql: evitare la password
~psql~ consente di impostare un file di credenziali (~$HOME/.pgpass~) per collegarsi
a uno specifico database/host con uno specifico utente senza dover digitare
una password.
Ogni riga nel file contiene:
- host e porta a cui collegarsi;
- database a cui collegarsi (~*~ per tutti);
- username e password con cui collegarsi.

Il file non deve essere leggibile da altri utenti (es. permessi ~600~).

#+begin_src sh
% cat ~/.pgpass
127.0.0.1:5432:template1:postgres:xxxxxxxx

% psql -U postgres template1
template1=#
#+end_src

*** Errori comuni
    *Il file deve avere permessi ~rw~ per il solo proprietario*. Inoltre si deve specificare
    la porta a cui collegarsi dopo l'hostname!
*** End of block                                               :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:


*** psql: configurazione utente
~psql~ consente di specificare delle configurazioni utente nel file ~$HOME/.psqlrc~.
Tutti i comandi (~psql~ compatibili) specificati in tale file vengono eseguiti
prima di fornire il prompt all'utente.

Utile per impostare variabili, prompt, formati di output, ecc.
*** psql: ~/.psqlrc di esempio
#+begin_src sh
\set HISTFILE ~/.psql_history_ :DBNAME
\set ON_ERROR_ROLLBACK on
\set ON_ERROR_STOP     on
\x
\set PROMPT1 '[%n @ %/ on %m] %l %x %# '
#+end_src

Il prompt corrisponde a: /username/ (~%n~), /database/ (~%/~),
/hostname/ (~%m~), /linea/ (~%l~), /stato transazione/ (~%x~)
e /prompt superutente o utente normale/ (~%#~).

** Interazione: ruoli, database, tabelle
*** Ruoli e Utenti
   Dalla versione 8.1 in poi PostgreSQL non distingue piu' fra utenti e gruppi
   ma usa il concetto di *ruolo* che rappresenta entrambi:
   - un ruolo può rappresentare un utente;
   - ad un ruolo si possono aggiungere altri utenti (e quindi rappresenta un gruppo).

*** Ruoli e Connessioni
    *Per collegarsi ad un database occorre sempre un ruolo*, ossia un utente
    PostgreSQL (che è logicamente separato da quello del sistema operativo).
    Quando viene inizializzato un cluster viene creato un ruolo superutente
    per permetterne la gestione (negli esempi ~postgres~).
*** End of block                                               :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:

*** Vedere i ruoli
Il catalogo ~pg_roles~ contiene le informazioni sui ruoli e le loro proprietà:

#+begin_src sql
# SELECT rolname, rolsuper, rolcreatedb, rolcanlogin
FROM pg_roles;
      rolname      | rolsuper | rolcreatedb | rolcanlogin
-------------------+----------+-------------+-------------
 pg_signal_backend | f        | f           | f
 postgres          | t        | t           | t
#+end_src

E' possibile creare utenti/gruppi/ruoli con privilegi di super utente, possibilità di creare nuovi
database e di collegarsi o no al cluster.

*** Creare i ruoli
   Il comand SQL ~CREATE ROLE~ (o da terminale ~createuser~) consente di creare un nuovo utente/gruppo.
   Ad esempio si supponga di voler gestire un database di una applicazione definendo due utenti: uno applicativo
   e uno amministrativo/interattivo:

   #+begin_src sql
# CREATE ROLE my_app
  WITH NOLOGIN
  CONNECTION LIMIT 1
  PASSWORD 'xxx';
CREATE ROLE

# ALTER ROLE my_app WITH LOGIN;

# CREATE ROLE luca
  WITH CREATEDB LOGIN PASSWORD 'xxxxx'
  IN ROLE my_app;
CREATE ROLE
   #+end_src

Ora il ruolo ~my_app~ funge sia da utente che da gruppo a cui ~luca~ appartiene.
Si noti l'uso di ~ALTER ROLE~ per correggere un errore.

*** Creare i ruoli (2)
   I ruoli appena creati risultano ora:
#+begin_src sql
# SELECT rolname, rolsuper, rolcreatedb, rolcanlogin, rolconnlimit
  FROM pg_roles;
      rolname      | rolsuper | rolcreatedb | rolcanlogin | rolconnlimit
-------------------+----------+-------------+-------------+--------------
 pg_signal_backend | f        | f           | f           |           -1
 postgres          | t        | t           | t           |           -1
 my_app            | f        | f           | t           |            1
 luca              | f        | t           | t           |           -1
#+end_src

*** Creare i ruoli (3)
   E' ora possibile configurare il file ~.pgpass~ per i nuovi ruoli:
#+begin_src sh
% cat ~/.pgpass
127.0.0.1:5432_template1:postgres:postgres
localhost:5432:template1:luca:xxxxxx
localhost:5432:template1:my_app:xxxxx
#+end_src

*** Evitare di censire ogni singolo database
    Si ricordi che è possibile usare ~*~ per host, porta e database. Questo semplifica
    il deployment di nuovi database, ma dall'altro lato rende piu' complesso censire
    e controllare i database a cui si accede.
*** End of block                                               :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:
*** Creare un database
   Usando il comando SQL ~CREATE DATABASE~ è possibile aggiungere un nuovo database
   (e /opzionalmente/ aggiungere un commento per indicare lo scopo del database):
#+begin_src sql
# CREATE DATABASE testdb
  WITH OWNER 'luca';

# COMMENT ON DATABASE testdb IS 'A test database';
#+end_src

  Alternativamente si può usare il comando shell ~createdb~:
#+begin_src sh
% createdb --owner='luca' -e -h localhost -U postgres testdb 'A test database'
CREATE DATABASE testdb OWNER luca;
COMMENT ON DATABASE testdb IS 'A test database';
#+end_src

*** Vedere i database disponibili
 Il catalogo ~pg_database~ contiene le informazioni circa i database presenti nel
 sistema:

#+begin_src sql
# SELECT datname FROM pg_database;
  datname
-----------
 postgres
 testdb
 template1
 template0
#+end_src

 Alternativamente si può usare l'opzione ~-l~ in ~psql~:
#+begin_src sh
% psql -h localhost -U postgres -l
...
Name              | testdb
Owner             | luca
Encoding          | UTF8
Collate           | C
Ctype             | C
Access privileges |
#+end_src
*** Eliminare un database
 Avendo i privilegi corretti, si può usare il comando SQL ~DROP DATABASE~
 o il comando shell ~dropdb~:

#+begin_src sql
% psql -h localhost -U postgres template1
# DROP DATABASE testdb;
DROP DATABASE
#+end_src

#+begin_src sh
% dropdb -h localhost -U postgres testdb
#+end_src
*** Creare una tabella
   L'istruzione SQL è ~CREATE TABLE~.
#+begin_src sql
% psql -h localhost testdb                                                                                               ~
> CREATE TABLE persona(
 pk serial,
 nome varchar(20),
 cognome varchar(20),
 codice_fiscale varchar(16),
 PRIMARY KEY(pk),
 UNIQUE(codice_fiscale)
 );
#+end_src

*** Modificare una tabella
   Ci sono varie istruzioni, in particolare ~ALTER TABLE~ che consente di agire sulla tabella
   e sui relativi vincoli:

#+begin_src sql
> ALTER TABLE persona ADD COLUMN eta integer;
> ALTER TABLE persona ADD CHECK ( eta > 0 and eta < 120 );
#+end_src

*** Come è fatta la tabella?
   Il comando speciale di ~psql~ ~\d~ consente di ispezionare una tabella e i suoi vincoli:
#+begin_src sql
> \d persona
                                    Table "public.persona"
     Column     |         Type          |                      Modifiers
----------------+-----------------------+------------------------------------------------------
 pk             | integer               | not null default nextval('persona_pk_seq'::regclass)
 nome           | character varying(20) |
 cognome        | character varying(20) |
 codice_fiscale | character varying(16) |
 eta            | integer               |
Indexes:
    "persona_pkey" PRIMARY KEY, btree (pk)
    "persona_codice_fiscale_key" UNIQUE CONSTRAINT, btree (codice_fiscale)
Check constraints:
    "persona_eta_check" CHECK (eta > 0 AND eta < 120)
#+end_src

* SQL PostgreSQL
** Accorgimenti iniziali
*** SELECT not dual !
   In PostgreSQL non esiste la "famosa" tabella ~dual~ e lo statement ~SELECT~
   fa esattamente quello che ci si aspetta:

#+begin_src sql
> SELECT 1 FROM dual;
ERROR:  relation "dual" does not exist

> SELECT 1;
 ?column?
----------
        1
#+end_src
*** Dollar quoting
   PostgreSQL permette l'uso del *dollar quoting* (simile all'operatore ~qq~ di Perl):
   - si può usare un tag con nome arbitrario purché racchiuso fra due simboli ~$~;
   - il tag va usato per l'apertura e la chiusura;
   - la stringa fra tag viene sottoposta ad escape automatico.

#+begin_src sql
> SELECT $qq$Perche' l'hai scritto?$qq$;
        ?column?
------------------------
 Perche' l'hai scritto?
#+end_src
Si può usare anche uno statement SQL come tag (es. ~$SELECT$~).
*** Camel Case
Lo standard SQL non ammette il camel case, e chiede l'uso di *UPPERCASE*.
PostgreSQL utilizza il *lowercase* per tutti gli identificatori (il risultato non cambia).
#+begin_src sql
> CREATE TABLE Foo( Bar int, bAz int );
-- diventa
-- create table foo( bar int, baz int);
#+end_src

Se si vuole usare il *cAmeLcAsE* si deve indicare ogni operatore /*sempre*/
fra doppi apici (sconsigliato):
#+begin_src sql
> CREATE TABLE "Foo"( "Bar" int, "bAz" int );
> SELECT "Bar", "bAz" FROM "Foo";
#+end_src
** INSERT
*** Valori di uscita di una INSERT
In default una istruzione di ~INSERT~ restituisce due valori:
- ~oid~ della tupla inserita (se la tabella ha gli oid);
- /numero di tuple inserite/.

E' possibile specificare una clausola ~RETURNING~ che restituisca dei valori
basati su una /select-like/ di ogni tupla inserita (caso banale: la chiave automatica).
*** INSERT RETURNING: un primo esempio
#+begin_src sql
> INSERT INTO persona( cognome, nome, codice_fiscale )
  VALUES( 'Luca', 'Ferrari', 'FRRLCU78L19F257T' )
  RETURNING pk;
 pk
----
 13
#+end_src
*** INSERT RETURNING: un esempio piu' complesso
#+begin_src sql
> INSERT INTO persona( cognome, nome, codice_fiscale )
  VALUES( 'Luca', 'Ferrari', 'FRRLCU78L19F257Z' )
  RETURNING upper(codice_fiscale), pk;
      upper       | pk
------------------+----
 FRRLCU78L19F257Z | 14
#+end_src
** UPSERT
*** INSERT or UPDATE?
Una /UPSERT/ è una ~INSERT~ che, in caso di conflitto (vincolo di univocità violato)
esegue una ~UPDATE~ automaticamente.

*UPSERT è una modifica della sintassi di ~INSERT~!*
*UPSERT non può funzionare se si sono delle rules definite sulla tabella!*

Si specifica cosa fare in caso di conflitto, ed eventualmente come risolvere tale conflitto.

In default viene ritornato il numero di tuple inserite o aggiornate in caso di conflitto (come
da return di un ~INSERT~).
*** Funzionamento di UPSERT
Occorre che sia specificato un ~CONSTRAINT~ che indica il conflitto (o una colonna su cui esiste
un constraint di univocità).

La tupla in conflitto viene nominata ~EXCLUDED~.

*** Senza UPSERT...
#+begin_src sql
> INSERT INTO persona( codice_fiscale, nome, cognome )
  VALUES( 'FRRLCU78L19F257B', 'Ferrari', 'Luca' );

-- no upsert!
> INSERT INTO persona( codice_fiscale, nome, cognome )
  VALUES( 'FRRLCU78L19F257B', 'Luca', 'Ferrari' );
ERROR:  duplicate key value violates
  unique constraint "persona_codice_fiscale_key"
#+end_src
*** UPSERT in azione
#+begin_src sql
-- upsert!
> INSERT INTO persona( codice_fiscale, nome, cognome )
  VALUES( 'FRRLCU78L19F257B', 'Luca', 'Ferrari' )
  ON CONFLICT(codice_fiscale)
  DO UPDATE SET nome = EXCLUDED.nome,
             cognome = EXCLUDED.cognome;
#+end_src
*** UPSERT in aborto (controllato)
Se si specifica la risoluzione del conflitto come ~DO NOTHING~ allora la query non effettua
l'inserimento della tupla e fallisce silenziosamente (cioè con successo).
#+begin_src sql
> INSERT INTO persona( codice_fiscale, nome, cognome )
  VALUES( 'FRRLCU78L19F257B', 'Luca', 'Ferrari' )
  ON CONFLICT(codice_fiscale)
  DO NOTHING;

INSERT 0 0
#+end_src
*** UPSERT RETURNING
E' possibile usare la clausola ~RETURNING~ anche nel caso di un /UPSERT/:
#+begin_src sql
> INSERT INTO persona( codice_fiscale, nome, cognome )
  VALUES( 'FRRLCU78L19F257B', 'Luca', 'Ferrari' )
  ON CONFLICT(codice_fiscale)
  DO UPDATE SET nome = EXCLUDED.nome,
             cognome = EXCLUDED.cognome
RETURNING nome, cognome;

 nome | cognome
------+---------
 Luca | Ferrari

#+end_src
** Cast
*** Modalità di cast
In PostgreSQL il cast può essere effettuato in quattro modi:
- specificando il tipo prima del valore (es. ~int '10'~);
- specificando il tipo dopo il valore con l'operatore ~::~ (es. ~'10'::int~);
- usando l'operatore ~CAST~;
- usando il tipo come fosse una funzione (es. ~text( 10 )~ ).
#+begin_src sql
> SELECT '10'::int + 3;
> SELECT int '10' + 3;
> SELECT CAST( '10' AS integer ) + 3;
#+end_src

*** Considerazioni sul cast
I modi consigliati sono *~CAST()~ (conforme SQL standard)* o ~::~, gli altri hanno delle limitazioni
(es. la modalità funzione va usata solo per nomi di tipi che sono anche nomi validi di funzione, mentre il tipo
prima del valore funziona solo per i letterali).

Qualora il cast non sia ambiguo, è possibile ometterlo, ovvero:

#+begin_src sql
> SELECT '10' + 3;
#+end_src

** Alcuni statement particolari
*** CASE
Rappresento lo /switch/ del linguaggio C, o il /given/ di Perl:
#+begin_src sql
> SELECT nome,
  CASE
     WHEN eta >= 18 THEN 'maggiorenne'
     ELSE 'minorenne'
  END
  FROM persona;
 nome  |    case
-------+-------------
 Luca  | maggiorenne
 Diego | minorenne
#+end_src

*** CASE con equals
Si può usare la versione che effettua una comparazione secca sul valore da analizzare:
#+begin_src sql
> SELECT nome,
  CASE eta
   WHEN 39 THEN 'maggiorenne'
   WHEN 10 THEN 'minorenne'
   ELSE 'non saprei'
  END
  FROM persona;
#+end_src

*** COALESCE
Ritorna il primo valore non nullo degli argomenti specificati:
#+begin_src sql
> SELECT COALESCE( NULL, 'MIRIAM',
                   'LUCA', NULL );
 coalesce
----------
 MIRIAM
#+end_src

E' utile per estrarre informazioni che possono trovarsi in campi multipli.

*** NULLIF
Ritorna un valore ~NULL~ se gli operatori sono uguali, altrimenti
ritorna il primo valore:
#+begin_src sql
> SELECT NULLIF('luca', 'LUCA');
 nullif
--------
 luca
> SELECT NULLIF( 10, 10 );
 nullif
--------

#+end_src
/E' una sorta di ~xor~ del poveraccio!/
*** Row
L'operatore ~ROW~ permette di costruire una /tupla/ al volo. Accetta l'uso di costanti
e di espressioni da valutare al volo:
#+begin_src sql
> SELECT ROW( 1, 2, 'Foo', 'Fighters' );
        row
--------------------
 (1,2,Foo,Fighters)

> SELECT ROW( p.codice_fiscale, length( p.codice_fiscale ) ) FROM persona p;
          row
-----------------------
 (FRRLCU71L19F257B,16)
#+end_src
** Array
*** Costruttore di un array
Gli array sono dichiarati con il tipo seguito da parentesi quadre (es. ~integer[]~).
Il costruttore dell'array è l'operatore ~ARRAY~, che cerca di comprendere il tipo
dagli elementi dell'array stesso (se non effettuato un cast).
#+begin_src sql
> SELECT ARRAY[1, 2, 3, 4]::integer[];
   array
-----------
 {1,2,3,4}
#+end_src
*** Array multidimensionali
Sono costruiti combinando assieme piu' array.
#+begin_src sql
> SELECT ARRAY[ ARRAY[ 2, 4 ], ARRAY[ 1, 3 ] ];
     array
---------------
 {{2,4},{1,3}}
#+end_src

*** Array in tabella
Le tabelle possono includere degli array.
#+begin_src sql
> CREATE TABLE software( name text, versions text[] );
> INSERT INTO software
  VALUES( 'Java', '{1.5, 1.6, 1.7, 1.8 }' );
> INSERT INTO software
  VALUES( 'Perl', '{5.10, 5.20, 6.c}' );
#+end_src
*** Array in tabella: indici
Gli indici degli array funzionano come nel linguaggio C, *ma gli indici partono da 1!*:
#+begin_src sql
> SELECT name, versions[1] FROM software;
 name | versions
------+----------
 Perl | 5.10
 Java | 1.5
#+end_src
*** Array in tabella: estremi
Le funzioni ~array_lower()~ e ~array_upper()~ forniscono il minimo e massimo indice
usabile in una determinata dimensione dell'array:
#+begin_src sql
> SELECT name,
  versions[ array_lower( versions, 1) ] AS required,
  versions[ array_upper( versions, 1 ) ] AS optimal
  FROM software;
 name | required | optimal
------+----------+---------
 Perl | 5.10     | 6.c
 Java | 1.5      | 1.8
#+end_src
*** Array in tabella: slicing
L'operatore ~[:]~ permette di ottenere lo slicing:
#+begin_src sql
> SELECT name, versions[1:2] FROM software;
 name |  versions
------+-------------
 Perl | {5.10,5.20}
 Java | {1.5,1.6}
#+end_src

*** Array in tabella: aggiunta di elementi
Si possono seguire diverse strade:
- ricostruire l'intero array con i nuovi valori tramite ~ARRAY~;
- appendere l'array originale con uno singolo (costruito con ~ARRAY~ o ~'{}'~);
- usare ~array_prepend()~ per inserire un elemento in testa, ~array_append()~ per aggiungerlo in coda
  e/o ~array_cat()~ per concatenare due array.

*** Array in tabella: aggiunta di elementi (esempio 1)
#+begin_src sql
> UPDATE software
  SET versions = versions || ARRAY['2017.09']
  WHERE name = 'Perl';

> UPDATE software
  SET versions = versions || '{1.8_168}'
  WHERE name = 'Java';
#+end_src

*** Array in tabella: aggiunta di elementi (esempio 2)
#+begin_src sql
> UPDATE software
  SET versions = array_append( versions, '1.8_169' )
  WHERE name = 'Java';

> UPDATE software
  SET versions = array_prepend( '1.4', versions )
  WHERE name = 'Java';
#+end_src

*** Array in tabella: concatenazione
#+begin_src sql
> UPDATE software
  SET versions = array_cat( ARRAY[ '5.6', '5.8' ], versions )
  WHERE name = 'Perl';
#+end_src

*** Array in tabella: ricerca
Ci sono due operatori principali:
- ~ANY~ ricerca un valore in uno qualunque degli elementi dell'array;
- ~ALL~ ricerca un valore in tutti gli elementi dell'array.

Altri operatori utili nel confronto di due array:
- ~&&~ ricerca le sovrapposizioni;
- ~@>~ /contains/;
- ~<@~ /is contained by/.
*** Array in tabella: ricerca (esempio 1)
#+begin_src sql
> SELECT name FROM software WHERE '6.c' = ANY( versions );
 name
------
 Perl

> SELECT name FROM software WHERE '6.c' = ALL( versions );
 name
------
(0 rows)
#+end_src

*** Array in tabella: ricerca (esempio 2)
#+begin_src sql
> SELECT name FROM software WHERE ARRAY[ '5.10', '5.20' ] && versions;
 name
------
 Perl
#+end_src

*** Array in tabella: ricerca (esempio 3)
#+begin_src sql
-- contains
> SELECT name FROM software
  WHERE ARRAY[ '5.10', '5.20' ] @> versions;

(0 rows)

-- is contained by
> SELECT name FROM software
  WHERE ARRAY[ '5.10', '5.20' ] <@ versions;
 name
------
 Perl
#+end_src
*** Array in tabella: eliminare un elemento
La funzione ~array_remove()~ toglie un valore da un array, mentre ~array_replace()~
sostituisce un elemento con un altro. *Restituiscono l'array modificato!*
#+begin_src sql
> UPDATE software
  SET versions = array_remove( versions, '5.6' );

> UPDATE software
  SET versions = array_replace( versions, '5.8', '5.8.2' );
#+end_src
*** Array in tabella: trovare un elemento
Le funzioni ~array_position()~ e ~array_positions()~ ritornano la posizione di uno
elemento (eventualmente ripetuto) nell'array:
#+begin_src sql
> SELECT name, array_positions( versions, '5.20' )
  FROM software;
 name | array_positions
------+-----------------
 Perl | {3}
 Java | {}
#+end_src
*** Array in tabella: trasformare un array in tabella
#+begin_src sql
> SELECT name, unnest( versions ) FROM software;
 name | unnest
------+---------
 Perl | 5.8.2
 Perl | 5.10
 Perl | 5.20
 Perl | 6.c
...
#+end_src
** Range
*** Range di dato
I tipi di dato /range/ sono valori /non esattamente definiti/.
L'idea è quella di identificare un tipo ammesso di valori (denominato *subtype*),
sul quale si imposta un valore di inizio e di fine e tutti i valori fra questi inclusi.

Esempio: /dalle ore 8:00 alle ore 9:00/. Con un solo valore range si indica
l'inizio (/8:00/) e la fine (/9:00/) del sottotipo (es. ~time~).

*** Range predefiniti
PostgreSQL supporta i seguenti tipi range:
- ~int4range~ range di ~integer~;
- ~int8range~ range di ~biginteger~;
- ~numrange~ range di ~numeric~;
- ~tsrange~ rande di timestamp;
- ~daterange~ range di ~date~.

*** Esempio di utilizzo di range
#+begin_src sql
> CREATE TABLE ticket(
    pk SERIAL PRIMARY KEY,
    tipo text,
    periodo daterange,
    altezza int4range );
#+end_src

*** Costruzione di un range: sintassi stringa
Un tipo range viene sempre specificato come stringa (fra apici)
e può valere:
- ~[ begin, end ]~ oppure ~( begin, end )~
- ~empty~ per non specificare nessun valore (simile a ~NULL~),

Come la forma matematica, le parentesi quadre indicano l'inclusione dell'estremo
mentre quelle tonde l'esclusione dell'estreno.

*** Costruzione di range: costruttori
Alternativamente alla forma stringa, ogni tipo di range predefinito include
un costruttore con lo stesso nome del tipo di range e che accetta due o tre parametri:
- ~typerange( a, b )~ costruisce un range di ~type~ come ~'[a, b)'~;
- ~typerange( a, b, '()' )~ costruisce un range di ~type~ con gli estremi specificati
  dalla combinazione delle parentesi.

*** Inserimento di valori di range
#+begin_src sql
> INSERT INTO ticket( tipo, periodo, altezza )
  VALUES( 'GRATUITO-BIMBO',
  '[2017-06-01, 2017-09-30)',
  '(60, 100)' );

> INSERT INTO ticket( tipo, periodo, altezza )
  VALUES( 'GRATUITO-ANZIANO',
  '[2017-06-01, 2017-10-31]',
  'empty' );
#+end_src

*** Operatori di range
Per ricercare fra un range si usano operatori simili a quelli
di un array:
- ~@>~ il range (a sinistra) contiene il valore scalare a destra;
- ~isempty~ indica se il range è vuoto;
- ~upper~ e ~lower~ estraggono gli estremi del range;
- ~&&~ sovrapposizione fra due range.

*** Query sui range
#+begin_src sql
> SELECT tipo FROM ticket
  WHERE periodo
     && daterange( '2017-07-01',
                   '2017-07-31',
                   '[]' );
#+end_src

*** Query sui range (2)
#+begin_src sql
> SELECT tipo FROM ticket
  WHERE periodo @> '2017-10-31'::date;
#+end_src

** Tipi di dato personalizzato
*** Tipi personalizzati
PostgreSQL consente di creare dei /tipi/ personalizzati:
- *compositi* (una sorta di struttura);
- *enum* le classiche enumerazioni, sostanzialmente una serie di /etichette/;
- *range* un tipo che identifica un range di valori;
- *scalare* un tipo fortemente integrato nel server e che richiede la scrittura di opportune
  funzioni in codice C;

*** Creare un tipo enumerazione
Si vogliono /standardizzare/ gli stati di un software:
#+begin_src sql
> CREATE TYPE sw_version
  AS ENUM ( 'stable',
            'unstable',
            'EOL',
            'development' );
#+end_src

*** Creare un tipo composito
SI supponga di voler creare un semplice tipo strutturato per un repository
software:
#+begin_src sql
> CREATE TYPE sw_repository
  AS ( url text,
       author text );
#+end_src
*Il tipo composito si usa con parentesi tonde!*

*** Usare i tipi in una tabella
#+begin_src sql
> CREATE TABLE software(
      pk SERIAL PRIMARY KEY,
      name text,
      version sw_version,
      repository sw_repository );
#+end_src

*** Inserire i tipi compositi
#+begin_src sql
> INSERT INTO software( name, version, repository )
  VALUES( 'PostgreSQL-9.6',
      'stable',
      ( 'https://www.postgresql.org', 'PGDG' ) );

> INSERT INTO software( name, version, repository )
  VALUES( 'Perl-6',
     'stable',
     ( 'https://www.perl6.org', 'Perl Developers' ) );
#+end_src

*** Estrarre i tipi composti
#+begin_src sql
> SELECT name, (repository).url FROM software;
      name      |            url
----------------+----------------------------
 PostgreSQL-9.6 | https://www.postgresql.org
 Perl-6         | https://www.perl6.org
#+end_src

*** Creare un tipo personalizzato range
#+begin_src sql
> CREATE OR REPLACE FUNCTION f_versions_diff( older float, newer float )
RETURNS float AS $BODY$
DECLARE
BEGIN
    RETURN (newer - older)::integer;
END;
$BODY$
LANGUAGE plpgsql IMMUTABLE;
#+end_Src

*** Creare un tipo personalizzato range (2)
#+begin_src sql
> CREATE TYPE sw_major_version AS RANGE (
subtype = float,
subtype_diff = f_versions_diff );
#+end_src

*** Creare un tipo personallizato range (3)
#+begin_src sql
> SELECT '[9.6, 10.0)'::sw_major_version;
 sw_major_version
------------------
 [9.6,10)
#+end_src

** TODO JSON & JSONB
*** Tipi di dato JSON
PostgreSQL supporta due tipi di dato /JSON (JavaScript Object Notation):
- ~json~ tipo di dato testuale che richiede un nuovo /parsing/ ogni volta che
  si opera sul dato stesso;
- ~jsonb~ una forma che viene destrutturata e memorizzata in formato binario per successive
  elaborazioni piu' rapide (richiede maggior tempo in inserimento per la conversione).

Il formato ~json~ mantiene l'input intatto, quindi spazi bianchi, chiavi duplicate (solo l'ultima
viene trattata dagli operatori). IL tipo ~jsonb~ rimuove spazi bianchi ridondanti nonché mantiene
un solo valore per ogni chiave (l'ultimo nel caso di chiavi duplicate).
* Vacuum e Autovacuum
** Impatti di Vacuum e autovacuum
*** Tabella di eventi
   Si immagini di popolare una tabella di eventi:

#+begin_src sql
> CREATE TABLE evento( pk serial NOT NULL,
                      description text,
                      ts timestamp default current_timestamp,
                       PRIMARY KEY(pk) );
#+end_src

e di popolarla con alcuni dati...
#+begin_src sql
> INSERT INTO evento( description )
 SELECT 'Evento ' ||
    CASE WHEN ( random() * 10 )::integer % 2 = 0
         THEN 'pari'
         ELSE 'dispari'
    END
 FROM generate_series( 1, 1000000 );

INSERT 0 1000000
Time: 8635.289 ms
#+end_src

*** Tabella di eventi: quanto occupa?
#+begin_src sql
> SELECT relname, relpages, reltuples
FROM pg_class
WHERE relkind = 'r' AND relname = 'evento';
 relname | relpages | reltuples
---------+----------+-----------
 evento  |     6879 |     1e+06
#+end_src

indicativamente ~6879 * 8kB = 53,74 MB~ di spazio disco.
Verifichiamo...
#+begin_src sh
% oid2name -H localhost -U luca -d testdb -t evento                                                                      ~
From database "testdb":
  Filenode  Table Name
----------------------
     16465      evento

% oid2name -H localhost -U luca                                                                                          ~
  16393         testdb

% sudo ls -lh /mnt/data1/pgdata/base/16393/16465                                                                         ~
-rw-------  1 postgres  postgres    54M Oct 18 10:40 /mnt/data1/pgdata/base/16393/16465
#+end_src

*** Tabella di eventi: quanto occupa? (2)
Metodo meno "scomodo" di cercare il file fisico su disco...
#+begin_src sql
> SELECT pg_size_pretty(
             pg_relation_size( 'evento'::regclass )
         );
 pg_size_pretty
----------------
 54 MB
(1 row)
#+end_src
*** Tabella di eventi: statistiche
Le statistiche di sistema sembrano funzionare correttamente:
#+begin_src sql
> SELECT pg_relation_size( 'evento'::regclass ) AS dimensione_fisica, relpages, reltuples
  FROM pg_class  WHERE relkind = 'r' AND relname = 'evento';
 dimensione_fisica | relpages | reltuples
-------------------+----------+-----------
          56352768 |     6879 |     1e+06

> TRUNCATE evento;

> SELECT pg_relation_size( 'evento'::regclass ) AS dimensione_fisica, relpages, reltuples
  FROM pg_class  WHERE relkind = 'r' AND relname = 'evento';
 dimensione_fisica | relpages | reltuples
-------------------+----------+-----------
                 0 |        0 |         0
#+end_src

*** Tabella di eventi: statistiche (2)
Ma cosa succede se *fermiamo autovacuum*?

#+begin_src sql
 > INSERT INTO evento( description ) -- 1000000 tuple
...
INSERT 0 1000000

> SELECT pg_relation_size( 'evento'::regclass ) AS dimensione_fisica, relpages, reltuples
  FROM pg_class  WHERE relkind = 'r' AND relname = 'evento';
 dimensione_fisica | relpages | reltuples
-------------------+----------+-----------
          56344576 |        0 |         0
#+end_src

*Il numero di tuple e pagine non è stato aggiornato*.
Che impatto ha questo? Il planner non sarà in grado di capire che "mole di dati" ha davanti!
*** Tabella di eventi: statistiche (3)
Niente panico! E' possibile lanciare *vacuum* manualmente.
#+begin_src sql
> VACUUM FULL VERBOSE evento;
INFO:  vacuuming "public.evento"
INFO:  "evento": found 0 removable, 1000000 nonremovable row versions in 6878 pages
DETAIL:  0 dead row versions cannot be removed yet.
CPU 0.14s/0.30u sec elapsed 0.82 sec.

> SELECT pg_relation_size( 'evento'::regclass ) AS dimensione_fisica, relpages, reltuples
  FROM pg_class  WHERE relkind = 'r' AND relname = 'evento';
 dimensione_fisica | relpages | reltuples
-------------------+----------+-----------
          56344576 |     6878 |     1e+06
#+end_src

* Transazioni
** Livello di isolamento
*** Livelli di isolamento
   Le problematiche sono:
   - *dirty reads*: è possibile vedere (leggere) tuple non ancora committate da altre
     transazioni;
   - *unrepeatable reads*: una tupla riletta piu' volte durante una transazione presenta valori
     modificati da un'altra transazione;
   - *phantom reads*: la stessa query eseguita piu' volta fornisce un resultset modificato (nella
     quantità) da un'altra transazione

*** Livelli di isolamento in PostgreSQL
   PostgreSQL supporta 3 livelli di isolamento sui 4 standard (/read uncommited/, /read committed/,
   /repeatable read/, /serializable/). Questo non rappresenta un problema poiché è sufficiente
   garantire il /livello di isolamento superiore/.

   Una transazione può essere di tipo:
   - *read committed*: /(default)/ uno statement vede solo le tuple consolidate
     prima dell'inizio dello statement stesso;
   - *repeatable read*: ogni statement della transazione può vedere solo le tuple
     consolidate prima dell'esecuzione del primo statement (ovvero, all'inizio della transazione);
   - *serializable*: come *repeatable read* ma impone che le transazioni siano /idempotenti/ rispetto
     al loro effettivo ordine di esecuzione (monitoring di consistenza seriale).
*** Impostare i livelli di isolamento in PostgreSQL
   All'interno di una transazione è possibile impostare il livello
   di isolamento, che però non può essere piu' cambiato dopo l'esecuzione
   di uno statement di modifica (incluso ~SELECT~).
   Quando si avvia una transazione è possibile specificare l'isolation level
   direttamente nel blocco ~BEGIN~, mentre per gli altri casi c'è ~SET TRANSACTION~:

#+begin_src sql
> BEGIN TRANSACTION ISOLATION LEVEL REPEATABLE READ;
> SET TRANSACTION ISOLATION LEVEL SERIALIZABLE;
ERROR:  SET TRANSACTION ISOLATION LEVEL must not be called in a subtransaction
#+end_src
** Casistiche particolari delle transazioni
*** Transazioni ~READ ONLY~ contro ~READ WRITE~
   PostgreSQL permette di specificare due tipi di transazioni:
   - *READ WRITE*: (default) è possibile eseguire ogni statement SQL;
   - *READ ONLY*: è una /promessa/ di non alterare i dati. Tutti i comandi
     generici (~UPDATE, INSERT, DELETE, EXECUTE, ALTER TABLE, VACUUM~, ecc.)
     sono disabilitati a meno che non agiscano su tabelle temporanee.

  *Non c'è nessuna garanzia che una transazione ~READ ONLY~ non effettui scritture su disco!*
*** Transazioni ~DEFERRABLE~
   C'è un caso particolare di transazione: ~DEFERRABLE~.
   Questo si applica solo a transazioni ~READ ONLY~ e ~SERIALIZABLE~.

   L'idea è che la transazione accetta di "attendere" prima della sua esecuzione, e in cambio
   l'overhead di monitoring per la serializzazione è ridotto. Ciò produce dei vantaggi
   per le transazioni di reportistica.

* Stored Procedures & Cursori
** FUNCTION
*** Funzioni
   PostgreSQL permette la creazione di funzioni tramite ~CREATE FUNCTION~.
   Le funzioni possono accettare dei parametri (eventualmente tipizzati e con valori
   di default), possono definire delle variabili (eventualmente tipizzate) e avere
   un valore di ritorno (tipizzato).

   Le funzioni sono create in uno specifico linguaggio, solitamente ~pgpsql~
   e sono identificate dalla loro /signature/.

*** Template di CREATE FUNCTION
#+begin_src sql
CREATE OR REPLACE FUNCTION function_name( <arg>, <arg>, ... )
RETURNS <return type>
AS
-- definition
LANGUAGE language [<volatilità>];
#+end_src

*** Prototiti di funzione
   - la lista di parametri può includere solo i tipi, nel qual caso i parametri sono accessibili con ~$1~, ~$2~, ecc.;
   - i parametri possono includere un valore di default specificato con ~DEFAULT~;
   - i parametri possono essere in ingresso (~IN~, default), in uscita (~OUT~, non importa
     farne il ~RETURN~) o in entrambi (~INOUT~).

*** Volatilità di una funzione
   Le funzioni hanno tre livelli di /volatilità/:
   - ~VOLATILE~: /default/, modifica il database e può dare risultati diversi
     anche se inocata con gli stessi argomenti;
   - ~STABLE~: non modifica il database e ritorna lo stesso valore con gli stessi
     argomenti /per tutte le tuple nello stesso statement/ (è indipendente dal valore
     delle singole tuple), utile per operatori di confronto (es. negli indici);
   - ~IMMUTABLE~: non modifica il database e ritorna lo stesso valore con gli stessi
     argomenti /sempre/.

  Esempi: ~random()~ è ~VOLATILE~, ~current_timestamp~ è ~STABLE~,
  ~version()~ è ~IMMUTABLE~.

** Il linguaggio plpgsql
*** plpgsql
   E' il linguaggio /default/ per la gestione di blocchi di codice:
   - prevede la dichiarazione delle variabili di funzione  con ~DECLARE~;
   - racchiude il body della funzione fra ~BEGIN~ e ~END~
   - consente cicli e istruzioni condizionali.

*** Esempio di semplice funzione: somma
#+begin_src sql
CREATE OR REPLACE FUNCTION somma( int, int )
RETURNS INTEGER
AS
$BODY$
DECLARE --nessun variabile
BEGIN
        RETURN $1 + $2;
END;
$BODY$
LANGUAGE plpgsql;
#+end_src

#+begin_src sql
> select somma( 10, 20 );
 somma
-------
    30
#+end_src

*** Esempio di semplice funzione: somma con alias parametri
   Simile alle /sub/ di Perl 5!
#+begin_src sql
CREATE OR REPLACE FUNCTION somma( int, int )
RETURNS INTEGER
AS
$BODY$
DECLARE
        a ALIAS FOR $1;
        b ALIAS FOR $2;
BEGIN
        RETURN a + b;
END;
$BODY$
LANGUAGE plpgsql;
#+end_src

*** Esempio di semplice funzione: somma con parametri nominali
#+begin_src sql
CREATE OR REPLACE FUNCTION somma( a int, b int )
RETURNS INTEGER
AS
$BODY$
DECLARE
BEGIN
        RETURN a + b;
END;
$BODY$
LANGUAGE plpgsql;
#+end_src

*** Esempio di semplice funzione: somma e sottrazione
#+begin_src sql
CREATE OR REPLACE FUNCTION somma_sottrazione( INOUT a int ,
                                              INOUT b int )
AS $BODY$
DECLARE
BEGIN
        a = a + b;
        b = a - b;
END; $BODY$
LANGUAGE plpgsql;
#+end_src

*** Esempio di semplice funzione: somma e sottrazione (2)
#+begin_src sql
> SELECT somma_sottrazione( 10, 20 );
 somma_sottrazione
-------------------
 (30,10)

> SELECT b, a FROM somma_sottrazione( 10, 20 );
 b  | a
----+----
 10 | 30
#+end_src

*** Esempio di semplice funzione: somma con valori di default
   I valori di default possono essere omessi nella chiamata
   di funzione (*~NULL~ è considerato un valore*):
#+begin_src sql
CREATE OR REPLACE FUNCTION somma( a int DEFAULT 0,
                                  b int DEFAULT 0 )
RETURNS INTEGER
AS $BODY$
DECLARE
BEGIN
        RETURN a + b;
END;
$BODY$
LANGUAGE plpgsql;
#+end_src

#+begin_src sql
 > SELECT somma();
 somma
-------
     0
#+end_src

*** Esempio di semplice funzione: costanti
   E' possibile definire delle costanti in fase di dichiarazione di variabili
   con ~CONSTANT~, ed è opportuno definirne il valore.

#+begin_src sql
CREATE OR REPLACE FUNCTION somma( a int DEFAULT 0,
                                  b int DEFAULT 0 )
RETURNS INTEGER
AS
$BODY$
DECLARE
      c CONSTANT integer := 10;
BEGIN
        RETURN a + b + c;
END;
$BODY$
LANGUAGE plpgsql;
#+end_src

*** Variabili costanti
   Se si cercasse di modificare una variabile costante verrebbe generato
   un errore di compilazione della funzione:
#+begin_src sql
psql:functions.sql:43: ERROR:  "c" is declared CONSTANT
LINE 38:  c := a + b;
          ^
#+end_src

*** Variabili ROWTYPE
Alcune variabili possono essere dichiarate con l'attributo ~%rowtype~ specificando
la tabella a cui fanno riferimento.
Le variabili di fatto rappresentano una tupla (strutturata) della tabella dichiarata.
#+begin_src sql
DECLARE
  my_record persona%rowtype;
BEGIN
 my_record.nome = 'Luca';
 my_record.eta  = 39;
...-- return next etc.
END;
#+end_src
*** Variaibili RECORD
Le variabili ~record~ sono la generalizzazione di quelle ~rowtype~: possono contenere
un record estratto da una qualsiasi tabella e assumeranno la struttura di quella tupla,
*ma prima del loro assegnamento non possono essere usate*.

Le si possono assegnare piu' volte a tuple di struttura differente.
*** Funzioni che ritornano tuple
Ci sono due modi per dichiarare una funzione che ritorna una o piu' tuple:
- ~RETURNS RECORD~ restituisce una singola tupla contenuta in un ~record~ (questo ad esempio
  è il caso con parametri ~OUT~);
- ~RETURNS SETOF~ restituisce piu' tuple di un tipo specificato (es. di una tabella).
*** RETURN NEXT e RETURN QUERY
Le funzioni che ritornano un ~SETOF~ possono usare ~RETURN NEXT~ per appendere un nuovo record
al result set. Una volta conclusa la costruzione del result set si usa un normale ~RETURN~
per uscire dalla funzione.

Alternativamente si può usare ~RETURN QUERY~ per inserire nel result set il risultato
di una query.

*** RETURN NEXT: esempio
#+begin_src sql
CREATE OR REPLACE FUNCTION find_maggiorenni()
RETURNS SETOF persona AS $BODY$
DECLARE
  current_maggiorenne persona%rowtype;
BEGIN
  FOR current_maggiorenne IN
        SELECT * FROM persona WHERE eta >= 18
  LOOP
          RETURN NEXT current_maggiorenne;
  END LOOP;

  RETURN;
END;
$BODY$ LANGUAGE plpgsql;
#+end_src

*** RETURN QUERY: esempio
*** IF...ELSE
#+begin_src sql
  IF eta >= 18 THEN
       RETURN 'maggiorenne';
  ELSIF eta >= 10 THEN
       RETURN 'teen-ager';
  ELSE
      RETURN 'bimbo';
  END IF;
#+end_src
*** Cicli
I cicli hanno tutti una parola chiave ~LOOP~ e finiscono con ~END LOOP~.

E' possibile specificare una etichetta per identificare il ciclo, l'etichetta deve:
- essere dichiarata prima del ciclo fra doppie parentesi angolari (es. ~<<CICLO_1>>~);
- essere inclusa nella chiusura del ciclo (es. ~END LOOP CICLO1~).
*** LOOP
Ciclo (con eventuale etichetta). Può essere annidato.

Due operatori sintatticamente simili controllano il flusso:
- ~CONTINUE~ ricomincia l'iterazione dall'etichetta specificata (o dal ciclo corrente) quando la condizione ~WHEN~ si verifica;
- ~EXIT~ esce (termina) il ciclo specificato dall'etichetta (o quello corrente) quando la condizione ~WHEN~ viene soddisfatta.

*** LOOP: esempio
#+begin_src sql
<<LP_ETA>>
  LOOP
     eta := eta + 1;
     EXIT LP_ETA WHEN eta >= 18;
  END LOOP LP_ETA;
#+end_src
oppure semplificando:
#+begin_src sql
  LOOP
     eta := eta + 1;
     EXIT  WHEN eta >= 18;
  END LOOP;
#+end_src
*** WHILE
Analogo al ciclo /while/ di ogni linguaggio di programmazione, è un ~LOOP~ con ~EXIT~ integrata!
Può includere una etichetta.
#+begin_src sql
<<LP_ETA>>
  WHILE eta <= 18 LOOP
     eta := eta + 1;
  END LOOP LP_ETA;
#+end_src

*** FOR
Analogo al ciclo /for/ del linguaggio C, senza la definizione di incremento diventa un /foreach/:
#+begin_src sql
<<LP_ETA>>
  FOR current_eta IN 18..30 LOOP
     RAISE INFO 'vALORE %', current_eta;
  END LOOP LP_ETA;
#+end_src
o analogamento al ciclo for del linguaggio C:
#+begin_src sql
  FOR current_eta IN 18..30 BY 2 LOOP
     RAISE INFO 'vALORE %', current_eta;
  END LOOP LP_ETA;
#+end_src

*** FOREACH
Itera fra gli elementi di un array. Segue le stesse regole sintattiche del ciclo ~FOR~ (etichetta, ecc).
#+begin_src sql
 FOREACH current_version IN ARRAY v_array LOOP
    RAISE INFO 'Version %', current_version;
 END LOOP;
#+end_src

*** FOR IN query
Quando si deve iterare sul result set di una query la sintassi è ~FOR IN <query>~:
#+begin_src sql
FOR my_record IN SELECT * FROM persona LOOP
END LOOP;
#+end_src
oppure la variante con ~EXECUTE~ se la query viene specificata da una stringa:
#+begin_src sql
query_string := 'SELECT * FROM persona';
FOR my_record IN EXECUTE query_string LOOP
END LOOP;
#+end_src

#+begin_src sql
CREATE OR REPLACE FUNCTION find_maggiorenni()
RETURNS SETOF persona
AS $BODY$
DECLARE
        current_maggiorenne persona%rowtype;
BEGIN
        RETURN QUERY SELECT * FROM persona WHERE eta >= 18;
        RETURN;
END;
$BODY$ LANGUAGE plpgsql;
#+end_src

*** Eccezioni
Il blocco ~BEGIN...END~ di una funzione permette l'opzionale ~EXCEPTION~ che funziona
da /catch/ per le eccezioni. Al suo interno l'eccezione viene cercata fra quelle specificate
nelle clausole ~WHEN~.

*Se nessuna clausola ~WHEN~ di ~EXCEPTION~ fa match, o se il blocco ~EXCEPTION~ non è stato specificato, la funzione termina con errore!*

Le eccezioni possibili sono /etichettate/ e definite alla pagina
<https://www.postgresql.org/docs/9.6/static/errcodes-appendix.html>
come ad esempio ~division_by_zero~.

*Il sistema mantiene lo stato delle variabili al momento in cui si verifica l'errore*, l'uso di un blocco
~EXCEPTION~ è /costoso/ per il sistema, quindi non va usato ove non si possono verificare o non interessa
catturare eccezioni.

*** Eccezioni: variabili diagnostiche
All'interno di un blocco ~EXCEPTION~ le variabili speciali ~SQLSTATE~ e ~SQLERRM~ contengono lo stato e il messaggio
associato all'errore generato.

E' inoltre possibile usare il comando ~GET_STACKED_DIAGNOSTIC~ per estrarre ulteriori informazioni circa
l'errore di esecuzione (es. su quale tabella, colonna, constraint, ecc.).

*** Eccezioni: esempio
#+begin_src sql
BEGIN
    RETURN divide_what / divide_by;
EXCEPTION
    WHEN division_by_zero THEN
      RAISE INFO 'Divisione per zero';
      RAISE INFO 'Errore % %', SQLSTATE, SQLERRM;
      RETURN 0;
END;
#+end_src

*** PERFORM: il problema
Se in una stored procedure si utilizza una query che ritorna dei risultati,
ma si vuole scartare l'insieme dei risultati stessi, occorre usare ~PERFORM~.
In altre parole: *nelle stored procedures è possibile usare ogni comando SQL che non ritorni risultati o dove i risultati siano /memorizzati in variabili/ (anche di iterazione)*.

#+begin_src sql
CREATE OR REPLACE FUNCTION do_select()
RETURNS VOID AS $BODY$
DECLARE
BEGIN
        SELECT * FROM persona;
END;
$BODY$ LANGUAGE plpgsql;
#+end_src

#+begin_src sql
> SELECT do_select();
ERROR:  query has no destination for result data
HINT:  If you want to discard the results of a
SELECT, use PERFORM instead.
#+end_src

*** PERFORM: la soluzione
#+begin_src sql
CREATE OR REPLACE FUNCTION do_select()
RETURNS VOID
AS $BODY$ DECLARE
BEGIN
        PERFORM  * FROM persona;
END;
$BODY$ LANGUAGE plpgsql;
#+end_src

*** PERFORM vs SELECT                                          :B_definition:
    *PERFORM* sostituisce *SELECT* in una query!
*** End of block                                               :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:

*** SELECT INTO
E' possibile assegnare a una (o piu') variabili il risultato di una ~SELECT~
specificando appunto la lista di variabile ove inserire (~INTO~) il risultato, considerando
che:
- se la query ritorna piu' di una riga e non è specificato ~STRICT~ allora solo la prima tupla
  viene inserita nelle variabili e la query termina (ossia ~SELECT INTO~ esegue un implicito
  ~LIMIT 1~);
- se la query ritorna piu' di una riga ed è specificato ~STRICT~ allora si ha un errore di esecuzione
  (ossia *~STRICT~ impone che la query fornisca una sola tupla*).
*** SELECT INTO: esempio senza STRICT
#+begin_src sql
CREATE OR REPLACE FUNCTION do_select()
RETURNS VOID AS $BODY$
DECLARE
        v_nome text;
        v_cognome text;
BEGIN
        SELECT nome, cognome
        INTO v_nome, v_cognome
        FROM persona;

        RAISE INFO 'Trovati % %',
                    v_nome,
                    v_cognome;
END;
$BODY$ LANGUAGE plpgsql;
#+end_src
*** SELECT INTO: esempio senza STRICT (2)
#+begin_src sql
> SELECT count(*) FROM persona;
 count
-------
     4 -- ci sono 4 persone!
> SELECT do_select();
INFO:  Trovati EMANUELA SANTUNIONE
#+end_src
*** SELECT INTO: errore di STRICT
Se la query viene eseguita con ~STRICT~ si ottiene un errore di esecuzione:

#+begin_src sql
> SELECT do_select();
ERROR:  query returned more than one row
#+end_src

*** SELECT INTO: esempio con STRICT
#+begin_src sql
CREATE OR REPLACE FUNCTION do_select()
RETURNS VOID AS $BODY$
DECLARE
        v_nome text;
        v_cognome text;
BEGIN
        SELECT nome, cognome
        INTO STRICT v_nome, v_cognome
        FROM persona
        WHERE codice_fiscale = 'FRRLCU78L19F257B';

        RAISE INFO 'Trovati % %',
                   v_nome,
                   v_cognome;
END;
$BODY$ LANGUAGE plpgsql;
#+end_src
Si filtra sulla chiave per ottenere esattamente un record!

*** EXECUTE
Il comando ~EXECUTE~ consente l'esecuzione di query costruite al volo (/no-caching/)
in formato stringa.
Il comando permette la sotituzione di variabili all'iterno della stringa di query:
- le variabili sono identificate con ~$1~, ~$2~, ecc.;
- il comando deve avere una forma con ~USING~ seguito dalla lista dei parametri da sostituire.

*I parametri possono essere usati solo per dei dati, per i nomi di tabella/colonna si deve effettuare una concatenazione di stringa!*

Inoltre ~EXECUTE~ permette di effettuare un ~INTO [STRICT]~ come una normale ~SELECT~.
*** EXECUTE: esempio
#+begin_src sql
-- SELECT do_count( 2, 'persona' );
CREATE OR REPLACE FUNCTION do_count( pk int, tabella text)
RETURNS integer
AS $BODY$ DECLARE
        v_count int;
BEGIN
        EXECUTE 'SELECT count(*) FROM '
                 || tabella
                 || ' WHERE pk >= $1'
        INTO STRICT v_count
        USING pk;

        RETURN v_count;
END;
$BODY$ LANGUAGE plpgsql;
#+end_src

** Cursori
*** Cos'è un cursore?
Un cursore è un meccanismo che trasforma un record-set in una iterazione fra record: non si ottiene
piu' l'insieme dei risultati in un unico blocco ma si /scorre/ il risultato tupla per tupla.

I cursori sono di due tipologie:
- /bound/ sono dichiarati con la relativa query a cui fanno riferimento;
- /unbound/ sono dichiarati senza la query, che sarà fornita successivamente.

*Tutti i cursori sono di tipo ~refcursor~, ma solo quelli /unbound/ vengono esplicitamente dichiarati come tali*.
Un cursorse si dice /scrollable/ se può scorrere le tuple in avanti e indietro.
*** Workflow di un cursore
Solitamente il workflow è il seguente:
1. dichiarazione (bound/unbound);
2. ~OPEN~ indica che si vuole usare il cursore;
3. ~FETCH~ preleva una tupla dalla query (imposta la variabile ~FOUND~ di conseguenza);
   - ~MOVE~
   - ~INSERT~ o ~UPDATE~
4. ~CLOSE~ si è finito di usare il cursore, le risorse sono liberate.
*** Esempio di cursore
#+begin_src sql
CREATE OR REPLACE FUNCTION do_cursor()
RETURNS int AS $BODY$
DECLARE
   counter int := 0;
   my_curs CURSOR FOR SELECT * FROM persona;
   my_record persona%rowtype;
BEGIN
    OPEN my_curs;
    FETCH my_curs INTO my_record;
    WHILE FOUND
    LOOP
      IF my_record.eta >= 18
      THEN
         counter := counter + 1;
      END IF;
      FETCH my_curs INTO my_record;
    END LOOP;

     CLOSE my_curs;
     RETURN counter;
END;
$BODY$ LANGUAGE plpgsql;
#+end_src
*** Esempio di cursore parametrico
#+begin_src sql
CREATE OR REPLACE FUNCTION do_cursor()
RETURNS int AS $BODY$
DECLARE
        counter int := 0;
        my_curs CURSOR (s_eta int)
             FOR SELECT * FROM persona
                 WHERE eta >= s_eta;
        my_record persona%rowtype;
BEGIN
        OPEN my_curs( 18 );
        FETCH my_curs INTO my_record;
        WHILE FOUND
        LOOP
          counter := counter + 1;
          FETCH my_curs INTO my_record;
        END LOOP;

     CLOSE my_curs;
     RETURN counter;
END; $BODY$ LANGUAGE plpgsql;
#+end_src
*** Esempio di cursore unbound
#+begin_src sql
CREATE OR REPLACE FUNCTION do_cursor()
RETURNS int AS $BODY$
DECLARE
        counter int := 0;
        my_curs refcursor;
        my_record persona%rowtype;
BEGIN
        OPEN my_curs FOR
            SELECT * FROM persona
            WHERE eta >= 18;
        FETCH my_curs INTO my_record;
        WHILE FOUND
        LOOP
          counter := counter + 1;
          FETCH my_curs INTO my_record;
        END LOOP;

     CLOSE my_curs;
     RETURN counter;
END;
$BODY$ LANGUAGE plpgsql;
#+end_src
*** Ciclo "automatico" su cursore
Invece che il workflow ~OPEN~, ~FETCH~, ~LOOP~, ~CLOSE~ si può usare
il ciclo ~FOR~ che riduce le operazioni necessaire al solo ~LOOP~.

*Con ~FOR~ non si usa ~OPEN~, ~CLOSE~, ~FETCH~*!
*** Esempio di ciclo "automatico" su cursore
#+begin_src sql
CREATE OR REPLACE FUNCTION do_cursor()
RETURNS int AS $BODY$
DECLARE
        counter int := 0;
        my_curs CURSOR FOR
          SELECT * FROM persona
          WHERE eta >= 18;
        my_record persona%rowtype;
BEGIN
   FOR my_record IN my_curs
   LOOP
     counter := counter + 1;
   END LOOP;
  RETURN counter;
END; $BODY$ LANGUAGE plpgsql;
#+end_src
*** Capire FETCH
L'istruzione ~FETCH~ permette di specificare la direzione e il posizionamento assoluto o relativo.
La direzione viene specificata con ~FORWARD~ (default) o ~BACKWARD~.
Il posizionamento viene specificato con ~FIRST~, ~LAST~, ~ABSOLUTE n~ e ~RELATIVE n~.
*** Esempio di spostamento con FETCH: lettura all'indietro
#+begin_src sql
     OPEN my_curs;
     FETCH LAST FROM my_curs INTO my_record;
     WHILE FOUND
     LOOP
        IF my_record.eta >= 18 THEN
          counter := counter + 1;
        END IF;
        FETCH BACKWARD FROM my_curs INTO my_record;
     END LOOP;
     CLOSE my_curs;
#+end_src
*** Esempio di spostamento con FETCH: lettura all'indietro ogni due record
#+begin_src sql
     OPEN my_curs;
     FETCH LAST FROM my_curs INTO my_record;
     WHILE FOUND
     LOOP
        IF my_record.eta >= 18 THEN
          counter := counter + 1;
        END IF;
        FETCH RELATIVE -2 FROM my_curs INTO my_record;
     END LOOP;
     CLOSE my_curs;
#+end_src
*** UPDATE/DELETE FOR CURRENT
E' possibile eseguire un aggiornamento/cancellazione di una tupla su cui è posizionato il cursore.
La sintassi è ~UPDATE <table> SET <cols> WHERE CURRENT OF <cursor>~ o nel caso
di una cancellazione ~DELETE FROM <table> WHERE CURRENT OF <cursor>~.

#+begin_src sql
 OPEN my_curs;
  FETCH LAST FROM my_curs INTO my_record;
  WHILE FOUND
  LOOP
     IF my_record.eta >= 18 THEN
       counter := counter + 1;
     ELSE
       UPDATE persona set valid = false
            WHERE CURRENT OF my_curs;
     END IF;
     FETCH RELATIVE -2 FROM my_curs INTO my_record;
  END LOOP;
  CLOSE my_curs;
#+end_src
* Triggers
** Triggers DML
*** Introduzione ai triggers
   PostgreSQL supporta (da sempre) i trigger a livello di /statement/ o /tupla/
   sia per esecuzione prima (before) o dopo (after). Sulle viste agiscono
   i trigger /INSTEAD OF/.

   In PostgreSQL i trigger vengono definiti con un workflow ben definito:
   1. definire una funzione (tipicamente in ~plpgsql~) che *non accetta alcun
      argomento e ritorna un valore di tipo ~trigger~*;
   2. si /aggancia/ la funzione ad un evento scatenato su una tabella (tramite
      ~CREATE TRIGGER~).
*** Tipologia di trigger
I trigger possono essere eseguiti per ~statment~ o per ~riga~.
Nel caso di esecuzione a livello di statement il valore di ritorno del trigger
è ignorato (~NULL~), nel caso di esecuzione per riga il valore di ritorno
può essere ~NULL~ per indicare che l'oeprazione deve abortire o ritornare una
tupla (~NEW~, ~OLD~) per inserimento/modifica.

*** Tiplogia di trigger (riassunto)
   | Statement SQL                | Quando       | A livello di                                   |
   |------------------------------+--------------+------------------------------------------------|
   | ~INSERT~, ~UPDATE~, ~DELETE~ | /BEFORE/     | *tupla* su tabelle e FK                        |
   |                              | /AFTER/      | *tupla* su tabelle e FK                        |
   |------------------------------+--------------+------------------------------------------------|
   | ~INSERT~, ~UPDATE~, ~DELETE~ | /BEFORE/     | *statement* su tabelle (anche esterne) e viste |
   |                              | /AFTER/      | *statement* su tabelle (anche esterne) e viste |
   |------------------------------+--------------+------------------------------------------------|
   | ~TRUNCATE~                   | /BEFORE/     | *statement* su tabelle                         |
   |                              | /AFTER/      | *statement* su tabelle                         |
   |------------------------------+--------------+------------------------------------------------|
   | ~INSERT~, ~UPDATE~, ~DELETE~ | /INSTEAD OF/ | *tupla* su vista                               |
   |------------------------------+--------------+------------------------------------------------|

*** Esecuzione dei trigger
   I trigger sono eseguiti in ordine alfabetico (per tipologia di evento).

   I trigger ~BEFORE~ vengono eseguiti *prima del controllo delle constraint*, analogamente
   i trigger ~AFTER~ dopo l'esecuzione e quindi *dopo il controllo delle constraint*.

   I trigger vedono sempre la tupla di uscita ~NEW~ (quella che verrà /memorizzata/) e se sono
   per update anche quella di ingresso ~OLD~ (quella che si sta aggiornando).

   Il tipo di  operazione che ha fatto scattare il trigger è disponibile tramite la stringa ~TR_OP~, il
   numero di argomenti del trigger tramite ~TG_NARGS~ e i singoli argomenti nell'array di stringhe
   ~TG_ARGV~.

*** Esempio di trigger: descrizione
   Si vuole creare un semplice trigger che, al momento di inserimento o aggiornamento di una tupla
   della tabella ~persona~, controlli che l'età inserita sia coerente con quella del relativo
   codice fiscale e la "auto-corregga" calcolandola dall'anno attuale.

*** Esempio di trigger: funzione
#+begin_src sql
CREATE OR REPLACE FUNCTION tr_check_eta()
RETURNS TRIGGER
AS $BODY$
DECLARE
        current_eta integer;
        current_year integer;
BEGIN
  IF NEW.codice_fiscale IS NOT NULL THEN
       current_eta  = to_number(
                       substring( NEW.codice_fiscale FROM 7 FOR 2 ),
                      '99' );
       current_year = to_number( to_char( current_date, 'YY' ),
                      '99' );
       IF current_year < current_eta THEN
          current_eta = current_year + 100 - current_eta;
       END IF;
  END IF;
#+end_src

*** Esempio di trigger: funzione (2)
#+begin_src sql
  IF TG_OP = 'INSERT' THEN
       NEW.eta = current_eta;
       RAISE INFO 'Calcolo eta'' INSERT = %', current_eta;
       RETURN NEW;
   END IF;

  IF TG_OP = 'UPDATE' THEN
     IF OLD.eta > NEW.eta OR NEW.eta <= 0 THEN
        RAISE INFO 'Aggiusto eta'' UPDATE da % a %', OLD.eta, current_eta;
        NEW.eta = current_eta;
     END IF;
  END IF;

END;
$BODY$
LANGUAGE plpgsql VOLATILE;
#+end_src

*** Esempio di trigger: aggancio alla tabella
#+begin_src sql
> CREATE TRIGGER tr_persona_eta
  BEFORE INSERT OR UPDATE
  ON persona
  FOR EACH ROW
  EXECUTE PROCEDURE tr_check_eta();
#+end_src

*** Esempio di trigger: esecuzione
#+begin_src sql
> INSERT INTO persona( nome, cognome, codice_fiscale )
VALUES( 'Luca', 'Ferrari', 'FRRLCU78L19F257B' );
INFO:  Calcolo eta' INSERT = 39

> UPDATE persona SET eta = 10 WHERE codice_fiscale = 'FRRLCU78L19F257B';
INFO:  Aggiusto eta' UPDATE da 39 a 39
#+end_src

*** Esempio di trigger: agganciarlo a una colonna
   Il trigger di esempio non dovrebbe scattare per ogni ~UPDATE~ incondizionato, ma solo
   per gli ~UPDATE~ che coinvolgono la colonna ~eta~ o ~codice_fiscale~.
   E' possibile specificare a quali colonne il trigger deve essere agganciato:

#+begin_src sql
>  DROP TRIGGER tr_persona_eta ON persona;
> CREATE TRIGGER tr_persona_eta
  BEFORE INSERT OR UPDATE OF eta, codice_fiscale
  ON persona
  FOR EACH ROW
  EXECUTE PROCEDURE tr_check_eta();
#+end_src

*** Esempio di trigger: aggancio a una colonna (2)
   Il trigger scatta ora solo per gli aggiornamenti delle colonne specificate:
#+begin_src sql
> UPDATE persona SET eta = 10 WHERE codice_fiscale = 'FRRLCU78L19F257B';
INFO:  Aggiusto eta' UPDATE da 39 a 39

> UPDATE persona SET nome = 'LUCA' WHERE codice_fiscale = 'FRRLCU78L19F257B';
-- non è scattato il trigger!
#+end_src

*** Trigger parametrici
   E' possibile passare dei parametri alla funzione di un trigger, tali
   parametri saranno visibili tramite l'array ~TG_ARGV~.
   *I parametri sono letterali e convertiti sempre a stringa*.

*** Esempio di trigger parametrico: funzione con parametro
La funzione dell'esempio precedente può essere modificata per accettare
l'età da usare come default:

#+begin_src sql
CREATE OR REPLACE FUNCTION tr_check_eta()
RETURNS TRIGGER
AS $BODY$
DECLARE
        current_eta integer;
        current_year integer;
BEGIN
        IF TG_NARGS > 0 THEN
           current_eta := to_number( TG_ARGV[ 0 ], '99' );
        ELSE
           current_eta := -1;
        END IF;
...
#+end_src

*** Esempio di trigger parametrico: aggancio
#+begin_src sql
> CREATE TRIGGER tr_persona_eta
  BEFORE INSERT OR UPDATE OF eta, codice_fiscale
  ON persona
  FOR EACH ROW EXECUTE PROCEDURE tr_check_eta( 10 );

> UPDATE persona SET eta = 10, codice_fiscale = NULL
  WHERE codice_fiscale = 'FRRLCU78L19F257B';
INFO:  Aggiusto eta' UPDATE da 39 a 10
#+end_src
** Tiggers DDL
*** Introduzione ai trigger DDL
PostgreSQL permette di definire dei trigger per /eventi/ di DDL, ovvero
~CREATE~, ~DROP~, ~ALTER~, ~COMMENT~, ~GRANT~, ~REVOKE~.
Gli istanti in cui si possono intercettare gli eventi sono:
- ~ddl_command_start~: appena il comando viene avviato, senza alcun controllo
  sull'esistenza dell'oggetto a cui si applica;
- ~ddl_command_end~: appena il comando è finito (quindi i cataloghi di sistema
  sono stati aggiornati ma non ancora consolidati);
- ~table_rewrite~: si effettua un ~ALTER [TABLE | TYPE]~ su una tabella;
- ~sql_drop~: il comando ~DROP~ ha rimosso dal catalogo di sistema degli oggetti.

*Bisogna essere superutenti!*
*** Creazione di un event trigger
Le regole sono simili a quelle di un trigger normale:
1. si crea una funzione che deve ritornare un tipo ~event_trigger~. *Il valore di ritorno è solo un marcaposto, questi trigger non ritornano alcun valore!*
2. si aggancia il trigger all'evento con ~CREATE EVENT TRIGGER~;
3. si possono usare alcune funzioni di utilità per scoprire /cosa/ sta accadendo e cosa ha /scatenato/ il trigger (non esistono
   al momento variabili speciali da interrogare ma solo funzioni di catalogo).
*** Dati interni di un event trigger
Ci sono delle funzioni speciali che ritornano delle tuple contenenti le informazioni
di come un trigger è stato invocato:
- ~pg_event_trigger_ddl_commands()~ per ~ddl_command_start~ e ~ddl_command_stop~;
- ~pg_event_trigger_dropped_objects()~ per ~sql_drop~;
- ~pg_event_trigger_table_rewrite_oid()~ per ~table_rewrite~.
*** Esempio di event trigger
#+begin_src sql
CREATE OR REPLACE FUNCTION ddl_start_end()
RETURNS EVENT_TRIGGER AS
$BODY$
DECLARE
        command record;
BEGIN
   RAISE INFO 'event trigger fired!';
   FOR command IN SELECT * FROM pg_event_trigger_ddl_commands()
   LOOP
           RAISE INFO 'Comando % su %',
                 command.command_tag,
                 command.object_identity;
   END LOOP;
END; $BODY$
LANGUAGE plpgsql;
#+end_src
*** Esempio di esecuzione con event trigger
#+begin_src sql
# CREATE EVENT TRIGGER tr_start_end
  ON ddl_command_start
  EXECUTE PROCEDURE ddl_start_end();

# ALTER TABLE testddl ADD COLUMN foo int;
INFO:  event trigger fired!
INFO:  Comando ALTER TABLE su public.testddl
ALTER TABLE
#+end_src
*** Esempio di even trigger (drop)
#+begin_src sql
CREATE OR REPLACE FUNCTION ddl_drop_fn()
RETURNS EVENT_TRIGGER AS $BODY$
DECLARE
        dropping record;
BEGIN
        RAISE INFO 'event trigger fired!';
        FOR dropping IN SELECT * FROM pg_event_trigger_dropped_objects()
        LOOP
                RAISE INFO 'drop % di %',
                      tg_tag, -- cosa si droppa?
                      dropping.object_identity;
        END LOOP;
END; $BODY$ LANGUAGE plpgsql;
#+end_src

*** Esecuzione di event trigger (drop)
#+begin_src sql
# CREATE EVENT TRIGGER tr_drop
  ON sql_drop
  EXECUTE PROCEDURE ddl_drop_fn();
#+end_src
*** Esecuzione di event trigger (drop)
#+begin_src sql
# DROP TABLE testddl;
INFO:  event trigger fired! -- ddl_command_start
INFO:  drop DROP TABLE di public.testddl
INFO:  drop DROP TABLE di testddl_pkey on public.testddl
INFO:  drop DROP TABLE di public.testddl_pkey
INFO:  drop DROP TABLE di public.testddl_pk_seq
INFO:  drop DROP TABLE di public.testddl_pk_seq
INFO:  drop DROP TABLE di for public.testddl.pk
INFO:  drop DROP TABLE di public.testddl
INFO:  drop DROP TABLE di public.testddl[]
INFO:  drop DROP TABLE di pg_toast.pg_toast_16508
INFO:  drop DROP TABLE di pg_toast.pg_toast_16508_index
INFO:  drop DROP TABLE di pg_toast.pg_toast_16508
INFO:  event trigger fired! -- ddl_command_end
#+end_src

* Grant/Revoke
** Grant in PostgreSQL
PostgreSQL distingue due tipi principali di ~GRANT~ e conseguentemente di ~REVOKE~:
- su un oggetto di database (es. tabella), nel qual caso anche a livello di colonna;
- su un ruolo (ovvero gestione dei gruppi).

La parola ~PUBLIC~ indica tutti gli utenti, mentre la parola chiave ~ALL~ indica tutti i
tipi di permessi.
Per agire a livello globale (/pericoloso!/):
#+begin_src sql
> REVOKE ALL ON <oggetto> FROM PUBLIC;
> GRANT ALL ON <oggetto> TO PUBLIC;
#+end_src
** Grant di grant
Il proprietario di un oggetto ha per definizione tutti i permessi
sull'oggetto che ha creato.

Chi possiede il permesso ~GRANT~ può concedere lo stesso permesso
ad altri ruoli: si può quindi non solo abitare agli oggetti, ma anche
alle abilitazioni stesse verso altri utenti.
** Esempio di permessi di colonna
#+begin_src sql
# REVOKE ALL ON software FROM PUBLIC;
# GRANT SELECT(name) ON software TO luca;
#+end_src
e come utente ~luca~:
#+begin_src sql
> SELECT name FROM software; --OK!
> SELECT name, versions FROM software;
ERROR:  permission denied for relation software
#+end_src
** OWNED
Esistono comandi appositi per /passare/ un oggetto da un ruolo ad un altro e per
eliminare tutti gli oggetti posseduti da un determinato ruolo. La parola chiave
~CURRENT_USER~ identifica l'utente corrente.
#+begin_src sql
> REASSIGN OWNED BY CURRENT_USER TO dba;
-- drop altri oggetti
> DROP OWNED BY dismissed;
#+end_src

*Tipicamente si usano questi comandi prima della cancellazione di un ruolo!*
** Row Level Security
E' possibile specificare, tabella per tabella, una sicurezza a livello
di tupla, denominata /Row Level Security/.

La Row Level Security si basa su delle /policy/ che devono discriminare quali dati
mostrare/nascondere. Se nessuna policy viene creata si usa un default di /deny all/.
** Row Level Security: esempio
#+begin_src sql
> CREATE POLICY view_maggiorenni
  ON persona
  FOR SELECT  -- quale statement?
  TO PUBLIC   -- quale ruolo ?
  USING  (eta >= 18); -- condizione di SELECT

> ALTER TABLE persona ENABLE ROW LEVEL SECURITY;
#+end_src
e come altro utente si vedranno solo le tuple che soddisfano ~USING~.
** Row Level Security: spiegazione
Anzitutto l'utente che effettua lo statement deve avere le opportune ~GRANT~.
*Il proprietario dell'oggetto non è soggetto alle policy*.

Nel caso di statement ~SELECT~ la condizione è data da ~USING~, nel caso di
~INSERT~ o ~UPDATE~ da ~CHECK~, e si può combinare tutto quanto assieme:

#+begin_src sql
> CREATE POLICY handle_maggiorenni
  ON persona
  FOR ALL  -- SELECT, UPDATE, DELETE, INSERT
  TO PUBLIC   -- quale ruolo ?
  USING  (eta >= 18) -- condizione di SELECT
  WITH CHECK (eta >= 18); -- condizione DDL
#+end_src
** Row Level Security: un altro esempio
Tipicamente questo meccanismo viene usato per nascondere le tuple
di altri utenti:

#+begin_src sql
> CREATE POLICY handle_my_tuples
  ON usernames
  FOR ALL  -- SELECT, UPDATE, DELETE, INSERT
  TO PUBLIC   -- quale ruolo ?
  USING  (usernam >= CURRENT_USER) -- condizione di SELECT
  WITH CHECK (usernam >= CURRENT_USER); -- condizione DDL
#+end_src

* Viste & Rules
** Viste
*** Tipologie di viste
Esistono due tipi principali di viste:
- /viste dinamiche/: effettuano la query al momento propagandola alle tabelle
  di definizione della vista;
- /materializzate/: contengono una versione memorizzata dei dati prelevati
  dalle tabelle sottostanti e necessitano di essere aggiornata (refresh).
*** Viste dinamiche
Si definisce la vista attraverso una query (che può includere join, order-by, ecc):
#+begin_src sql
> CREATE VIEW vw_persona
  AS
  SELECT upper( cognome ), nome, eta
  FROM persona
  ORDER BY cognome, nome;

> SELECT * FROM vw_persona;
#+end_src
*** Viste materializzate
Si utilizza il comando ~CREATE MATERIALIZED VIEW~ specificando se prelevare subito i dati (~WITH DATA~)
o no (~WITH NO DATA~). In quest'ultimo caso la vista deve prima essere sottoposta a ~REFRESH~ per essere utilizzata.
#+begin_src sql
> CREATE MATERIALIZED VIEW vw_m_persona
  AS SELECT upper( cognome ), nome
  FROM persona
  ORDER BY cognome, eta
  WITH NO DATA;

 > SELECT * FROM vw_m_persona;
ERROR:  materialized view "vw_m_persona"
        has not been populated
#+end_src

*** Popolare e fare refresh di una vista materializzata
Il comando ~REFRESH MATERIALIZED VIEW~ viene usato per popolare la vista materializzata.
Sostanzialmente il comando effettua:
- un ~TRUNCATE~ della vista (quindi i dati precedenti sono persi);
- un /lock/ della vista (che quindi non può essere usata fino a che il refresh non è terminato;
- una esecuzione della query di definizione della vista per popolarla con i dati.

Per evitare il /lock/ si può usare ~CONCURRENTLY~, così che la vista possa essere letta mentre viene
popolata.
Se si specifica ~WITH NO DATA~ la query non viene eseguita e la vista ritorna ad uno stato
non usabile fino al prossimo refresh.
*** Popolare (e ripopolare) la vista materializzata
#+begin_src sql
> REFRESH MATERIALIZED VIEW vw_m_persona;
-- equivalente a
> REFRESH MATERIALIZED VIEW vw_m_persona WITH DATA;
#+end_src
*** Popolare una vista materializzata senza lock
Per usare ~CONCURRENTLY~ nel refresh si deve avere un indice /unique/ su almeno una colonna
della vista, e non lo si può usare per il primo popolamento della vista.
#+begin_src sql
> CREATE UNIQUE INDEX idx_vw_m_persona_nome
  ON vw_m_persona( nome );

> REFRESH MATERIALIZED
  VIEW CONCURRENTLY vw_m_persona
  WITH DATA;
#+end_src

** Rules
*** Introduzione alle rules
Le *rules* sono definite anche *query rewrite system*.
Le rules consentono la riscrittura al volo delle query (anticipando anche i trigger)
e quindi di rimbalzare una query da un oggetto ad un altro o espandere una query
in piu' di una.

*A differenza di un trigger, una rule può intercettare una ~SELECT~!*
*** Parametri di una rule
Una rule deve specificare:
- un /evento/ ovvero ~SELECT~, ~INSERT~, ~UPDATE~, ~DELETE~;
- la tabella a cui l'evento si applica (ossia su quale tabella il comando è stato eseguito);
- una eventuale /condizione/ che può referenziare ~OLD~ e ~NEW~ come alias delle tabelle originali
  e verso cui rimbalzare la query;
- il /comando/ da eseguire come ~INSTEAD~ o ~ALSO~.

*Le viste sono realizzate come una rule ~INSTEAD~!*
*** Esempio di una rule: DELETE
#+begin_src sql
> CREATE OR REPLACE RULE r_delete_persona
  AS ON DELETE TO persona
  DO INSTEAD
    UPDATE persona
    SET valid = false
    WHERE OLD.pk = pk;
#+end_src
*** Esempio di rule: INSERT
#+begin_src sql
 > CREATE OR REPLACE RULE r_insert_persona
   AS ON INSERT
   TO persona
   DO ALSO
    INSERT INTO log( message )
    VALUES ( 'Inserimento/aggiornamento tupla '
             || NEW.cognome || ' '
             || NEW.nome );
#+end_src
*** Rules "_RETURN"
La rule per una select è speciale e viene denominata ~"_RETURN"~ (ce ne può essere solo una)
e deve essere eseguita su una tabella vuota. E' il modello con il quale PostgreSQL realizza
le viste dinamiche.

Il workflow è:
1. creare una tabella *vuota* con le stesse colonne della tabella finale;
2. definire la rule ~"_RETURN"~ con ~DO INSTEAD~ e ~SELECT~ sulla tabella corretta.

*Nel momento in cui ~"_RETURN"~ viene definita la tabella viene catalogata come vista!**

*** Esempio di rule: "_RETURN"
#+begin_src sql
-- CREATE TABLE maggiorenni() INHERITS( persona );
> CREATE TABLE maggiorenni( LIKE persona );
> CREATE OR REPLACE RULE "_RETURN"
  AS ON SELECT TO maggiorenni
  DO INSTEAD
    SELECT * FROM persona
    WHERE eta >= 18;
#+end_src

*** Esempio di rule: UPDATE
E' possibile /bloccare/ una tabella con una rule ~DO NOTHING~.
#+begin_src sql
> CREATE OR REPLACE RULE r_update_persona
  AS ON update
  TO persona
  DO INSTEAD NOTHING;
#+end_src
* TODO Window Functions & CTE
** Window Functions
** Common Table Expressions
* TODO Foreign Data Wrapper
* TODO Extensions
* Configurazione del Server
** postgresql.conf
Il file principale di configurazione è ~postgresql.conf~, contenuto solitamente
in ~$PGDATA~ (alcune distribuzioni lo inseriscono nell'albero ~/etc~).

Il file contiene dei parametri in formato ~chiave = valore~ con valori
booleani (~on~, ~off~), numerici, stringa.

Il carattere ~#~ identifica un commento.

** Vedere la configurazione a run-time
La vista speciale ~pg_settings~ consente di valutare ogni singolo parametro
con i relativi valori di default, minimo, massimo, descrizione, ecc.

#+begin_src sql
# SELECT name, setting, min_val, max_val, unit,
  sourcefile, sourceline,
  short_desc,
  pending_restart
  FROM pg_settings
  WHERE name like 'shared_buffer%';

-[ RECORD 1 ]---+-------------------------------------------------------------
name            | shared_buffers
setting         | 16384
min_val         | 16
max_val         | 1073741823
unit            | 8kB
sourcefile      | /mnt/data1/pgdata/postgresql.conf
sourceline      | 113
short_desc      | Sets the number of shared memory buffers used by the server.
pending_restart | f
#+end_src
** Vedere la configurazione a run-time: note su pg_settings
I dati sul file di configurazione (~sourcefile~, ~sourceline~) non sono visualizzati per utenti
non amministratori.
Il flag ~pending_restart~ indica se il valore è stato modificato nel file di configurazione
ma non ancora /riletto/ dal sistema (ossia occorre un riavvio).
Il valore ~unit~ indica l'unità di misura del valore corrente ~setting~, nell'esempio
di cui sopra il valore è impostato a:
         ~8 kB * 16384 = 131072 kB = 128 MB~
corrispondente al seguente valore nel file di configurazione:
#+begin_src sh
% sudo grep shared_buffers /mnt/data1/pgdata/postgresql.conf                                                             ~
shared_buffers = 128MB
#+end_src

* Write Ahead Log
** Introduzione ai WAL
I *Write Ahead Log* sono un componente fondamentale per il funzionamento del database.

L'idea dietro ai ~WAL~ è questa:
- ogni volta che una transazione effettua un ~COMMIT~ i dati *NON* vengono scritti
  immediatamente su disco, per ottimizzare l'I/O.
- il ~COMMIT~ viene registrato nei *WAL* che contengono /le differenze/ (binarie)
  dei dati;
- il WAL viene *reso persistente su disco*.

Siccome il WAL viene usato in modo *sequenziale* l'impatto di I/O è basso e si garantisce
in questo modo di avere uno strato di persistenza.
** Utilizzo dei WAL: crash recovery
I WAL vengono usati principalmente in caso di crash: se il database riparte a seguito di
un crash, *il sistema ripercorre i segmenti di WAL e riapplica le modifiche ai dati*.

Durante questa fase di /recovery/ il database si trova in uno stato /inconsistente/, i WAL
garantiscono appunto l'allineamento dei dati a quanto si trova su memoria persistente
e quindi la /consistenza/ del database.
** Sicurezza dei WAL
I segmenti di WAL sono *fondamentali* per il funzionamento del database, e quindi occorrono alcuni
accorgimenti per assicurare un buon funzionamento dei WAL:
1. la dimensione dei log è fissa (16MB), così come il loro numero (con qualche piccola variazione);
   questo garantisce che lo spazio di archiviazione dei WAL non si riempirà mai!
2. ogni dato nel WAL viene memorizzato come /record/ in linked list al record precedente; questo
   permette di risalire all'ultimo record "buono" nella catena dei segmenti;
3. ogni record inserito nei segmenti ha un checksum CRC32 che ne garantisce l'integrità;
4. i /signals/ sono interrotti durante la scrittura dei WAL, così da garantire che il processo
   non sia interrotto per errore.
** Dove sono i WAL
PostgreSQL memorizza il *Write Ahead Log* nella directory ~pg_xlog~.
*Ogni /segmento/ è di 16 MB e ha un nome in esadecimale*.
#+begin_src sh
% sudo  ls -lh /mnt/data1/pgdata/pg_xlog                                                                                 ~
 16M Oct 27 10:21 000000010000000000000082
 16M Oct 18 10:32 000000010000000000000083
 16M Oct 18 10:32 000000010000000000000084
#+end_src
** Checkpoint
*Un checkpoint è un ponto di consolidamento fra WAL e dati fisici.*

Il sistema non può registrare modifiche indefinitamente nei WAL:
- i segmenti aumenterebbe all'infinito;
- il tempo di recovery (ripercorrere i WAL) aumenterebbe di conseguenza.

Per evitare tali problemi si definiscono degli *istanti periodici detti /checkpoint/*
ove PostgreSQL si preoccupa di consolidare i dati fisici su disco, scartando quindi i
WAL precedenti quel checkpoint.

**** Crash recovery                                            :B_definition:
Di fatto un crash recovery *ripercorre i segmenti di WAL dall'ultimo checkpoint conosciuto*!
**** End of block                                           :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:
** LSN
Come si fa a sapere quali pagine dati sono /sicure/ per essere scaricate su memoria
persistente?
La risposta è *LSN: Log Sequence Number*.

Ogni pagina dati contiene un numero LSN che indica quale segmento di log contiene le modifiche
a quella pagina. 
*Una pagina dati non può quindi essere resa persistente se i log fino a quel ~lsn~ non sono stati a loro volta resi persistenti*.
** Regolare i checkpoint
I checkpoint sono configurabili attraverso due parametri:
- ~max_wal_size~ indica quanti segmenti (da 16MB l'uno) sono tollerati fra due checkpoint consecutivi;
- ~checkpoint_timeout~ indica quanti secondi sono tollerati fra due checkpoint consecutivi.

Un checkpoint viene forzato aumaticamente ogni volta che si raggiunge una quantità di /dati sporchi/
pari a ~max_wal_size * 16 MB~ o dopo che ~checkpoint_timeout~ secondi sono trascorsi.
*La prima condizione che si verifica fa scattare un checkpoint*!
** Checkpoint Throttling
Siccome al raggiungimento di un /checkpoint/ il database deve forzare un /flush/ di tutte le pagine dati "sporche",
il sottosistema di I/O viene messo a dura prova.

Per evitare dei colli di bottiglia è stato introdotto un parametro che consente di stabilire entro quanto tempo
il checkpoint deve essere completato: ~checkpoint_completion_target~. Il suo valore è compreso fra 0 e 1 e indica
la frazione di tempo (~checkpoint_timeout~) da usare per completare il checkpoint stesso.
** Comprendere ~checkpoint_completion_target~
L'idea di ~checkpoint_completion_target~ è di *rallentare* l'attività di I/O di scarto delle pagine dati sporche.
In sostanza le pagine dati devono essere tutte scritte entro
   ~checkpoint_completion_target * checkpoint_timeout~ secondi
che con la configurazione di default divente:
  ~0.5 * 5 min = 2.5 min~
e quindi il sistema ha circa 2.5 minuti per completare l'I/O.
** Non forzare la mano a ~checkpoint_completion_target~
Il parametro offre una indicazione di come verrà /sparso/ l'I/O nel tempo, non è una stima esatta.
Ne consegue che valori prossimi a 1 rallenteranno le scritture su disco causando I/O costante (bassa banda), di contro
valori prossimi a 0 forzano un picco di I/O rapido (alta banda). Il rischio è che valori prossimi ad 1 producano
un /inseguimento/ dei checkpoint continuo.
*Il valore corretto dipende dal carico di lavoro!*
** Checkpoint manuali
Un superutente può forzare un checkpoint immediato con il comando ~CHECKPOINT~.
Il comando è pensato per le fasi di archiviazione e recovery, difficilmente
è da usarsi nell'ultilizzo regolare del database.
** Quanti sono i WAL?
Stabilito che i segmenti di WAL sono /riciclati/ dopo un checkpoint, è possibile stimare
l'occupazione della directory ~pg_xlog~ che è pressoché costante nel tempo e vale:
#+begin_src sh
 ( 2 + checkpoint_completion_target ) * checkpoint_segments + 1.
#+end_src
ossia è dominata da ~checkpoint_segments~.
*Durante un uso intenso potrebbe capitare che il numero di segmenti aumenti oltre ~checkpoint_segments~*, ma
il sistema provvederà all'eliminazione del residuo una volta ripristinato l'ordine. e' quindi consigliato
mantenere una certa quota disco per consentire qualche segmento ulteriore a quanto calcolato sopra.
