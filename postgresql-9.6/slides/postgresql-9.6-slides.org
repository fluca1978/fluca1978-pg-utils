#+TITLE:     PostgreSQL 9.6
#+AUTHOR:    Luca Ferrari
#+EMAIL:     fluca1978@gmail.com
#+DATE:      <2017-08-25 ven>
#+LANGUAGE:  it

#+OPTIONS:   H:3 num:t toc:t \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+INFOJS_OPT: view:nil toc:nil ltoc:t mouse:underline buttons:0 path:http://orgmode.org/org-info.js
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+LINK_UP:
#+LINK_HOME:

#+startup: beamer
#+LaTeX_CLASS: beamer
#+latex_header: \mode<beamer>{\usetheme{Madrid}}
#+latex_header: \AtBeginSection[]{\begin{frame}<beamer>\frametitle{Outline}\tableofcontents[currentsection]\end{frame}}

#+BEAMER_HEADER: \subtitle{il database Open Source piu' avanzato del pianeta}
#+BEAMER_HEADER: \institute[ITPUG]{Italian PostgreSQL Users' Group (ITPUG)\\\url{http://www.itpug.org}}
#+BEAMER_HEADER: \institute[fluca1978]{fluca1978\\\url{https://fluca1978.github.io}}
#+BEAMER_HEADER: \titlegraphic{\includegraphics[height=3cm]{./images/logo.png}}




* Introduzione
** Il progetto PostgreSQL
*** Cos'è?
   PostgreSQL è un *Object Relational Database Management System* (ORDBMS).

**** O-RDBMS                                                   :B_definition:
   *Object* non è da intendersi relativamente al paradigma /OOP/ quanto al fatto
   che un utente /puo' estendere il database con i propri "oggetti"/.
**** End of block                                           :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:

Ad esempio, PostgreSQL non supporta i /query-hints/ tanto famosi in altri sistemi
commerciali: per gli sviluppatori questa funzionalità non ha senso e non è mai stata
(e mai verrà) implementata.

#+begin_quote
Approccio simile a quello di OpenBSD!
#+end_quote

   PostgreSQL è il naturale discendente di *Ingres* (dopo, /post/, gres), un database
   accademico/sperimentale inventato dal prof. Michael Stonebreaker e commercializzato
   indicativamente nello stesso spazio temporale di Oracle (1989 circa).

   Tutto inizia alla Berkely University of California.

*** Quand'è?

   | Nome          | Anno di produzione | Note                             |
   |---------------+--------------------+----------------------------------|
   | POSTGRES      |               1989 | successore di Ingres             |
   | POSTGRES95    |               1994 | viene aggiunto un interprete SQL |
   | Postgres 1    |               1995 |                                  |
   | PostgreSQL 6  |               1997 |                                  |
   | PostgreSQL 7  |               2000 | foreign keys, join e no-crash    |
   | PostgreSQL 8  |               2005 | port Windows nativo              |
   | PostgreSQL 9  |               2010 | Replication                      |
   | PostgreSQL 10 |               2017 | ...                              |

   #+begin_quotation
The copyright of Postgres 1.0 has been loosened to be freely modifiable
and modifiable for any purpose.  Please read the COPYRIGHT file.
Thanks to Professor Michael Stonebraker for making this possible.
--- Release 1.0
#+end_quotation

*** Di chi è?
   PostgreSQL non è guidato da nessun vendor e di conseguenza _non ha una
   lista di clienti da soddisfare_. Questo significa che
   una feature sarà implementata in PostgreSQL solo se ha senso dal punto di
   vista /tecnico/ e /scientifico/.

**** Approccio culturale                                       :B_definition:
    PostgreSQL is a *non-commercial, all volunteer, free software project*,
    and as such *there is no formal list of feature requirements*
    required for development.
    We really do follow the mantra of
    letting developers scratch their own itches.
**** End of block                                           :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:
Ad esempio, PostgreSQL non supporta i /query-hints/ tanto famosi in altri sistemi
commerciali: per gli sviluppatori questa funzionalità non ha senso e non è mai stata
(e mai verrà) implementata.

#+begin_quote
Approccio simile a quello di OpenBSD!
#+end_quote

*** Per chi è?
Licenza *BSD* (anche per il logo):


#+begin_src
PostgreSQL Database Management System
(formerly known as Postgres, then as Postgres95)

Portions Copyright (c) 1996-2017, PostgreSQL Global Development Group

Portions Copyright (c) 1994, The Regents of the University of California

Permission to use, copy, modify, and distribute this software and its
documentation for any purpose, without fee, and without a written agreement
is hereby granted, provided that the above copyright notice and this
paragraph and the following two paragraphs appear in all copies.
#+end_src

*** Quanto costa?
   Il progetto è /Open Source/ ed è /Free/.

   Esistono diverse varianti commerciali che si differenziano dalla versione
   /mainstream/ per funzionalità (es. replica multi-master, query multi-nodo, ecc.)
   e per un /costo/ che dipende direttamente dal vendor.

   Molti degli sviluppatori della versione mainstream sono in realtà _anche_ sviluppatori
   di un qualche vendor.

*** Qual'era?
   In PostgreSQL i numeri di versione */erano/* a tre cifre separati da punto:
   - */release brand/* (es. 7, no-crash, 8 MS Windows portability, 9 Replication)
   - */year release/*  (da quanti anni si ha questo brand)
   - */minor release/* (rilasciata circa ogni quattro mesi o in presenza di gravi
     problemi di sicurezza o consistenza)

**** Major version vs Minor Version                               :B_theorem:
    - *9.5*.1 # major version 9.5, minor version 1
      - 9.5.1 compatibile con 9.5.2, 9.5.3, ...
    - *9.6*.2 # major version 9.6, minor version 2
      - incompatibile con 9.5.x!

**** End of block                                           :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:
   Le prime due cifre rappresentavano una *major version* e quindi erano segnale di
   possibile incompatibilità.

*** Qual'é?
   Dalla versione 10 la numerazione è diventata a due sole cifre.

   La cifra prima del punto rappresenta la /major version/.

   *Questo rappresenta una incompatibilità semantica con il passato*: gli script
   che facevano affidamento alla versione devono modificare la propria logica!

   L'unico metodo affidabile è quello di considerare che ogni cifra viene
   usata con un formato ~printf(2)~ pari a ~%02d~ e che il numero
   dell'anno da ora in avanti è sempre zero.

   | Versione | Major | Minor | Internal |
   |----------+-------+-------+----------|
   |    9.5.1 |   9.5 |     1 |   090501 |
   |    9.6.4 |   9.6 |     4 |   090604 |
   |----------+-------+-------+----------|
   |     10.0 |    10 |     0 |   100000 |
   |     10.1 |    10 |     1 |   100001 |

*** Quanto dura?
   Ogni /major release/ di PostgreSQL viene manutenuta per *5 anni* dalla data di primo rilascio.
   Una volta che una release raggiunge la *End Of Life* nessun pacchetto binario sarà piu' rilasciato
   ma potrebbe essere aggiornato (in retrocompatibilità) l'albero dei sorgenti (a discrezione degli
   sviluppatori e senza alcuna garanzia).

   Ecco un esempio delle prossime "scadenze":

| Version | First release date  | 	EOL date       |
|---------+---------------------+------------------|
|     9.6 | 	September 2016 	 | September 2021   |
|     9.5 | 	January 2016 	   | January 2021     |
|     9.4 | 	December 2014 	  | December 2019    |
|     9.3 | 	September 2013 	 | September 2018   |
|     9.2 | 	September 2012 	 | *September 2017* |

*** Quanto è?
   E' difficile /spaventare/ una istanza PostgreSQL!

| Dato                        | Limite massimo                       |
|-----------------------------+--------------------------------------|
| Maximum Database Size	     | Unlimited                            |
| Maximum Table Size	        | 32 TB                                |
| Maximum Row Size	          | 1.6 TB                               |
| Maximum Field Size	        | 1 GB                                 |
| Maximum Rows per Table	    | Unlimited                            |
| Maximum Columns per Table	 | 250 - 1600 depending on column types |
| Maximum Indexes per Table	 | Unlimited                            |

*** Chi lo usa?

   Alcuni esempi:

#+ATTR_LATEX: :width 0.2\textwidth
 [[./images/debian.png]]
 [[./images/redhat.png]]
[[./images/cisco.png]]
[[./images/skype.png]]

*** Chi lo sviluppa?
   *Chiunque*, anche tu! Non esiste un /benevolent dictator/!

   Tre livelli principali di sviluppatori:
   1. *core team*: 5 membri storici che si occupano di gestire il ciclo di rilascio e tutte le questioni
      "spinose" (mancanza di consenso, disciplina, ecc)
      - Peter Eisentraut
      - Magnus Hagander
      - Tom Lane
      - Bruce Momjian
      - Dave Page
   2. *major contributors*: /sviluppatori fidati/ (commit access) che lavorano abitualmente alle funzionalità del
      progetto
   3. *contributor*: chiunque fornisca una patch, una proposta, una traduzione, ...


   - *hacker emeritus*: chi ha lavorato in passato al progetto con particolare successo
      (Josh Berkus, Marc G. Fournier, Thomas G. Lockhart, Vadim B. Mikheev, Jan Wieck)

*** Come si sviluppa?
   Si utilizza ~git~ (migrato da CVS intorno al 2009).

   #+begin_src sh
% git clone git://git.postgresql.org/git/postgresql.git

Cloning into 'postgresql'...
...
% du -hs postgresql
356M    postgresql
% git rev-list --all --count
59672
   #+end_src

   - Linguaggio di programmazione principale: ~C~, stile BSD (~style(9)~).
   - Strumenti di sviluppo ben noti: ~gcc~, ~gmake~, ~autoconf~, ecc.
   - Strumenti (anche Perl) ad-hoc per mantenere il codice: ~pgindent~, ~git_changelog~,
     ~make_ctags~, ecc.

*** Da quanto si sviluppa?
   Da molto tempo (oltre 30 anni), ma non si torna prima della versione 1.01 di *Postgres95*,
   ramo di sviluppo 6 del Postgres "attuale":

   #+begin_src sh
% git log `git rev-list --max-parents=0 HEAD`

commit d31084e9d1118b25fd16580d9d8c2924b5740dff
Author: Marc G. Fournier <scrappy@hub.org>
Date:   Tue Jul 9 06:22:35 1996 +0000

    Postgres95 1.01 Distribution - Virgin Sources
   #+end_src

** Concetti Generali
*** Terminologia
- Ogni istanza di PostgreSQL gestisce un *cluster*.

- Un cluster è formato da uno o piu' *database*, ogni database può essere a sua volta
  scomposto in uno o piu' *schema* (/namespace logico/),
  che a sua volta può contenere uno o piu' *oggetti* (/tabelle, trigger, indici, funzioni/, ...).
  Ogni *database* è totalmente isolato dall'altro.

- Ogni oggetto può appartenere ad uno e un solo *tablespace* (/spazio fisico/).

- Il *cluster* mantiene anche le informazioni relative agli utenti e ai permessi.
  Gli utenti vengono chiamati *ruoli* e rappresentano sia singole utenze che gruppi
  (quindi un ruolo può contenere altri ruoli).

In linea con la filosofia Unix, PostgreSQL vuole svolgere un compito solo nel miglior modo possibile: gestire
i dati. E' compito del DBA documentarsi e aggiungere le estensioni necessarie a seconda del caso d'uso (es. pooling).

*** Cluster di Database
Un singolo cluster quindi può gestire un albero di oggetti a granularità molto specifica:

  - /database 1/
    - /schema ~public~/ (default)
    - /schema 1/
      - /tabelle, trigger, indici/ -> /tablespace disco SSD/
      - /tabelle, trigger, indici/ -> /tablespace disco lento/
    - /schema 2/
      - /tabelle, trigger, indici/ -> /tablespace disco SSD/
      - /tabelle, trigger, indici/ -> /tablespace disco lento/
  - /database 2/
    - /schema ~public~/ (default)
    - /schema 1/
      - /tabelle, trigger, indici/ -> /tablespace disco SSD/
      - /tabelle, trigger, indici/ -> /tablespace disco lento/
    - /schema 2/
      - /tabelle, trigger, indici/ -> /tablespace disco SSD/
      - /tabelle, trigger, indici/ -> /tablespace disco lento/

*** Analogia tra Cluster e OS
L'isolamento e la gestione di un cluster ricorda molto quella di un sistema operativo:

| PostgreSQL                                | Unix                             |
|-------------------------------------------+----------------------------------|
| cluster                                   | OS                               |
| ruolo                                     | utente                           |
| tablespace                                | mount point                      |
|-------------------------------------------+----------------------------------|
| database                                  | home directory                   |
| schema                                    | sottodirectory  (es ~$HOME/bin~) |
| oggetto (tabella, trigger, funzione, ...) | file, script                     |

*** Schema a Processi: Connessioni
PostgreSQL utilizza uno *schema a processi*: /ogni connessione viene gestita da un sottoprocesso creato ad-hoc/.


*** Processi vs Thread
Ci sono svariate ragioni per preferire uno schema a processi rispetto ad uno a thread: *isolamento* e *portabilità*
sono le principali.

*** End of block                                               :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:
Il processo principale è denominato *postmaster*; ogni volta che questo riceve una richiesta di connessione si effettua una /fork/
di un processo *postgres* (denominato anche *backend*) delegato a gestire la connessione.

*** Connessioni
    Una connessione può essere *TCP/IP* oppure su *socket locale*.
*** Schema a Processi: IPC
   Siccome ogni processo è /fisicamente/ isolato, ma piu' connessioni possono dover condividere i dati, PostgreSQL
   utilizza un'area *shared memory* ove mantiene i dati. Tale zona di memoria è visibile a tutti i processi *postgres*.



   La shared memory viene organizzata in */pagine dati/* che rappresentano la copia in memoria dei dati persistenti su disco.
   Vi sono una serie di processi di utilità che si occupano di scaricare/caricare i dati dalla /shared memory/ e dal disco.
*** File System
   PostgreSQL si appoggia al *filesystem* per lo stoccaggio dei dati in maniera persistenza.

   Questo offre diversi vantaggi, fra i quali la possibilità di un tuning molto raffinato
   circa le opzioni di funzionamento del filesystem (replica, journaling, ecc.).

   Dall'altra parte, il filesystem deve essere *affidabile*, pena il rischio di perdita dati.
* Installazione
** Installazione
*** Tipologie di installazione
   E' possibile installare PostgreSQL:
   - mediante installer ufficiale
   - mediante pacchetti binari della propria installazione
   - compilando l'albero dei sorgenti

*** Macchina Virtuale                                          :B_definition:
   Tutte le prove qui mostrate sono state effettuate su una macchina virtuale con
   quattro dischi da 2GB utilizzati come spazio dati:
   #+begin_src sh
   $ uname -a
   FreeBSD olivia 11.1-RELEASE FreeBSD 11.1-RELEASE
   $ mount
   /dev/ada1p1 on /mnt/data1 (ufs, local, soft-updates)
   /dev/ada2p1 on /mnt/data2 (ufs, local, soft-updates)
   /dev/ada3p1 on /mnt/data3 (ufs, local, soft-updates)
   /dev/ada4p1 on /mnt/data4 (ufs, local, soft-updates)
   #+end_src
*** End of block                                               :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:

*** Installazione
Compilazione dai ports:
#+begin_src sh
# cd /usr/ports/databases/postgresql96-server
# make PREFIX=/opt/postgresql-9.6 BATCH=yes install clean
#+end_src

oppure il pacchetto binario:

#+begin_src sh
# pkg install postgresql96-server-9.6.5_1
#+end_src

In FreeBSD il database viene gestito dall'utente di sistema ~postgres~:

#+begin_src sh
# id postgres
uid=770(postgres) gid=770(postgres) groups=770(postgres)
#+end_src

altri sistemi operativi creano utenti simili (~psql~, ~pgsql~, ecc.).

*** Configurazione avvio servizio (OS)
I parametri di configurazione dipendono ovviamente dal sistema operativo, ad
esempio su FreeBSD le variabili di ~rc.conf~ sono visibili da
~/usr/local/etc/rc.d/postgresql~:

#+begin_src sh
#  postgresql_enable="YES"
#  postgresql_data="/var/db/postgres/data96"
#  postgresql_flags="-w -s -m fast"
#  postgresql_initdb_flags="--encoding=utf-8 --lc-collate=C"
#  postgresql_class="default"
#  postgresql_profiles=""
#+end_src

** Layout su disco
*** PGDATA
PostgreSQL utilizza il filesystem del sistema operativo per salvare i dati in modo
persistente.

In particolare una directory specifica, denominata *PGDATA*, viene usata per contenere
tutti gli oggetti PostgreSQL. Tale directory deve essere inizializzata opportunamente
(creazione struttura directory, impostazione dei permessi, ecc.)
tramite il programma ~initdb~.

*** Importanza di PGDATA
   Un cluster può servire *una sola PGDATA* alla volta.
   La directory PGDATA deve essere protetta opportunamente da accessi involontari
   di altri utenti del sistema.
*** End of block                                               :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:

*** initdb
Creazione di una directory per la memorizzazione del database (alcuni
sistemi operativi lo fanno automaticamente al momento dell'installazione
binaria):

#+begin_src sh
# mkdir /mnt/data1/pgdata
  && chown postgres:postgres /mnt/data1/pgdata
$ initdb --data-checksum --encoding="UTF-8"
         --pwprompt
         -D /mnt/data1/pgdata/
#+end_src

~initdb~ deve essere eseguito da un utente non privilegiato, le opzioni indicano:
- ~--data-checksum~: abilita il controllo sulle pagine dati del database;
- ~--encoding~: default encoding di ogni database se non sovrascritto;
- ~--pwprompt~: richiede la password del superutente di PostgreSQL (comodo per non impostarlo dopo);
- *~-D~*: l'opzione principale, indica *dove si troveranno i dati*.

*** $PGDATA
La directory ~$PGDATA~ contiene diversi file e directory, in particolare:
- ~PG_VERSION~: file di testo con la versione che serve il cluster;
- *~postgresql.conf~*: configurazione principale del cluster;
- *~pg_hba.conf~*: file di accesso al database;
- *~base~*: directory sotto la quale si troveranno tutti i database;
- *~global~*: directory che contiene dati inter-database (es. cataloghi di sistema);
- ~pg_stat~ e ~pg_stat_tmp~: informazioni per le statistiche di sistema;
- *~pg_tblscp~*: link ai vari tablespace (oggetti fuori da ~base~);
- *~pg_xlog~* e ~pg_clog~: rispettivamente WAL e commit log.

Per altre informazioni vedere [[https://www.postgresql.org/docs/9.6/static/storage-file-layout.html][Storage File System Layout]].
*** File fisici su disco
Ogni /oggetto/ con dei dati (es. tabella) viene memorizzato su disco in un file
con nome pari al suo /Object IDentifier/ (~OID~) numerico. Questo ha il vantaggio di:
- essere indipendente dal nome /logico/ e dalla relativa codifica e charset;
- essere /univoco/ indipendentemente da quante volte si cambia nome all'oggetto nel database.

Ogni file dato viene /spezzato/ in chunk da ~1 GB~ massimo, quindi dello stesso oggetto si possono
avere piu' file nominati con ~oid~, ~oid.1~, ~oid.2~, ecc.

Solitamente i file crescono in dimensione di ~8 kB~ alla volta (ossia della dimensione di una pagina dati).

*** oid2name
L'utility ~oid2name~ (modulo /contrib/) consente di esplorare
la struttura dati su disco.
#+begin_src sh
% oid2name -H localhost -U postgres
Password:
All databases:
    Oid  Database Name  Tablespace
----------------------------------
  12758       postgres  pg_default
  12757      template0  pg_default
      1      template1  pg_default
#+end_src

Gli /oid/ visualizzati in questo caso corrispondono al nome *fisico su disco*
dei database:

#+begin_src sh
% sudo ls /mnt/data1/pgdata/base
1       12757   12758
#+end_src

*** oid2name (2)
 Esploriamo il database ~template1~ su disco e cerchiamo di capire
 cosa contiene:

#+begin_src sh
% sudo stat /mnt/data1/pgdata/base/1/12618
107 65870 -rw------- 1 postgres postgres 145910 8192
#+end_src

A cosa corrisponde l'oggetto file ~12618~?

#+begin_src sh
% oid2name -H localhost -U postgres -d template1 -o 12618
Password:
From database "template1":
  Filenode  Table Name
----------------------
     12618  sql_sizing
#+end_src

*ATTENZIONE: si deve specificare a quale database si fa riferimento, poiché
gli stessi oid possono essere riciclati in database differenti*

*** oid2name (3)
E se si vuole trovare una tabella dato il suo nome?

 #+begin_src sh
% oid2name -H localhost -U postgres -d template1 -t sql_sizing
Password:
From database "template1":
  Filenode  Table Name
----------------------
     12618  sql_sizing
 #+end_src

~oid2name~ va ad interrogare il catalogo di sistema per trovare le informazioni
necessarie.

** Connessioni
*** Connessione al servizio
Il file ~pg_hba.conf~ contiene le informazioni su quali metodi di autenticazione,
quali utenti, quali host remoti e quali database sono accessibili per la connessione.
Si può editare questo file prima di avviare il servizio (se si è impostata una password
per ~postgres~ superuser) o anche in seguito.

#+begin_src sh
# tipo  database   utente   da dove       metodo
local   all        all                    trust
host    all        all      127.0.0.1/32    md5
#+end_src

*** pg_hba.conf vs sudoers
    Il file ~pg_hba.conf~ è simile al file ~sudoers~, e come tale
    va gestito scrupolosamente.
    La parola ~all~ indica tutti gli utenti/database (a seconda di dove è messa).
    *Il metodo ~trust~ non richiede autenticazione e non va usato!*
*** End of block                                               :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:

*** Avvio del servizio
Una volta che i primi pezzi sono al loro posto, è possibile avviare il servizio:

#+begin_src sh
# service postgresql start
#+end_src

e se tutto va a buon fine...
#+begin_src sh
# psql -h localhost -U postgres -l
Password for user postgres:
   Name    |  Owner   | Encoding |
-----------+----------+----------+
 postgres  | postgres | UTF8     |
 template0 | postgres | UTF8     |
 template1 | postgres | UTF8     |
(3 rows)
#+end_src

*** Database template
Quando viene inizializzata ~PGDATA~ il sistema crea due database chaimati /template/:
- ~template0~: la copia principale del template;
- *~template1~*: la copia usata in default.

Ogni votla che viene creato un nuovo database *le impostazioni di base sono copiate da ~template1~*
(che funge da /skel/ directory).

E' facoltà del DBA impostare ~template1~ opportunamente per far si che la creazione di nuovi database
abbia una base comune riconosciuta (es. schemi, linguaggi, ecc.).

~template0~ è la copia di sicurezza del template, qualora si "sporchi" troppo ~template1~.

*** Database templating
I due database template non svolgono alcuna funzione particolare se non quella di essere
usati come possibili punti di origine di un nuovo database. In default, se non specificato, PostgreSQL
copia ~template1~, mentre ~template0~ dovrebbe essere lasciato /vergine/ per operazioni particolari
quali restore (può servire un database vuoto a cui collegarsi).

*** Creare i propri template
    E' possibile creare quanti database template si vuole e istruire il comando
    ~CREATE DATABASE~ per usare altri template oltre ~template1~. Si noti però
    che un database template non accetta connessioni durante la creazione, quindi
    questo *non è un meccanismo di /clonazione/ dei database!*
*** End of block                                               :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:

** Terminale psql
*** psql
Il pacchetto /client/ contiene un interprete da riga di comando, denominato ~psql~
che consente di collegarsi al database e svolgere /tutti/ i compiti necessari.

#+begin_src sh
% psql -h localhost -U postgres template1
Password for user postgres:
psql (9.6.5)
Type "help" for help.

template1=#
template1=# \q
%
#+end_src

I parametri di linea comando sono:
- ~-h~: host a cui collegarsi (hostname, indirizzo ip);
- ~-U~: utente con cui collegarsi (/ruolo/ PostgreSQL);
- database a cui collegarsi (es. ~template1~).

*** psql: connection URI
Oltre a specificare ogni singolo parametro della conessione tramite opzioni di comando,
~psql~ consente di utilizzare un URI per la connessione, ad esempio:

#+begin_src sh
% psql postgresql://postgres@localhost:5432/template1
Password:
psql (9.6.5)
Type "help" for help.

template1=#
#+end_src

Parametri ulteriori possono essere specificati nell'URL (dopo ~?~),
come ad esempio:

#+begin_src sh
postgresql://postgres@localhost/template1?sslmode=require
#+end_src

*** psql: prompt

In modo simile alla shell, il prompt di ~psql~ mostra:
- il database al quale si è collegati (~template1~);
- un ~#~ se si è superuser o ~>~ se si è utenti normali.

Si esce da ~psql~ con ~\q~.

*** Quale versione del server?
~psql~ mostra all'avvio la propria versione (client) ma con una query
è possibile capire anche la versione del server:

#+begin_src SQL
template1=# SELECT version();
 PostgreSQL 9.6.5 on amd64-portbld-freebsd11.0, ...
(1 row)
#+end_src


La funzione speciale ~version()~ viene compilata al momento
del build del pacchetto binario.


*** psql, ruoli, database
In default ~psql~ cerca di collegarsi a un database che ha lo stesso nome
utente dell'utente che esegue il comando stesso, con un ruolo che ha
lo stesso nome.
In altre parole:

#+begin_src sh
% id -p
uid     luca

% psql
psql: FATAL:  role "luca" does not exist
#+end_src

corrisponde a:

#+begin_src sh
% psql -h localhost -U luca luca
#+end_src

*** psql: ruoli, database e variabili di ambiente
 In realtà quando non viene specificato un utente e/o un database
 ~psql~ cerca di collegarsi a quanto stabilito dalle variabili
 di ambiente ~PGUSER~ e ~PGDATABASE~ (e le relative ~PGHOST~ e ~PGPORT~):

#+begin_src sh
% export PGUSER=foo PGDATABASE=myDB
% psql
psql: FATAL:  no pg_hba.conf entry for host "[local]",
              user "foo",
              database "myDB", SSL off
#+end_src

*** psql: aiuto
All'interno di ~psql~ ci sono due tipologie di aiuto:
- /aiuto sui comandi SQL/: si ottiene con ~\h~
  - ~\h~ senza argomenti mostra tutti i comandi SQL disponibili;
  - ~\h COMANDO~ mostra l'aiuto del comando SQL specificato;
- /aiuto su ~psql~/: si ottiene con ~\?~ e mostra tutti i comandi
  speciali di ~psql~. Tutti i comandi ~psql~ iniziano con backslash
  (es. ~\d~).

*** psql: evitare la password
~psql~ consente di impostare un file di credenziali (~$HOME/.pgpass~) per collegarsi
a uno specifico database/host con uno specifico utente senza dover digitare
una password.
Ogni riga nel file contiene:
- host e porta a cui collegarsi;
- database a cui collegarsi (~*~ per tutti);
- username e password con cui collegarsi.

Il file non deve essere leggibile da altri utenti (es. permessi ~600~).

#+begin_src sh
% cat ~/.pgpass
127.0.0.1:5432:template1:postgres:xxxxxxxx

% psql -U postgres template1
template1=#
#+end_src

*** Errori comuni
    *Il file deve avere permessi ~rw~ per il solo proprietario*. Inoltre si deve specificare
    la porta a cui collegarsi dopo l'hostname!
*** End of block                                               :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:


*** psql: configurazione utente
~psql~ consente di specificare delle configurazioni utente nel file ~$HOME/.psqlrc~.
Tutti i comandi (~psql~ compatibili) specificati in tale file vengono eseguiti
prima di fornire il prompt all'utente.

Utile per impostare variabili, prompt, formati di output, ecc.
*** psql: ~/.psqlrc di esempio
#+begin_src sh
\set HISTFILE ~/.psql_history_ :DBNAME
\set ON_ERROR_ROLLBACK on
\set ON_ERROR_STOP     on
\x
\set PROMPT1 '[%n @ %/ on %m] %l %x %# '
#+end_src

Il prompt corrisponde a: /username/ (~%n~), /database/ (~%/~),
/hostname/ (~%m~), /linea/ (~%l~), /stato transazione/ (~%x~)
e /prompt superutente o utente normale/ (~%#~).

** Interazione: ruoli, database, tabelle
*** Ruoli e Utenti
   Dalla versione 8.1 in poi PostgreSQL non distingue piu' fra utenti e gruppi
   ma usa il concetto di *ruolo* che rappresenta entrambi:
   - un ruolo può rappresentare un utente;
   - ad un ruolo si possono aggiungere altri utenti (e quindi rappresenta un gruppo).

*** Ruoli e Connessioni
    *Per collegarsi ad un database occorre sempre un ruolo*, ossia un utente
    PostgreSQL (che è logicamente separato da quello del sistema operativo).
    Quando viene inizializzato un cluster viene creato un ruolo superutente
    per permetterne la gestione (negli esempi ~postgres~).
*** End of block                                               :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:

*** Vedere i ruoli
Il catalogo ~pg_roles~ contiene le informazioni sui ruoli e le loro proprietà:

#+begin_src sql
# SELECT rolname, rolsuper, rolcreatedb, rolcanlogin
FROM pg_roles;
      rolname      | rolsuper | rolcreatedb | rolcanlogin
-------------------+----------+-------------+-------------
 pg_signal_backend | f        | f           | f
 postgres          | t        | t           | t
#+end_src

E' possibile creare utenti/gruppi/ruoli con privilegi di super utente, possibilità di creare nuovi
database e di collegarsi o no al cluster.

*** Creare i ruoli
   Il comand SQL ~CREATE ROLE~ (o da terminale ~createuser~) consente di creare un nuovo utente/gruppo.
   Ad esempio si supponga di voler gestire un database di una applicazione definendo due utenti: uno applicativo
   e uno amministrativo/interattivo:

   #+begin_src sql
# CREATE ROLE my_app
  WITH NOLOGIN
  CONNECTION LIMIT 1
  PASSWORD 'xxx';
CREATE ROLE

# ALTER ROLE my_app WITH LOGIN;

# CREATE ROLE luca
  WITH CREATEDB LOGIN PASSWORD 'xxxxx'
  IN ROLE my_app;
CREATE ROLE
   #+end_src

Ora il ruolo ~my_app~ funge sia da utente che da gruppo a cui ~luca~ appartiene.
Si noti l'uso di ~ALTER ROLE~ per correggere un errore.

*** Creare i ruoli (2)
   I ruoli appena creati risultano ora:
#+begin_src sql
# SELECT rolname, rolsuper, rolcreatedb, rolcanlogin, rolconnlimit
  FROM pg_roles;
      rolname      | rolsuper | rolcreatedb | rolcanlogin | rolconnlimit
-------------------+----------+-------------+-------------+--------------
 pg_signal_backend | f        | f           | f           |           -1
 postgres          | t        | t           | t           |           -1
 my_app            | f        | f           | t           |            1
 luca              | f        | t           | t           |           -1
#+end_src

*** Creare i ruoli (3)
   E' ora possibile configurare il file ~.pgpass~ per i nuovi ruoli:
#+begin_src sh
% cat ~/.pgpass
127.0.0.1:5432_template1:postgres:postgres
localhost:5432:template1:luca:xxxxxx
localhost:5432:template1:my_app:xxxxx
#+end_src

*** Evitare di censire ogni singolo database
    Si ricordi che è possibile usare ~*~ per host, porta e database. Questo semplifica
    il deployment di nuovi database, ma dall'altro lato rende piu' complesso censire
    e controllare i database a cui si accede.
*** End of block                                               :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:
*** Creare un database
   Usando il comando SQL ~CREATE DATABASE~ è possibile aggiungere un nuovo database
   (e /opzionalmente/ aggiungere un commento per indicare lo scopo del database):
#+begin_src sql
# CREATE DATABASE testdb
  WITH OWNER 'luca';

# COMMENT ON DATABASE testdb IS 'A test database';
#+end_src

  Alternativamente si può usare il comando shell ~createdb~:
#+begin_src sh
% createdb --owner='luca' -e -h localhost -U postgres testdb 'A test database'
CREATE DATABASE testdb OWNER luca;
COMMENT ON DATABASE testdb IS 'A test database';
#+end_src

*** Vedere i database disponibili
 Il catalogo ~pg_database~ contiene le informazioni circa i database presenti nel
 sistema:

#+begin_src sql
# SELECT datname FROM pg_database;
  datname
-----------
 postgres
 testdb
 template1
 template0
#+end_src

 Alternativamente si può usare l'opzione ~-l~ in ~psql~:
#+begin_src sh
% psql -h localhost -U postgres -l
...
Name              | testdb
Owner             | luca
Encoding          | UTF8
Collate           | C
Ctype             | C
Access privileges |
#+end_src
*** Eliminare un database
 Avendo i privilegi corretti, si può usare il comando SQL ~DROP DATABASE~
 o il comando shell ~dropdb~:

#+begin_src sql
% psql -h localhost -U postgres template1
# DROP DATABASE testdb;
DROP DATABASE
#+end_src

#+begin_src sh
% dropdb -h localhost -U postgres testdb
#+end_src
*** Creare una tabella
   L'istruzione SQL è ~CREATE TABLE~.
#+begin_src sql
% psql -h localhost testdb                                                                                               ~
> CREATE TABLE persona(
 pk serial,
 nome varchar(20),
 cognome varchar(20),
 codice_fiscale varchar(16),
 PRIMARY KEY(pk),
 UNIQUE(codice_fiscale)
 );
#+end_src

*** Modificare una tabella
   Ci sono varie istruzioni, in particolare ~ALTER TABLE~ che consente di agire sulla tabella
   e sui relativi vincoli:

#+begin_src sql
> ALTER TABLE persona ADD COLUMN eta integer;
> ALTER TABLE persona ADD CHECK ( eta > 0 and eta < 120 );
#+end_src

*** Come è fatta la tabella?
   Il comando speciale di ~psql~ ~\d~ consente di ispezionare una tabella e i suoi vincoli:
#+begin_src sql
> \d persona
                                    Table "public.persona"
     Column     |         Type          |                      Modifiers
----------------+-----------------------+------------------------------------------------------
 pk             | integer               | not null default nextval('persona_pk_seq'::regclass)
 nome           | character varying(20) |
 cognome        | character varying(20) |
 codice_fiscale | character varying(16) |
 eta            | integer               |
Indexes:
    "persona_pkey" PRIMARY KEY, btree (pk)
    "persona_codice_fiscale_key" UNIQUE CONSTRAINT, btree (codice_fiscale)
Check constraints:
    "persona_eta_check" CHECK (eta > 0 AND eta < 120)
#+end_src

* SQL PostgreSQL
** Accorgimenti iniziali
*** SELECT not dual !
   In PostgreSQL non esiste la "famosa" tabella ~dual~ e lo statement ~SELECT~
   fa esattamente quello che ci si aspetta:

#+begin_src sql
> SELECT 1 FROM dual;
ERROR:  relation "dual" does not exist

> SELECT 1;
 ?column?
----------
        1
#+end_src
*** Dollar quoting
   PostgreSQL permette l'uso del *dollar quoting* (simile all'operatore ~qq~ di Perl):
   - si può usare un tag con nome arbitrario purché racchiuso fra due simboli ~$~;
   - il tag va usato per l'apertura e la chiusura;
   - la stringa fra tag viene sottoposta ad escape automatico.

#+begin_src sql
> SELECT $qq$Perche' l'hai scritto?$qq$;
        ?column?
------------------------
 Perche' l'hai scritto?
#+end_src
Si può usare anche uno statement SQL come tag (es. ~$SELECT$~).
*** Camel Case
Lo standard SQL non ammette il camel case, e chiede l'uso di *UPPERCASE*.
PostgreSQL utilizza il *lowercase* per tutti gli identificatori (il risultato non cambia).
#+begin_src sql
> CREATE TABLE Foo( Bar int, bAz int );
-- diventa
-- create table foo( bar int, baz int);
#+end_src

Se si vuole usare il *cAmeLcAsE* si deve indicare ogni operatore /*sempre*/
fra doppi apici (sconsigliato):
#+begin_src sql
> CREATE TABLE "Foo"( "Bar" int, "bAz" int );
> SELECT "Bar", "bAz" FROM "Foo";
#+end_src
** INSERT
*** Valori di uscita di una INSERT
In default una istruzione di ~INSERT~ restituisce due valori:
- ~oid~ della tupla inserita (se la tabella ha gli oid);
- /numero di tuple inserite/.

E' possibile specificare una clausola ~RETURNING~ che restituisca dei valori
basati su una /select-like/ di ogni tupla inserita (caso banale: la chiave automatica).
*** INSERT RETURNING: un primo esempio
#+begin_src sql
> INSERT INTO persona( cognome, nome, codice_fiscale )
  VALUES( 'Luca', 'Ferrari', 'FRRLCU78L19F257T' )
  RETURNING pk;
 pk
----
 13
#+end_src
*** INSERT RETURNING: un esempio piu' complesso
#+begin_src sql
> INSERT INTO persona( cognome, nome, codice_fiscale )
  VALUES( 'Luca', 'Ferrari', 'FRRLCU78L19F257Z' )
  RETURNING upper(codice_fiscale), pk;
      upper       | pk
------------------+----
 FRRLCU78L19F257Z | 14
#+end_src
** UPSERT
*** INSERT or UPDATE?
Una /UPSERT/ è una ~INSERT~ che, in caso di conflitto (vincolo di univocità violato)
esegue una ~UPDATE~ automaticamente.

*UPSERT è una modifica della sintassi di ~INSERT~!*
*UPSERT non può funzionare se si sono delle rules definite sulla tabella!*

Si specifica cosa fare in caso di conflitto, ed eventualmente come risolvere tale conflitto.

In default viene ritornato il numero di tuple inserite o aggiornate in caso di conflitto (come
da return di un ~INSERT~).
*** Funzionamento di UPSERT
Occorre che sia specificato un ~CONSTRAINT~ che indica il conflitto (o una colonna su cui esiste
un constraint di univocità).

La tupla in conflitto viene nominata ~EXCLUDED~.

*** Senza UPSERT...
#+begin_src sql
> INSERT INTO persona( codice_fiscale, nome, cognome )
  VALUES( 'FRRLCU78L19F257B', 'Ferrari', 'Luca' );

-- no upsert!
> INSERT INTO persona( codice_fiscale, nome, cognome )
  VALUES( 'FRRLCU78L19F257B', 'Luca', 'Ferrari' );
ERROR:  duplicate key value violates
  unique constraint "persona_codice_fiscale_key"
#+end_src
*** UPSERT in azione
#+begin_src sql
-- upsert!
> INSERT INTO persona( codice_fiscale, nome, cognome )
  VALUES( 'FRRLCU78L19F257B', 'Luca', 'Ferrari' )
  ON CONFLICT(codice_fiscale)
  DO UPDATE SET nome = EXCLUDED.nome,
             cognome = EXCLUDED.cognome;
#+end_src
*** UPSERT in aborto (controllato)
Se si specifica la risoluzione del conflitto come ~DO NOTHING~ allora la query non effettua
l'inserimento della tupla e fallisce silenziosamente (cioè con successo).
#+begin_src sql
> INSERT INTO persona( codice_fiscale, nome, cognome )
  VALUES( 'FRRLCU78L19F257B', 'Luca', 'Ferrari' )
  ON CONFLICT(codice_fiscale)
  DO NOTHING;

INSERT 0 0
#+end_src
*** UPSERT RETURNING
E' possibile usare la clausola ~RETURNING~ anche nel caso di un /UPSERT/:
#+begin_src sql
> INSERT INTO persona( codice_fiscale, nome, cognome )
  VALUES( 'FRRLCU78L19F257B', 'Luca', 'Ferrari' )
  ON CONFLICT(codice_fiscale)
  DO UPDATE SET nome = EXCLUDED.nome,
             cognome = EXCLUDED.cognome
RETURNING nome, cognome;

 nome | cognome
------+---------
 Luca | Ferrari

#+end_src
** Cast
*** Modalità di cast
In PostgreSQL il cast può essere effettuato in quattro modi:
- specificando il tipo prima del valore (es. ~int '10'~);
- specificando il tipo dopo il valore con l'operatore ~::~ (es. ~'10'::int~);
- usando l'operatore ~CAST~;
- usando il tipo come fosse una funzione (es. ~text( 10 )~ ).
#+begin_src sql
> SELECT '10'::int + 3;
> SELECT int '10' + 3;
> SELECT CAST( '10' AS integer ) + 3;
#+end_src

*** Considerazioni sul cast
I modi consigliati sono *~CAST()~ (conforme SQL standard)* o ~::~, gli altri hanno delle limitazioni
(es. la modalità funzione va usata solo per nomi di tipi che sono anche nomi validi di funzione, mentre il tipo
prima del valore funziona solo per i letterali).

Qualora il cast non sia ambiguo, è possibile ometterlo, ovvero:

#+begin_src sql
> SELECT '10' + 3;
#+end_src

** Alcuni statement particolari
*** CASE
Rappresento lo /switch/ del linguaggio C, o il /given/ di Perl:
#+begin_src sql
> SELECT nome,
  CASE
     WHEN eta >= 18 THEN 'maggiorenne'
     ELSE 'minorenne'
  END
  FROM persona;
 nome  |    case
-------+-------------
 Luca  | maggiorenne
 Diego | minorenne
#+end_src

*** CASE con equals
Si può usare la versione che effettua una comparazione secca sul valore da analizzare:
#+begin_src sql
> SELECT nome,
  CASE eta
   WHEN 39 THEN 'maggiorenne'
   WHEN 10 THEN 'minorenne'
   ELSE 'non saprei'
  END
  FROM persona;
#+end_src

*** COALESCE
Ritorna il primo valore non nullo degli argomenti specificati:
#+begin_src sql
> SELECT COALESCE( NULL, 'MIRIAM',
                   'LUCA', NULL );
 coalesce
----------
 MIRIAM
#+end_src

E' utile per estrarre informazioni che possono trovarsi in campi multipli.

*** NULLIF
Ritorna un valore ~NULL~ se gli operatori sono uguali, altrimenti
ritorna il primo valore:
#+begin_src sql
> SELECT NULLIF('luca', 'LUCA');
 nullif
--------
 luca
> SELECT NULLIF( 10, 10 );
 nullif
--------

#+end_src
/E' una sorta di ~xor~ del poveraccio!/
*** Row
L'operatore ~ROW~ permette di costruire una /tupla/ al volo. Accetta l'uso di costanti
e di espressioni da valutare al volo:
#+begin_src sql
> SELECT ROW( 1, 2, 'Foo', 'Fighters' );
        row
--------------------
 (1,2,Foo,Fighters)

> SELECT ROW( p.codice_fiscale, length( p.codice_fiscale ) ) FROM persona p;
          row
-----------------------
 (FRRLCU71L19F257B,16)
#+end_src
** Array
*** Costruttore di un array
Gli array sono dichiarati con il tipo seguito da parentesi quadre (es. ~integer[]~).
Il costruttore dell'array è l'operatore ~ARRAY~, che cerca di comprendere il tipo
dagli elementi dell'array stesso (se non effettuato un cast).
#+begin_src sql
> SELECT ARRAY[1, 2, 3, 4]::integer[];
   array
-----------
 {1,2,3,4}
#+end_src
*** Array multidimensionali
Sono costruiti combinando assieme piu' array.
#+begin_src sql
> SELECT ARRAY[ ARRAY[ 2, 4 ], ARRAY[ 1, 3 ] ];
     array
---------------
 {{2,4},{1,3}}
#+end_src

*** Array in tabella
Le tabelle possono includere degli array.
#+begin_src sql
> CREATE TABLE software( name text, versions text[] );
> INSERT INTO software
  VALUES( 'Java', '{1.5, 1.6, 1.7, 1.8 }' );
> INSERT INTO software
  VALUES( 'Perl', '{5.10, 5.20, 6.c}' );
#+end_src
*** Array in tabella: indici
Gli indici degli array funzionano come nel linguaggio C, *ma gli indici partono da 1!*:
#+begin_src sql
> SELECT name, versions[1] FROM software;
 name | versions
------+----------
 Perl | 5.10
 Java | 1.5
#+end_src
*** Array in tabella: estremi
Le funzioni ~array_lower()~ e ~array_upper()~ forniscono il minimo e massimo indice
usabile in una determinata dimensione dell'array:
#+begin_src sql
> SELECT name,
  versions[ array_lower( versions, 1) ] AS required,
  versions[ array_upper( versions, 1 ) ] AS optimal
  FROM software;
 name | required | optimal
------+----------+---------
 Perl | 5.10     | 6.c
 Java | 1.5      | 1.8
#+end_src
*** Array in tabella: slicing
L'operatore ~[:]~ permette di ottenere lo slicing:
#+begin_src sql
> SELECT name, versions[1:2] FROM software;
 name |  versions
------+-------------
 Perl | {5.10,5.20}
 Java | {1.5,1.6}
#+end_src

*** Array in tabella: aggiunta di elementi
Si possono seguire diverse strade:
- ricostruire l'intero array con i nuovi valori tramite ~ARRAY~;
- appendere l'array originale con uno singolo (costruito con ~ARRAY~ o ~'{}'~);
- usare ~array_prepend()~ per inserire un elemento in testa, ~array_append()~ per aggiungerlo in coda
  e/o ~array_cat()~ per concatenare due array.

*** Array in tabella: aggiunta di elementi (esempio 1)
#+begin_src sql
> UPDATE software
  SET versions = versions || ARRAY['2017.09']
  WHERE name = 'Perl';

> UPDATE software
  SET versions = versions || '{1.8_168}'
  WHERE name = 'Java';
#+end_src

*** Array in tabella: aggiunta di elementi (esempio 2)
#+begin_src sql
> UPDATE software
  SET versions = array_append( versions, '1.8_169' )
  WHERE name = 'Java';

> UPDATE software
  SET versions = array_prepend( '1.4', versions )
  WHERE name = 'Java';
#+end_src

*** Array in tabella: concatenazione
#+begin_src sql
> UPDATE software
  SET versions = array_cat( ARRAY[ '5.6', '5.8' ], versions )
  WHERE name = 'Perl';
#+end_src

*** Array in tabella: ricerca
Ci sono due operatori principali:
- ~ANY~ ricerca un valore in uno qualunque degli elementi dell'array;
- ~ALL~ ricerca un valore in tutti gli elementi dell'array.

Altri operatori utili nel confronto di due array:
- ~&&~ ricerca le sovrapposizioni;
- ~@>~ /contains/;
- ~<@~ /is contained by/.
*** Array in tabella: ricerca (esempio 1)
#+begin_src sql
> SELECT name FROM software WHERE '6.c' = ANY( versions );
 name
------
 Perl

> SELECT name FROM software WHERE '6.c' = ALL( versions );
 name
------
(0 rows)
#+end_src

*** Array in tabella: ricerca (esempio 2)
#+begin_src sql
> SELECT name FROM software WHERE ARRAY[ '5.10', '5.20' ] && versions;
 name
------
 Perl
#+end_src

*** Array in tabella: ricerca (esempio 3)
#+begin_src sql
-- contains
> SELECT name FROM software
  WHERE ARRAY[ '5.10', '5.20' ] @> versions;

(0 rows)

-- is contained by
> SELECT name FROM software
  WHERE ARRAY[ '5.10', '5.20' ] <@ versions;
 name
------
 Perl
#+end_src
*** Array in tabella: eliminare un elemento
La funzione ~array_remove()~ toglie un valore da un array, mentre ~array_replace()~
sostituisce un elemento con un altro. *Restituiscono l'array modificato!*
#+begin_src sql
> UPDATE software
  SET versions = array_remove( versions, '5.6' );

> UPDATE software
  SET versions = array_replace( versions, '5.8', '5.8.2' );
#+end_src
*** Array in tabella: trovare un elemento
Le funzioni ~array_position()~ e ~array_positions()~ ritornano la posizione di uno
elemento (eventualmente ripetuto) nell'array:
#+begin_src sql
> SELECT name, array_positions( versions, '5.20' )
  FROM software;
 name | array_positions
------+-----------------
 Perl | {3}
 Java | {}
#+end_src
*** Array in tabella: trasformare un array in tabella
#+begin_src sql
> SELECT name, unnest( versions ) FROM software;
 name | unnest
------+---------
 Perl | 5.8.2
 Perl | 5.10
 Perl | 5.20
 Perl | 6.c
...
#+end_src
** Range
*** Range di dato
I tipi di dato /range/ sono valori /non esattamente definiti/.
L'idea è quella di identificare un tipo ammesso di valori (denominato *subtype*),
sul quale si imposta un valore di inizio e di fine e tutti i valori fra questi inclusi.

Esempio: /dalle ore 8:00 alle ore 9:00/. Con un solo valore range si indica
l'inizio (/8:00/) e la fine (/9:00/) del sottotipo (es. ~time~).

*** Range predefiniti
PostgreSQL supporta i seguenti tipi range:
- ~int4range~ range di ~integer~;
- ~int8range~ range di ~biginteger~;
- ~numrange~ range di ~numeric~;
- ~tsrange~ rande di timestamp;
- ~daterange~ range di ~date~.

*** Esempio di utilizzo di range
#+begin_src sql
> CREATE TABLE ticket(
    pk SERIAL PRIMARY KEY,
    tipo text,
    periodo daterange,
    altezza int4range );
#+end_src

*** Costruzione di un range: sintassi stringa
Un tipo range viene sempre specificato come stringa (fra apici)
e può valere:
- ~[ begin, end ]~ oppure ~( begin, end )~
- ~empty~ per non specificare nessun valore (simile a ~NULL~),

Come la forma matematica, le parentesi quadre indicano l'inclusione dell'estremo
mentre quelle tonde l'esclusione dell'estreno.

*** Costruzione di range: costruttori
Alternativamente alla forma stringa, ogni tipo di range predefinito include
un costruttore con lo stesso nome del tipo di range e che accetta due o tre parametri:
- ~typerange( a, b )~ costruisce un range di ~type~ come ~'[a, b)'~;
- ~typerange( a, b, '()' )~ costruisce un range di ~type~ con gli estremi specificati
  dalla combinazione delle parentesi.

*** Inserimento di valori di range
#+begin_src sql
> INSERT INTO ticket( tipo, periodo, altezza )
  VALUES( 'GRATUITO-BIMBO',
  '[2017-06-01, 2017-09-30)',
  '(60, 100)' );

> INSERT INTO ticket( tipo, periodo, altezza )
  VALUES( 'GRATUITO-ANZIANO',
  '[2017-06-01, 2017-10-31]',
  'empty' );
#+end_src

*** Operatori di range
Per ricercare fra un range si usano operatori simili a quelli
di un array:
- ~@>~ il range (a sinistra) contiene il valore scalare a destra;
- ~isempty~ indica se il range è vuoto;
- ~upper~ e ~lower~ estraggono gli estremi del range;
- ~&&~ sovrapposizione fra due range.

*** Query sui range
#+begin_src sql
> SELECT tipo FROM ticket
  WHERE periodo
     && daterange( '2017-07-01',
                   '2017-07-31',
                   '[]' );
#+end_src

*** Query sui range (2)
#+begin_src sql
> SELECT tipo FROM ticket
  WHERE periodo @> '2017-10-31'::date;
#+end_src

** Tipi di dato personalizzato
*** Tipi personalizzati
PostgreSQL consente di creare dei /tipi/ personalizzati:
- *compositi* (una sorta di struttura);
- *enum* le classiche enumerazioni, sostanzialmente una serie di /etichette/;
- *range* un tipo che identifica un range di valori;
- *scalare* un tipo fortemente integrato nel server e che richiede la scrittura di opportune
  funzioni in codice C;

*** Creare un tipo enumerazione
Si vogliono /standardizzare/ gli stati di un software:
#+begin_src sql
> CREATE TYPE sw_version
  AS ENUM ( 'stable',
            'unstable',
            'EOL',
            'development' );
#+end_src

*** Creare un tipo composito
SI supponga di voler creare un semplice tipo strutturato per un repository
software:
#+begin_src sql
> CREATE TYPE sw_repository
  AS ( url text,
       author text );
#+end_src
*Il tipo composito si usa con parentesi tonde!*

*** Usare i tipi in una tabella
#+begin_src sql
> CREATE TABLE software(
      pk SERIAL PRIMARY KEY,
      name text,
      version sw_version,
      repository sw_repository );
#+end_src

*** Inserire i tipi compositi
#+begin_src sql
> INSERT INTO software( name, version, repository )
  VALUES( 'PostgreSQL-9.6',
      'stable',
      ( 'https://www.postgresql.org', 'PGDG' ) );

> INSERT INTO software( name, version, repository )
  VALUES( 'Perl-6',
     'stable',
     ( 'https://www.perl6.org', 'Perl Developers' ) );
#+end_src

*** Estrarre i tipi composti
#+begin_src sql
> SELECT name, (repository).url FROM software;
      name      |            url
----------------+----------------------------
 PostgreSQL-9.6 | https://www.postgresql.org
 Perl-6         | https://www.perl6.org
#+end_src

*** Creare un tipo personalizzato range
#+begin_src sql
> CREATE OR REPLACE FUNCTION f_versions_diff( older float, newer float )
RETURNS float AS $BODY$
DECLARE
BEGIN
    RETURN (newer - older)::integer;
END;
$BODY$
LANGUAGE plpgsql IMMUTABLE;
#+end_Src

*** Creare un tipo personalizzato range (2)
#+begin_src sql
> CREATE TYPE sw_major_version AS RANGE (
subtype = float,
subtype_diff = f_versions_diff );
#+end_src

*** Creare un tipo personallizato range (3)
#+begin_src sql
> SELECT '[9.6, 10.0)'::sw_major_version;
 sw_major_version
------------------
 [9.6,10)
#+end_src

** TODO JSON & JSONB
*** Tipi di dato JSON
PostgreSQL supporta due tipi di dato /JSON (JavaScript Object Notation):
- ~json~ tipo di dato testuale che richiede un nuovo /parsing/ ogni volta che
  si opera sul dato stesso;
- ~jsonb~ una forma che viene destrutturata e memorizzata in formato binario per successive
  elaborazioni piu' rapide (richiede maggior tempo in inserimento per la conversione).

Il formato ~json~ mantiene l'input intatto, quindi spazi bianchi, chiavi duplicate (solo l'ultima
viene trattata dagli operatori). IL tipo ~jsonb~ rimuove spazi bianchi ridondanti nonché mantiene
un solo valore per ogni chiave (l'ultimo nel caso di chiavi duplicate).
*** Sintassi JSON
La sintassi per creare un tipo JSON prevede:
- /scalari/ (di tipo intero o stringa);
#+begin_src sql
> SELECT '"hello"'::json;
> SELECT '10'::json;
#+end_src
- /array/ (anche di tipi differenti), stabiliti da parentesi quadre;
#+begin_src sql
> SELECT '[ "Luca", "Ferrari", 39 ]'::json;
#+end_src
- /oggetti/ identificati da parentesi graffe;
#+begin_src sql
> SELECT '{ "name" : "Luca", "surname" : "Ferrari", "age" : 39 }'::json;
#+end_src
*** Un esempio pratico di differenza fra JSON e JSONB
Si ricordi che ~json~ mantiene intalterati i dati di input, mentre
~jsonb~ li riorganizza e li "ottimizza" tenendo solo l'ultima chiave
nel caso di duplicazione:
#+begin_src sql
> SELECT '{ "name" : "Luca",
  "surname" : "Ferrari",
  "age" : 29,
  "age" : 39 }'::json;
          json
------------------------
 { "name" : "Luca",    +
 "surname" : "Ferrari",+
 "age" : 29,           +
 "age" : 39 }
#+end_src

#+begin_src sql
> SELECT '{ "name" : "Luca",
    "surname" : "Ferrari",
    "age" : 29,
    "age" : 39 }'::jsonb;
                       jsonb
---------------------------------------------------
 {"age": 39, "name": "Luca", "surname": "Ferrari"}
#+end_src
*** Operatori JSON
Gli operatori hanno tutti due varianti:
1. se usati con indice numerico forniscono accesso ad un array;
2. se usati con indice testuale accedono ad un campo di oggetto.

Inoltre ogni operatore ha la sua controvariante /doppia freccia/ chie
ritorna il valore come testo ~text~.

| Operatore | Indice   | Significato                                        |
|-----------+----------+----------------------------------------------------|
| ->        | numerico | accesso ad array (da zero)                         |
| ->        | text     | accesso ad un oggetto con chiave                   |
| ->>       | numerico | accesso ad array, restituisce ~text~               |
| ->>       | text     | accesso ad oggetto con chiave (restituisce ~text~) |
| #>        | text[]   | dereferenziazione                                  |
| #>>       | text[]   | dereferenziazione (restituisce un ~text~)          |
*** Operatori JSON: esempi
#+begin_src sql
> SELECT '[ "foo", 0, "bar", 1 ]'::json->1; -- 0

> SELECT '{ "foo" : 0, "bar" : 1 }'::json->'foo'; -- 0

> SELECT '{ "foo" : { "bar" : 1 } }'::json#>'{foo, bar}'; --1
#+end_src
*** Operatori JSONB: esempi
Il tipo ~jsonb~ dispone di altri operatori comodi:
- ~?~ ricerca una chiave nell'oggetto;
#+begin_src sql
> SELECT '{ "foo" : { "bar" : 1 } }'::jsonb ? 'bar'; -- true
#+end_src
- ~@>~ e ~<@~ contenimento da einistra a destra e viceversa (solo al livello principale);
#+begin_src sql
> SELECT '{ "foo" : { "bar" : 1 } }'::jsonb
     @> '{"bar" : 1}'::jsonb;  -- false

> SELECT '{ "foo" : { "bar" : 1 } }'::jsonb
    @> '{"foo" : {"bar" : 1}}'::jsonb;  -- true
#+end_src
- ~||~ concatenazione di due oggetti.
#+begin_src sql
> SELECT '{ "name" : "Luca" }'::jsonb
   || '{ "surname" : "Ferrari" }'::jsonb;
#+end_src
*** Esempio di uso di JSONB in tabella
#+begin_src sql
> CREATE TABLE persona (
    pk SERIAL PRIMARY KEY,
    name text,
    surname text,
    stuff jsonb );

> INSERT INTO persona( name, surname, stuff )
  VALUES ( 'Luca', 'Ferrari',
    '{ "email" : "luca@mail.me", "web" : "http://fluca1978" }' );

> INSERT INTO persona( name, surname, stuff )
  VALUES ( 'Emanuela', 'Santunione',
    '{ "email" : "luca@mail.me" }' );
#+end_src
*** Esempio di JSONB in tabella (2)
Quali persone hanno un sito web?
#+begin_src sql
SELECT name, surname, stuff->'web'
FROM persona
WHERE stuff ? 'web';

 name | surname |      ?column?
------+---------+--------------------
 Luca | Ferrari | "http://fluca1978"
#+end_src
*** Funzioni di utilitaì JSON
Ci sono molte funzioni di utilità per convertire dati da e per JSON:
- ~row_to_json~ converte una tupla in un oggetto JSON (esportabile);
- ~jsopn_build_object~ costruisce un oggetto JSON da una lista di valori;
- ~array_to_json~ converte un array PostgreSQL in uno JSON.
#+begin_src sql
> SELECT row_to_json( row( name, surname, stuff->'email' ) )
  FROM persona
  WHERE stuff ? 'email';
                       row_to_json
---------------------------------------------------------
 {"f1":"Luca","f2":"Ferrari","f3":"luca@mail.me"}
 {"f1":"Emanuela","f2":"Santunione","f3":"luca@mail.me"}

> SELECT json_build_object( 'name', 'Luca', 'surname', 'Ferrari' );
            json_build_object
------------------------------------------
 {"name" : "Luca", "surname" : "Ferrari"}

> SELECT array_to_json( ARRAY[ 1, 2, 3, 4 ] );
 array_to_json
---------------
 [1,2,3,4]
#+end_src
* Vacuum e Autovacuum
** Impatti di Vacuum e autovacuum
*** Tabella di eventi
   Si immagini di popolare una tabella di eventi:

#+begin_src sql
> CREATE TABLE evento( pk serial NOT NULL,
                      description text,
                      ts timestamp default current_timestamp,
                       PRIMARY KEY(pk) );
#+end_src

e di popolarla con alcuni dati...
#+begin_src sql
> INSERT INTO evento( description )
 SELECT 'Evento ' ||
    CASE WHEN ( random() * 10 )::integer % 2 = 0
         THEN 'pari'
         ELSE 'dispari'
    END
 FROM generate_series( 1, 1000000 );

INSERT 0 1000000
Time: 8635.289 ms
#+end_src

*** Tabella di eventi: quanto occupa?
#+begin_src sql
> SELECT relname, relpages, reltuples
FROM pg_class
WHERE relkind = 'r' AND relname = 'evento';
 relname | relpages | reltuples
---------+----------+-----------
 evento  |     6879 |     1e+06
#+end_src

indicativamente ~6879 * 8kB = 53,74 MB~ di spazio disco.
Verifichiamo...
#+begin_src sh
% oid2name -H localhost -U luca -d testdb -t evento                                                                      ~
From database "testdb":
  Filenode  Table Name
----------------------
     16465      evento

% oid2name -H localhost -U luca                                                                                          ~
  16393         testdb

% sudo ls -lh /mnt/data1/pgdata/base/16393/16465                                                                         ~
-rw-------  1 postgres  postgres    54M Oct 18 10:40 /mnt/data1/pgdata/base/16393/16465
#+end_src

*** Tabella di eventi: quanto occupa? (2)
Metodo meno "scomodo" di cercare il file fisico su disco...
#+begin_src sql
> SELECT pg_size_pretty(
             pg_relation_size( 'evento'::regclass )
         );
 pg_size_pretty
----------------
 54 MB
(1 row)
#+end_src
*** Tabella di eventi: statistiche
Le statistiche di sistema sembrano funzionare correttamente:
#+begin_src sql
> SELECT pg_relation_size( 'evento'::regclass ) AS dimensione_fisica, relpages, reltuples
  FROM pg_class  WHERE relkind = 'r' AND relname = 'evento';
 dimensione_fisica | relpages | reltuples
-------------------+----------+-----------
          56352768 |     6879 |     1e+06

> TRUNCATE evento;

> SELECT pg_relation_size( 'evento'::regclass ) AS dimensione_fisica, relpages, reltuples
  FROM pg_class  WHERE relkind = 'r' AND relname = 'evento';
 dimensione_fisica | relpages | reltuples
-------------------+----------+-----------
                 0 |        0 |         0
#+end_src

*** Tabella di eventi: statistiche (2)
Ma cosa succede se *fermiamo autovacuum*?

#+begin_src sql
 > INSERT INTO evento( description ) -- 1000000 tuple
...
INSERT 0 1000000

> SELECT pg_relation_size( 'evento'::regclass ) AS dimensione_fisica, relpages, reltuples
  FROM pg_class  WHERE relkind = 'r' AND relname = 'evento';
 dimensione_fisica | relpages | reltuples
-------------------+----------+-----------
          56344576 |        0 |         0
#+end_src

*Il numero di tuple e pagine non è stato aggiornato*.
Che impatto ha questo? Il planner non sarà in grado di capire che "mole di dati" ha davanti!
*** Tabella di eventi: statistiche (3)
Niente panico! E' possibile lanciare *vacuum* manualmente.
#+begin_src sql
> VACUUM FULL VERBOSE evento;
INFO:  vacuuming "public.evento"
INFO:  "evento": found 0 removable, 1000000 nonremovable row versions in 6878 pages
DETAIL:  0 dead row versions cannot be removed yet.
CPU 0.14s/0.30u sec elapsed 0.82 sec.

> SELECT pg_relation_size( 'evento'::regclass ) AS dimensione_fisica, relpages, reltuples
  FROM pg_class  WHERE relkind = 'r' AND relname = 'evento';
 dimensione_fisica | relpages | reltuples
-------------------+----------+-----------
          56344576 |     6878 |     1e+06
#+end_src

* Transazioni
** Livello di isolamento
*** Livelli di isolamento
   Le problematiche sono:
   - *dirty reads*: è possibile vedere (leggere) tuple non ancora committate da altre
     transazioni;
   - *unrepeatable reads*: una tupla riletta piu' volte durante una transazione presenta valori
     modificati da un'altra transazione;
   - *phantom reads*: la stessa query eseguita piu' volta fornisce un resultset modificato (nella
     quantità) da un'altra transazione

*** Livelli di isolamento in PostgreSQL
   PostgreSQL supporta 3 livelli di isolamento sui 4 standard (/read uncommited/, /read committed/,
   /repeatable read/, /serializable/). Questo non rappresenta un problema poiché è sufficiente
   garantire il /livello di isolamento superiore/.

   Una transazione può essere di tipo:
   - *read committed*: /(default)/ uno statement vede solo le tuple consolidate
     prima dell'inizio dello statement stesso;
   - *repeatable read*: ogni statement della transazione può vedere solo le tuple
     consolidate prima dell'esecuzione del primo statement (ovvero, all'inizio della transazione);
   - *serializable*: come *repeatable read* ma impone che le transazioni siano /idempotenti/ rispetto
     al loro effettivo ordine di esecuzione (monitoring di consistenza seriale).
*** Impostare i livelli di isolamento in PostgreSQL
   All'interno di una transazione è possibile impostare il livello
   di isolamento, che però non può essere piu' cambiato dopo l'esecuzione
   di uno statement di modifica (incluso ~SELECT~).
   Quando si avvia una transazione è possibile specificare l'isolation level
   direttamente nel blocco ~BEGIN~, mentre per gli altri casi c'è ~SET TRANSACTION~:

#+begin_src sql
> BEGIN TRANSACTION ISOLATION LEVEL REPEATABLE READ;
> SET TRANSACTION ISOLATION LEVEL SERIALIZABLE;
ERROR:  SET TRANSACTION ISOLATION LEVEL must not be called in a subtransaction
#+end_src
** Casistiche particolari delle transazioni
*** Transazioni ~READ ONLY~ contro ~READ WRITE~
   PostgreSQL permette di specificare due tipi di transazioni:
   - *READ WRITE*: (default) è possibile eseguire ogni statement SQL;
   - *READ ONLY*: è una /promessa/ di non alterare i dati. Tutti i comandi
     generici (~UPDATE, INSERT, DELETE, EXECUTE, ALTER TABLE, VACUUM~, ecc.)
     sono disabilitati a meno che non agiscano su tabelle temporanee.

  *Non c'è nessuna garanzia che una transazione ~READ ONLY~ non effettui scritture su disco!*
*** Transazioni ~DEFERRABLE~
   C'è un caso particolare di transazione: ~DEFERRABLE~.
   Questo si applica solo a transazioni ~READ ONLY~ e ~SERIALIZABLE~.

   L'idea è che la transazione accetta di "attendere" prima della sua esecuzione, e in cambio
   l'overhead di monitoring per la serializzazione è ridotto. Ciò produce dei vantaggi
   per le transazioni di reportistica.

* Stored Procedures & Cursori
** FUNCTION
*** Funzioni
   PostgreSQL permette la creazione di funzioni tramite ~CREATE FUNCTION~.
   Le funzioni possono accettare dei parametri (eventualmente tipizzati e con valori
   di default), possono definire delle variabili (eventualmente tipizzate) e avere
   un valore di ritorno (tipizzato).

   Le funzioni sono create in uno specifico linguaggio, solitamente ~pgpsql~
   e sono identificate dalla loro /signature/.

*** Template di CREATE FUNCTION
#+begin_src sql
CREATE OR REPLACE FUNCTION function_name( <arg>, <arg>, ... )
RETURNS <return type>
AS
-- definition
LANGUAGE language [<volatilità>];
#+end_src

*** Prototiti di funzione
   - la lista di parametri può includere solo i tipi, nel qual caso i parametri sono accessibili con ~$1~, ~$2~, ecc.;
   - i parametri possono includere un valore di default specificato con ~DEFAULT~;
   - i parametri possono essere in ingresso (~IN~, default), in uscita (~OUT~, non importa
     farne il ~RETURN~) o in entrambi (~INOUT~).

*** Volatilità di una funzione
   Le funzioni hanno tre livelli di /volatilità/:
   - ~VOLATILE~: /default/, modifica il database e può dare risultati diversi
     anche se inocata con gli stessi argomenti;
   - ~STABLE~: non modifica il database e ritorna lo stesso valore con gli stessi
     argomenti /per tutte le tuple nello stesso statement/ (è indipendente dal valore
     delle singole tuple), utile per operatori di confronto (es. negli indici);
   - ~IMMUTABLE~: non modifica il database e ritorna lo stesso valore con gli stessi
     argomenti /sempre/.

  Esempi: ~random()~ è ~VOLATILE~, ~current_timestamp~ è ~STABLE~,
  ~version()~ è ~IMMUTABLE~.

** Il linguaggio plpgsql
*** plpgsql
   E' il linguaggio /default/ per la gestione di blocchi di codice:
   - prevede la dichiarazione delle variabili di funzione  con ~DECLARE~;
   - racchiude il body della funzione fra ~BEGIN~ e ~END~
   - consente cicli e istruzioni condizionali.

*** Esempio di semplice funzione: somma
#+begin_src sql
CREATE OR REPLACE FUNCTION somma( int, int )
RETURNS INTEGER
AS
$BODY$
DECLARE --nessun variabile
BEGIN
        RETURN $1 + $2;
END;
$BODY$
LANGUAGE plpgsql;
#+end_src

#+begin_src sql
> select somma( 10, 20 );
 somma
-------
    30
#+end_src

*** Esempio di semplice funzione: somma con alias parametri
   Simile alle /sub/ di Perl 5!
#+begin_src sql
CREATE OR REPLACE FUNCTION somma( int, int )
RETURNS INTEGER
AS
$BODY$
DECLARE
        a ALIAS FOR $1;
        b ALIAS FOR $2;
BEGIN
        RETURN a + b;
END;
$BODY$
LANGUAGE plpgsql;
#+end_src

*** Esempio di semplice funzione: somma con parametri nominali
#+begin_src sql
CREATE OR REPLACE FUNCTION somma( a int, b int )
RETURNS INTEGER
AS
$BODY$
DECLARE
BEGIN
        RETURN a + b;
END;
$BODY$
LANGUAGE plpgsql;
#+end_src

*** Esempio di semplice funzione: somma e sottrazione
#+begin_src sql
CREATE OR REPLACE FUNCTION somma_sottrazione( INOUT a int ,
                                              INOUT b int )
AS $BODY$
DECLARE
BEGIN
        a = a + b;
        b = a - b;
END; $BODY$
LANGUAGE plpgsql;
#+end_src

*** Esempio di semplice funzione: somma e sottrazione (2)
#+begin_src sql
> SELECT somma_sottrazione( 10, 20 );
 somma_sottrazione
-------------------
 (30,10)

> SELECT b, a FROM somma_sottrazione( 10, 20 );
 b  | a
----+----
 10 | 30
#+end_src

*** Esempio di semplice funzione: somma con valori di default
   I valori di default possono essere omessi nella chiamata
   di funzione (*~NULL~ è considerato un valore*):
#+begin_src sql
CREATE OR REPLACE FUNCTION somma( a int DEFAULT 0,
                                  b int DEFAULT 0 )
RETURNS INTEGER
AS $BODY$
DECLARE
BEGIN
        RETURN a + b;
END;
$BODY$
LANGUAGE plpgsql;
#+end_src

#+begin_src sql
 > SELECT somma();
 somma
-------
     0
#+end_src

*** Esempio di semplice funzione: costanti
   E' possibile definire delle costanti in fase di dichiarazione di variabili
   con ~CONSTANT~, ed è opportuno definirne il valore.

#+begin_src sql
CREATE OR REPLACE FUNCTION somma( a int DEFAULT 0,
                                  b int DEFAULT 0 )
RETURNS INTEGER
AS
$BODY$
DECLARE
      c CONSTANT integer := 10;
BEGIN
        RETURN a + b + c;
END;
$BODY$
LANGUAGE plpgsql;
#+end_src

*** Variabili costanti
   Se si cercasse di modificare una variabile costante verrebbe generato
   un errore di compilazione della funzione:
#+begin_src sql
psql:functions.sql:43: ERROR:  "c" is declared CONSTANT
LINE 38:  c := a + b;
          ^
#+end_src

*** Variabili ROWTYPE
Alcune variabili possono essere dichiarate con l'attributo ~%rowtype~ specificando
la tabella a cui fanno riferimento.
Le variabili di fatto rappresentano una tupla (strutturata) della tabella dichiarata.
#+begin_src sql
DECLARE
  my_record persona%rowtype;
BEGIN
 my_record.nome = 'Luca';
 my_record.eta  = 39;
...-- return next etc.
END;
#+end_src
*** Variaibili RECORD
Le variabili ~record~ sono la generalizzazione di quelle ~rowtype~: possono contenere
un record estratto da una qualsiasi tabella e assumeranno la struttura di quella tupla,
*ma prima del loro assegnamento non possono essere usate*.

Le si possono assegnare piu' volte a tuple di struttura differente.
*** Funzioni che ritornano tuple
Ci sono due modi per dichiarare una funzione che ritorna una o piu' tuple:
- ~RETURNS RECORD~ restituisce una singola tupla contenuta in un ~record~ (questo ad esempio
  è il caso con parametri ~OUT~);
- ~RETURNS SETOF~ restituisce piu' tuple di un tipo specificato (es. di una tabella).
*** RETURN NEXT e RETURN QUERY
Le funzioni che ritornano un ~SETOF~ possono usare ~RETURN NEXT~ per appendere un nuovo record
al result set. Una volta conclusa la costruzione del result set si usa un normale ~RETURN~
per uscire dalla funzione.

Alternativamente si può usare ~RETURN QUERY~ per inserire nel result set il risultato
di una query.

*** RETURN NEXT: esempio
#+begin_src sql
CREATE OR REPLACE FUNCTION find_maggiorenni()
RETURNS SETOF persona AS $BODY$
DECLARE
  current_maggiorenne persona%rowtype;
BEGIN
  FOR current_maggiorenne IN
        SELECT * FROM persona WHERE eta >= 18
  LOOP
          RETURN NEXT current_maggiorenne;
  END LOOP;

  RETURN;
END;
$BODY$ LANGUAGE plpgsql;
#+end_src

*** RETURN QUERY: esempio
*** IF...ELSE
#+begin_src sql
  IF eta >= 18 THEN
       RETURN 'maggiorenne';
  ELSIF eta >= 10 THEN
       RETURN 'teen-ager';
  ELSE
      RETURN 'bimbo';
  END IF;
#+end_src
*** Cicli
I cicli hanno tutti una parola chiave ~LOOP~ e finiscono con ~END LOOP~.

E' possibile specificare una etichetta per identificare il ciclo, l'etichetta deve:
- essere dichiarata prima del ciclo fra doppie parentesi angolari (es. ~<<CICLO_1>>~);
- essere inclusa nella chiusura del ciclo (es. ~END LOOP CICLO1~).
*** LOOP
Ciclo (con eventuale etichetta). Può essere annidato.

Due operatori sintatticamente simili controllano il flusso:
- ~CONTINUE~ ricomincia l'iterazione dall'etichetta specificata (o dal ciclo corrente) quando la condizione ~WHEN~ si verifica;
- ~EXIT~ esce (termina) il ciclo specificato dall'etichetta (o quello corrente) quando la condizione ~WHEN~ viene soddisfatta.

*** LOOP: esempio
#+begin_src sql
<<LP_ETA>>
  LOOP
     eta := eta + 1;
     EXIT LP_ETA WHEN eta >= 18;
  END LOOP LP_ETA;
#+end_src
oppure semplificando:
#+begin_src sql
  LOOP
     eta := eta + 1;
     EXIT  WHEN eta >= 18;
  END LOOP;
#+end_src
*** WHILE
Analogo al ciclo /while/ di ogni linguaggio di programmazione, è un ~LOOP~ con ~EXIT~ integrata!
Può includere una etichetta.
#+begin_src sql
<<LP_ETA>>
  WHILE eta <= 18 LOOP
     eta := eta + 1;
  END LOOP LP_ETA;
#+end_src

*** FOR
Analogo al ciclo /for/ del linguaggio C, senza la definizione di incremento diventa un /foreach/:
#+begin_src sql
<<LP_ETA>>
  FOR current_eta IN 18..30 LOOP
     RAISE INFO 'vALORE %', current_eta;
  END LOOP LP_ETA;
#+end_src
o analogamento al ciclo for del linguaggio C:
#+begin_src sql
  FOR current_eta IN 18..30 BY 2 LOOP
     RAISE INFO 'vALORE %', current_eta;
  END LOOP LP_ETA;
#+end_src

*** FOREACH
Itera fra gli elementi di un array. Segue le stesse regole sintattiche del ciclo ~FOR~ (etichetta, ecc).
#+begin_src sql
 FOREACH current_version IN ARRAY v_array LOOP
    RAISE INFO 'Version %', current_version;
 END LOOP;
#+end_src

*** FOR IN query
Quando si deve iterare sul result set di una query la sintassi è ~FOR IN <query>~:
#+begin_src sql
FOR my_record IN SELECT * FROM persona LOOP
END LOOP;
#+end_src
oppure la variante con ~EXECUTE~ se la query viene specificata da una stringa:
#+begin_src sql
query_string := 'SELECT * FROM persona';
FOR my_record IN EXECUTE query_string LOOP
END LOOP;
#+end_src

#+begin_src sql
CREATE OR REPLACE FUNCTION find_maggiorenni()
RETURNS SETOF persona
AS $BODY$
DECLARE
        current_maggiorenne persona%rowtype;
BEGIN
        RETURN QUERY SELECT * FROM persona WHERE eta >= 18;
        RETURN;
END;
$BODY$ LANGUAGE plpgsql;
#+end_src

*** Eccezioni
Il blocco ~BEGIN...END~ di una funzione permette l'opzionale ~EXCEPTION~ che funziona
da /catch/ per le eccezioni. Al suo interno l'eccezione viene cercata fra quelle specificate
nelle clausole ~WHEN~.

*Se nessuna clausola ~WHEN~ di ~EXCEPTION~ fa match, o se il blocco ~EXCEPTION~ non è stato specificato, la funzione termina con errore!*

Le eccezioni possibili sono /etichettate/ e definite alla pagina
<https://www.postgresql.org/docs/9.6/static/errcodes-appendix.html>
come ad esempio ~division_by_zero~.

*Il sistema mantiene lo stato delle variabili al momento in cui si verifica l'errore*, l'uso di un blocco
~EXCEPTION~ è /costoso/ per il sistema, quindi non va usato ove non si possono verificare o non interessa
catturare eccezioni.

*** Eccezioni: variabili diagnostiche
All'interno di un blocco ~EXCEPTION~ le variabili speciali ~SQLSTATE~ e ~SQLERRM~ contengono lo stato e il messaggio
associato all'errore generato.

E' inoltre possibile usare il comando ~GET_STACKED_DIAGNOSTIC~ per estrarre ulteriori informazioni circa
l'errore di esecuzione (es. su quale tabella, colonna, constraint, ecc.).

*** Eccezioni: esempio
#+begin_src sql
BEGIN
    RETURN divide_what / divide_by;
EXCEPTION
    WHEN division_by_zero THEN
      RAISE INFO 'Divisione per zero';
      RAISE INFO 'Errore % %', SQLSTATE, SQLERRM;
      RETURN 0;
END;
#+end_src

*** PERFORM: il problema
Se in una stored procedure si utilizza una query che ritorna dei risultati,
ma si vuole scartare l'insieme dei risultati stessi, occorre usare ~PERFORM~.
In altre parole: *nelle stored procedures è possibile usare ogni comando SQL che non ritorni risultati o dove i risultati siano /memorizzati in variabili/ (anche di iterazione)*.

#+begin_src sql
CREATE OR REPLACE FUNCTION do_select()
RETURNS VOID AS $BODY$
DECLARE
BEGIN
        SELECT * FROM persona;
END;
$BODY$ LANGUAGE plpgsql;
#+end_src

#+begin_src sql
> SELECT do_select();
ERROR:  query has no destination for result data
HINT:  If you want to discard the results of a
SELECT, use PERFORM instead.
#+end_src

*** PERFORM: la soluzione
#+begin_src sql
CREATE OR REPLACE FUNCTION do_select()
RETURNS VOID
AS $BODY$ DECLARE
BEGIN
        PERFORM  * FROM persona;
END;
$BODY$ LANGUAGE plpgsql;
#+end_src

*** PERFORM vs SELECT                                          :B_definition:
    *PERFORM* sostituisce *SELECT* in una query!
*** End of block                                               :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:

*** SELECT INTO
E' possibile assegnare a una (o piu') variabili il risultato di una ~SELECT~
specificando appunto la lista di variabile ove inserire (~INTO~) il risultato, considerando
che:
- se la query ritorna piu' di una riga e non è specificato ~STRICT~ allora solo la prima tupla
  viene inserita nelle variabili e la query termina (ossia ~SELECT INTO~ esegue un implicito
  ~LIMIT 1~);
- se la query ritorna piu' di una riga ed è specificato ~STRICT~ allora si ha un errore di esecuzione
  (ossia *~STRICT~ impone che la query fornisca una sola tupla*).
*** SELECT INTO: esempio senza STRICT
#+begin_src sql
CREATE OR REPLACE FUNCTION do_select()
RETURNS VOID AS $BODY$
DECLARE
        v_nome text;
        v_cognome text;
BEGIN
        SELECT nome, cognome
        INTO v_nome, v_cognome
        FROM persona;

        RAISE INFO 'Trovati % %',
                    v_nome,
                    v_cognome;
END;
$BODY$ LANGUAGE plpgsql;
#+end_src
*** SELECT INTO: esempio senza STRICT (2)
#+begin_src sql
> SELECT count(*) FROM persona;
 count
-------
     4 -- ci sono 4 persone!
> SELECT do_select();
INFO:  Trovati EMANUELA SANTUNIONE
#+end_src
*** SELECT INTO: errore di STRICT
Se la query viene eseguita con ~STRICT~ si ottiene un errore di esecuzione:

#+begin_src sql
> SELECT do_select();
ERROR:  query returned more than one row
#+end_src

*** SELECT INTO: esempio con STRICT
#+begin_src sql
CREATE OR REPLACE FUNCTION do_select()
RETURNS VOID AS $BODY$
DECLARE
        v_nome text;
        v_cognome text;
BEGIN
        SELECT nome, cognome
        INTO STRICT v_nome, v_cognome
        FROM persona
        WHERE codice_fiscale = 'FRRLCU78L19F257B';

        RAISE INFO 'Trovati % %',
                   v_nome,
                   v_cognome;
END;
$BODY$ LANGUAGE plpgsql;
#+end_src
Si filtra sulla chiave per ottenere esattamente un record!

*** EXECUTE
Il comando ~EXECUTE~ consente l'esecuzione di query costruite al volo (/no-caching/)
in formato stringa.
Il comando permette la sotituzione di variabili all'iterno della stringa di query:
- le variabili sono identificate con ~$1~, ~$2~, ecc.;
- il comando deve avere una forma con ~USING~ seguito dalla lista dei parametri da sostituire.

*I parametri possono essere usati solo per dei dati, per i nomi di tabella/colonna si deve effettuare una concatenazione di stringa!*

Inoltre ~EXECUTE~ permette di effettuare un ~INTO [STRICT]~ come una normale ~SELECT~.
*** EXECUTE: esempio
#+begin_src sql
-- SELECT do_count( 2, 'persona' );
CREATE OR REPLACE FUNCTION do_count( pk int, tabella text)
RETURNS integer
AS $BODY$ DECLARE
        v_count int;
BEGIN
        EXECUTE 'SELECT count(*) FROM '
                 || tabella
                 || ' WHERE pk >= $1'
        INTO STRICT v_count
        USING pk;

        RETURN v_count;
END;
$BODY$ LANGUAGE plpgsql;
#+end_src

** Cursori
*** Cos'è un cursore?
Un cursore è un meccanismo che trasforma un record-set in una iterazione fra record: non si ottiene
piu' l'insieme dei risultati in un unico blocco ma si /scorre/ il risultato tupla per tupla.

I cursori sono di due tipologie:
- /bound/ sono dichiarati con la relativa query a cui fanno riferimento;
- /unbound/ sono dichiarati senza la query, che sarà fornita successivamente.

*Tutti i cursori sono di tipo ~refcursor~, ma solo quelli /unbound/ vengono esplicitamente dichiarati come tali*.
Un cursorse si dice /scrollable/ se può scorrere le tuple in avanti e indietro.
*** Workflow di un cursore
Solitamente il workflow è il seguente:
1. dichiarazione (bound/unbound);
2. ~OPEN~ indica che si vuole usare il cursore;
3. ~FETCH~ preleva una tupla dalla query (imposta la variabile ~FOUND~ di conseguenza);
   - ~MOVE~
   - ~INSERT~ o ~UPDATE~
4. ~CLOSE~ si è finito di usare il cursore, le risorse sono liberate.
*** Esempio di cursore
#+begin_src sql
CREATE OR REPLACE FUNCTION do_cursor()
RETURNS int AS $BODY$
DECLARE
   counter int := 0;
   my_curs CURSOR FOR SELECT * FROM persona;
   my_record persona%rowtype;
BEGIN
    OPEN my_curs;
    FETCH my_curs INTO my_record;
    WHILE FOUND
    LOOP
      IF my_record.eta >= 18
      THEN
         counter := counter + 1;
      END IF;
      FETCH my_curs INTO my_record;
    END LOOP;

     CLOSE my_curs;
     RETURN counter;
END;
$BODY$ LANGUAGE plpgsql;
#+end_src
*** Esempio di cursore parametrico
#+begin_src sql
CREATE OR REPLACE FUNCTION do_cursor()
RETURNS int AS $BODY$
DECLARE
        counter int := 0;
        my_curs CURSOR (s_eta int)
             FOR SELECT * FROM persona
                 WHERE eta >= s_eta;
        my_record persona%rowtype;
BEGIN
        OPEN my_curs( 18 );
        FETCH my_curs INTO my_record;
        WHILE FOUND
        LOOP
          counter := counter + 1;
          FETCH my_curs INTO my_record;
        END LOOP;

     CLOSE my_curs;
     RETURN counter;
END; $BODY$ LANGUAGE plpgsql;
#+end_src
*** Esempio di cursore unbound
#+begin_src sql
CREATE OR REPLACE FUNCTION do_cursor()
RETURNS int AS $BODY$
DECLARE
        counter int := 0;
        my_curs refcursor;
        my_record persona%rowtype;
BEGIN
        OPEN my_curs FOR
            SELECT * FROM persona
            WHERE eta >= 18;
        FETCH my_curs INTO my_record;
        WHILE FOUND
        LOOP
          counter := counter + 1;
          FETCH my_curs INTO my_record;
        END LOOP;

     CLOSE my_curs;
     RETURN counter;
END;
$BODY$ LANGUAGE plpgsql;
#+end_src
*** Ciclo "automatico" su cursore
Invece che il workflow ~OPEN~, ~FETCH~, ~LOOP~, ~CLOSE~ si può usare
il ciclo ~FOR~ che riduce le operazioni necessaire al solo ~LOOP~.

*Con ~FOR~ non si usa ~OPEN~, ~CLOSE~, ~FETCH~*!
*** Esempio di ciclo "automatico" su cursore
#+begin_src sql
CREATE OR REPLACE FUNCTION do_cursor()
RETURNS int AS $BODY$
DECLARE
        counter int := 0;
        my_curs CURSOR FOR
          SELECT * FROM persona
          WHERE eta >= 18;
        my_record persona%rowtype;
BEGIN
   FOR my_record IN my_curs
   LOOP
     counter := counter + 1;
   END LOOP;
  RETURN counter;
END; $BODY$ LANGUAGE plpgsql;
#+end_src
*** Capire FETCH
L'istruzione ~FETCH~ permette di specificare la direzione e il posizionamento assoluto o relativo.
La direzione viene specificata con ~FORWARD~ (default) o ~BACKWARD~.
Il posizionamento viene specificato con ~FIRST~, ~LAST~, ~ABSOLUTE n~ e ~RELATIVE n~.
*** Esempio di spostamento con FETCH: lettura all'indietro
#+begin_src sql
     OPEN my_curs;
     FETCH LAST FROM my_curs INTO my_record;
     WHILE FOUND
     LOOP
        IF my_record.eta >= 18 THEN
          counter := counter + 1;
        END IF;
        FETCH BACKWARD FROM my_curs INTO my_record;
     END LOOP;
     CLOSE my_curs;
#+end_src
*** Esempio di spostamento con FETCH: lettura all'indietro ogni due record
#+begin_src sql
     OPEN my_curs;
     FETCH LAST FROM my_curs INTO my_record;
     WHILE FOUND
     LOOP
        IF my_record.eta >= 18 THEN
          counter := counter + 1;
        END IF;
        FETCH RELATIVE -2 FROM my_curs INTO my_record;
     END LOOP;
     CLOSE my_curs;
#+end_src
*** UPDATE/DELETE FOR CURRENT
E' possibile eseguire un aggiornamento/cancellazione di una tupla su cui è posizionato il cursore.
La sintassi è ~UPDATE <table> SET <cols> WHERE CURRENT OF <cursor>~ o nel caso
di una cancellazione ~DELETE FROM <table> WHERE CURRENT OF <cursor>~.

#+begin_src sql
 OPEN my_curs;
  FETCH LAST FROM my_curs INTO my_record;
  WHILE FOUND
  LOOP
     IF my_record.eta >= 18 THEN
       counter := counter + 1;
     ELSE
       UPDATE persona set valid = false
            WHERE CURRENT OF my_curs;
     END IF;
     FETCH RELATIVE -2 FROM my_curs INTO my_record;
  END LOOP;
  CLOSE my_curs;
#+end_src
* Triggers
** Triggers DML
*** Introduzione ai triggers
   PostgreSQL supporta (da sempre) i trigger a livello di /statement/ o /tupla/
   sia per esecuzione prima (before) o dopo (after). Sulle viste agiscono
   i trigger /INSTEAD OF/.

   In PostgreSQL i trigger vengono definiti con un workflow ben definito:
   1. definire una funzione (tipicamente in ~plpgsql~) che *non accetta alcun
      argomento e ritorna un valore di tipo ~trigger~*;
   2. si /aggancia/ la funzione ad un evento scatenato su una tabella (tramite
      ~CREATE TRIGGER~).
*** Tipologia di trigger
I trigger possono essere eseguiti per ~statment~ o per ~riga~.
Nel caso di esecuzione a livello di statement il valore di ritorno del trigger
è ignorato (~NULL~), nel caso di esecuzione per riga il valore di ritorno
può essere ~NULL~ per indicare che l'oeprazione deve abortire o ritornare una
tupla (~NEW~, ~OLD~) per inserimento/modifica.

*** Tiplogia di trigger (riassunto)
   | Statement SQL                | Quando       | A livello di                                   |
   |------------------------------+--------------+------------------------------------------------|
   | ~INSERT~, ~UPDATE~, ~DELETE~ | /BEFORE/     | *tupla* su tabelle e FK                        |
   |                              | /AFTER/      | *tupla* su tabelle e FK                        |
   |------------------------------+--------------+------------------------------------------------|
   | ~INSERT~, ~UPDATE~, ~DELETE~ | /BEFORE/     | *statement* su tabelle (anche esterne) e viste |
   |                              | /AFTER/      | *statement* su tabelle (anche esterne) e viste |
   |------------------------------+--------------+------------------------------------------------|
   | ~TRUNCATE~                   | /BEFORE/     | *statement* su tabelle                         |
   |                              | /AFTER/      | *statement* su tabelle                         |
   |------------------------------+--------------+------------------------------------------------|
   | ~INSERT~, ~UPDATE~, ~DELETE~ | /INSTEAD OF/ | *tupla* su vista                               |
   |------------------------------+--------------+------------------------------------------------|

*** Esecuzione dei trigger
   I trigger sono eseguiti in ordine alfabetico (per tipologia di evento).

   I trigger ~BEFORE~ vengono eseguiti *prima del controllo delle constraint*, analogamente
   i trigger ~AFTER~ dopo l'esecuzione e quindi *dopo il controllo delle constraint*.

   I trigger vedono sempre la tupla di uscita ~NEW~ (quella che verrà /memorizzata/) e se sono
   per update anche quella di ingresso ~OLD~ (quella che si sta aggiornando).

   Il tipo di  operazione che ha fatto scattare il trigger è disponibile tramite la stringa ~TR_OP~, il
   numero di argomenti del trigger tramite ~TG_NARGS~ e i singoli argomenti nell'array di stringhe
   ~TG_ARGV~.

*** Esempio di trigger: descrizione
   Si vuole creare un semplice trigger che, al momento di inserimento o aggiornamento di una tupla
   della tabella ~persona~, controlli che l'età inserita sia coerente con quella del relativo
   codice fiscale e la "auto-corregga" calcolandola dall'anno attuale.

*** Esempio di trigger: funzione
#+begin_src sql
CREATE OR REPLACE FUNCTION tr_check_eta()
RETURNS TRIGGER
AS $BODY$
DECLARE
        current_eta integer;
        current_year integer;
BEGIN
  IF NEW.codice_fiscale IS NOT NULL THEN
       current_eta  = to_number(
                       substring( NEW.codice_fiscale FROM 7 FOR 2 ),
                      '99' );
       current_year = to_number( to_char( current_date, 'YY' ),
                      '99' );
       IF current_year < current_eta THEN
          current_eta = current_year + 100 - current_eta;
       END IF;
  END IF;
#+end_src

*** Esempio di trigger: funzione (2)
#+begin_src sql
  IF TG_OP = 'INSERT' THEN
       NEW.eta = current_eta;
       RAISE INFO 'Calcolo eta'' INSERT = %', current_eta;
       RETURN NEW;
   END IF;

  IF TG_OP = 'UPDATE' THEN
     IF OLD.eta > NEW.eta OR NEW.eta <= 0 THEN
        RAISE INFO 'Aggiusto eta'' UPDATE da % a %', OLD.eta, current_eta;
        NEW.eta = current_eta;
     END IF;
  END IF;

END;
$BODY$
LANGUAGE plpgsql VOLATILE;
#+end_src

*** Esempio di trigger: aggancio alla tabella
#+begin_src sql
> CREATE TRIGGER tr_persona_eta
  BEFORE INSERT OR UPDATE
  ON persona
  FOR EACH ROW
  EXECUTE PROCEDURE tr_check_eta();
#+end_src

*** Esempio di trigger: esecuzione
#+begin_src sql
> INSERT INTO persona( nome, cognome, codice_fiscale )
VALUES( 'Luca', 'Ferrari', 'FRRLCU78L19F257B' );
INFO:  Calcolo eta' INSERT = 39

> UPDATE persona SET eta = 10 WHERE codice_fiscale = 'FRRLCU78L19F257B';
INFO:  Aggiusto eta' UPDATE da 39 a 39
#+end_src

*** Esempio di trigger: agganciarlo a una colonna
   Il trigger di esempio non dovrebbe scattare per ogni ~UPDATE~ incondizionato, ma solo
   per gli ~UPDATE~ che coinvolgono la colonna ~eta~ o ~codice_fiscale~.
   E' possibile specificare a quali colonne il trigger deve essere agganciato:

#+begin_src sql
>  DROP TRIGGER tr_persona_eta ON persona;
> CREATE TRIGGER tr_persona_eta
  BEFORE INSERT OR UPDATE OF eta, codice_fiscale
  ON persona
  FOR EACH ROW
  EXECUTE PROCEDURE tr_check_eta();
#+end_src

*** Esempio di trigger: aggancio a una colonna (2)
   Il trigger scatta ora solo per gli aggiornamenti delle colonne specificate:
#+begin_src sql
> UPDATE persona SET eta = 10 WHERE codice_fiscale = 'FRRLCU78L19F257B';
INFO:  Aggiusto eta' UPDATE da 39 a 39

> UPDATE persona SET nome = 'LUCA' WHERE codice_fiscale = 'FRRLCU78L19F257B';
-- non è scattato il trigger!
#+end_src

*** Trigger parametrici
   E' possibile passare dei parametri alla funzione di un trigger, tali
   parametri saranno visibili tramite l'array ~TG_ARGV~.
   *I parametri sono letterali e convertiti sempre a stringa*.

*** Esempio di trigger parametrico: funzione con parametro
La funzione dell'esempio precedente può essere modificata per accettare
l'età da usare come default:

#+begin_src sql
CREATE OR REPLACE FUNCTION tr_check_eta()
RETURNS TRIGGER
AS $BODY$
DECLARE
        current_eta integer;
        current_year integer;
BEGIN
        IF TG_NARGS > 0 THEN
           current_eta := to_number( TG_ARGV[ 0 ], '99' );
        ELSE
           current_eta := -1;
        END IF;
...
#+end_src

*** Esempio di trigger parametrico: aggancio
#+begin_src sql
> CREATE TRIGGER tr_persona_eta
  BEFORE INSERT OR UPDATE OF eta, codice_fiscale
  ON persona
  FOR EACH ROW EXECUTE PROCEDURE tr_check_eta( 10 );

> UPDATE persona SET eta = 10, codice_fiscale = NULL
  WHERE codice_fiscale = 'FRRLCU78L19F257B';
INFO:  Aggiusto eta' UPDATE da 39 a 10
#+end_src
** Tiggers DDL
*** Introduzione ai trigger DDL
PostgreSQL permette di definire dei trigger per /eventi/ di DDL, ovvero
~CREATE~, ~DROP~, ~ALTER~, ~COMMENT~, ~GRANT~, ~REVOKE~.
Gli istanti in cui si possono intercettare gli eventi sono:
- ~ddl_command_start~: appena il comando viene avviato, senza alcun controllo
  sull'esistenza dell'oggetto a cui si applica;
- ~ddl_command_end~: appena il comando è finito (quindi i cataloghi di sistema
  sono stati aggiornati ma non ancora consolidati);
- ~table_rewrite~: si effettua un ~ALTER [TABLE | TYPE]~ su una tabella;
- ~sql_drop~: il comando ~DROP~ ha rimosso dal catalogo di sistema degli oggetti.

*Bisogna essere superutenti!*
*** Creazione di un event trigger
Le regole sono simili a quelle di un trigger normale:
1. si crea una funzione che deve ritornare un tipo ~event_trigger~. *Il valore di ritorno è solo un marcaposto, questi trigger non ritornano alcun valore!*
2. si aggancia il trigger all'evento con ~CREATE EVENT TRIGGER~;
3. si possono usare alcune funzioni di utilità per scoprire /cosa/ sta accadendo e cosa ha /scatenato/ il trigger (non esistono
   al momento variabili speciali da interrogare ma solo funzioni di catalogo).
*** Dati interni di un event trigger
Ci sono delle funzioni speciali che ritornano delle tuple contenenti le informazioni
di come un trigger è stato invocato:
- ~pg_event_trigger_ddl_commands()~ per ~ddl_command_start~ e ~ddl_command_stop~;
- ~pg_event_trigger_dropped_objects()~ per ~sql_drop~;
- ~pg_event_trigger_table_rewrite_oid()~ per ~table_rewrite~.
*** Esempio di event trigger
#+begin_src sql
CREATE OR REPLACE FUNCTION ddl_start_end()
RETURNS EVENT_TRIGGER AS
$BODY$
DECLARE
        command record;
BEGIN
   RAISE INFO 'event trigger fired!';
   FOR command IN SELECT * FROM pg_event_trigger_ddl_commands()
   LOOP
           RAISE INFO 'Comando % su %',
                 command.command_tag,
                 command.object_identity;
   END LOOP;
END; $BODY$
LANGUAGE plpgsql;
#+end_src
*** Esempio di esecuzione con event trigger
#+begin_src sql
# CREATE EVENT TRIGGER tr_start_end
  ON ddl_command_start
  EXECUTE PROCEDURE ddl_start_end();

# ALTER TABLE testddl ADD COLUMN foo int;
INFO:  event trigger fired!
INFO:  Comando ALTER TABLE su public.testddl
ALTER TABLE
#+end_src
*** Esempio di even trigger (drop)
#+begin_src sql
CREATE OR REPLACE FUNCTION ddl_drop_fn()
RETURNS EVENT_TRIGGER AS $BODY$
DECLARE
        dropping record;
BEGIN
        RAISE INFO 'event trigger fired!';
        FOR dropping IN SELECT * FROM pg_event_trigger_dropped_objects()
        LOOP
                RAISE INFO 'drop % di %',
                      tg_tag, -- cosa si droppa?
                      dropping.object_identity;
        END LOOP;
END; $BODY$ LANGUAGE plpgsql;
#+end_src

*** Esecuzione di event trigger (drop)
#+begin_src sql
# CREATE EVENT TRIGGER tr_drop
  ON sql_drop
  EXECUTE PROCEDURE ddl_drop_fn();
#+end_src
*** Esecuzione di event trigger (drop)
#+begin_src sql
# DROP TABLE testddl;
INFO:  event trigger fired! -- ddl_command_start
INFO:  drop DROP TABLE di public.testddl
INFO:  drop DROP TABLE di testddl_pkey on public.testddl
INFO:  drop DROP TABLE di public.testddl_pkey
INFO:  drop DROP TABLE di public.testddl_pk_seq
INFO:  drop DROP TABLE di public.testddl_pk_seq
INFO:  drop DROP TABLE di for public.testddl.pk
INFO:  drop DROP TABLE di public.testddl
INFO:  drop DROP TABLE di public.testddl[]
INFO:  drop DROP TABLE di pg_toast.pg_toast_16508
INFO:  drop DROP TABLE di pg_toast.pg_toast_16508_index
INFO:  drop DROP TABLE di pg_toast.pg_toast_16508
INFO:  event trigger fired! -- ddl_command_end
#+end_src

* Grant/Revoke
** Grant in PostgreSQL
PostgreSQL distingue due tipi principali di ~GRANT~ e conseguentemente di ~REVOKE~:
- su un oggetto di database (es. tabella), nel qual caso anche a livello di colonna;
- su un ruolo (ovvero gestione dei gruppi).

La parola ~PUBLIC~ indica tutti gli utenti, mentre la parola chiave ~ALL~ indica tutti i
tipi di permessi.
Per agire a livello globale (/pericoloso!/):
#+begin_src sql
> REVOKE ALL ON <oggetto> FROM PUBLIC;
> GRANT ALL ON <oggetto> TO PUBLIC;
#+end_src
** Grant di grant
Il proprietario di un oggetto ha per definizione tutti i permessi
sull'oggetto che ha creato.

Chi possiede il permesso ~GRANT~ può concedere lo stesso permesso
ad altri ruoli: si può quindi non solo abitare agli oggetti, ma anche
alle abilitazioni stesse verso altri utenti.
** Esempio di permessi di colonna
#+begin_src sql
# REVOKE ALL ON software FROM PUBLIC;
# GRANT SELECT(name) ON software TO luca;
#+end_src
e come utente ~luca~:
#+begin_src sql
> SELECT name FROM software; --OK!
> SELECT name, versions FROM software;
ERROR:  permission denied for relation software
#+end_src
** OWNED
Esistono comandi appositi per /passare/ un oggetto da un ruolo ad un altro e per
eliminare tutti gli oggetti posseduti da un determinato ruolo. La parola chiave
~CURRENT_USER~ identifica l'utente corrente.
#+begin_src sql
> REASSIGN OWNED BY CURRENT_USER TO dba;
-- drop altri oggetti
> DROP OWNED BY dismissed;
#+end_src

*Tipicamente si usano questi comandi prima della cancellazione di un ruolo!*
** Row Level Security
E' possibile specificare, tabella per tabella, una sicurezza a livello
di tupla, denominata /Row Level Security/.

La Row Level Security si basa su delle /policy/ che devono discriminare quali dati
mostrare/nascondere. Se nessuna policy viene creata si usa un default di /deny all/.
** Row Level Security: esempio
#+begin_src sql
> CREATE POLICY view_maggiorenni
  ON persona
  FOR SELECT  -- quale statement?
  TO PUBLIC   -- quale ruolo ?
  USING  (eta >= 18); -- condizione di SELECT

> ALTER TABLE persona ENABLE ROW LEVEL SECURITY;
#+end_src
e come altro utente si vedranno solo le tuple che soddisfano ~USING~.
** Row Level Security: spiegazione
Anzitutto l'utente che effettua lo statement deve avere le opportune ~GRANT~.
*Il proprietario dell'oggetto non è soggetto alle policy*.

Nel caso di statement ~SELECT~ la condizione è data da ~USING~, nel caso di
~INSERT~ o ~UPDATE~ da ~CHECK~, e si può combinare tutto quanto assieme:

#+begin_src sql
> CREATE POLICY handle_maggiorenni
  ON persona
  FOR ALL  -- SELECT, UPDATE, DELETE, INSERT
  TO PUBLIC   -- quale ruolo ?
  USING  (eta >= 18) -- condizione di SELECT
  WITH CHECK (eta >= 18); -- condizione DDL
#+end_src
** Row Level Security: un altro esempio
Tipicamente questo meccanismo viene usato per nascondere le tuple
di altri utenti:

#+begin_src sql
> CREATE POLICY handle_my_tuples
  ON usernames
  FOR ALL  -- SELECT, UPDATE, DELETE, INSERT
  TO PUBLIC   -- quale ruolo ?
  USING  (usernam >= CURRENT_USER) -- condizione di SELECT
  WITH CHECK (usernam >= CURRENT_USER); -- condizione DDL
#+end_src

* Viste & Rules
** Viste
*** Tipologie di viste
Esistono due tipi principali di viste:
- /viste dinamiche/: effettuano la query al momento propagandola alle tabelle
  di definizione della vista;
- /materializzate/: contengono una versione memorizzata dei dati prelevati
  dalle tabelle sottostanti e necessitano di essere aggiornata (refresh).
*** Viste dinamiche
Si definisce la vista attraverso una query (che può includere join, order-by, ecc):
#+begin_src sql
> CREATE VIEW vw_persona
  AS
  SELECT upper( cognome ), nome, eta
  FROM persona
  ORDER BY cognome, nome;

> SELECT * FROM vw_persona;
#+end_src
*** Viste materializzate
Si utilizza il comando ~CREATE MATERIALIZED VIEW~ specificando se prelevare subito i dati (~WITH DATA~)
o no (~WITH NO DATA~). In quest'ultimo caso la vista deve prima essere sottoposta a ~REFRESH~ per essere utilizzata.
#+begin_src sql
> CREATE MATERIALIZED VIEW vw_m_persona
  AS SELECT upper( cognome ), nome
  FROM persona
  ORDER BY cognome, eta
  WITH NO DATA;

 > SELECT * FROM vw_m_persona;
ERROR:  materialized view "vw_m_persona"
        has not been populated
#+end_src

*** Popolare e fare refresh di una vista materializzata
Il comando ~REFRESH MATERIALIZED VIEW~ viene usato per popolare la vista materializzata.
Sostanzialmente il comando effettua:
- un ~TRUNCATE~ della vista (quindi i dati precedenti sono persi);
- un /lock/ della vista (che quindi non può essere usata fino a che il refresh non è terminato;
- una esecuzione della query di definizione della vista per popolarla con i dati.

Per evitare il /lock/ si può usare ~CONCURRENTLY~, così che la vista possa essere letta mentre viene
popolata.
Se si specifica ~WITH NO DATA~ la query non viene eseguita e la vista ritorna ad uno stato
non usabile fino al prossimo refresh.
*** Popolare (e ripopolare) la vista materializzata
#+begin_src sql
> REFRESH MATERIALIZED VIEW vw_m_persona;
-- equivalente a
> REFRESH MATERIALIZED VIEW vw_m_persona WITH DATA;
#+end_src
*** Popolare una vista materializzata senza lock
Per usare ~CONCURRENTLY~ nel refresh si deve avere un indice /unique/ su almeno una colonna
della vista, e non lo si può usare per il primo popolamento della vista.
#+begin_src sql
> CREATE UNIQUE INDEX idx_vw_m_persona_nome
  ON vw_m_persona( nome );

> REFRESH MATERIALIZED
  VIEW CONCURRENTLY vw_m_persona
  WITH DATA;
#+end_src

** Rules
*** Introduzione alle rules
Le *rules* sono definite anche *query rewrite system*.
Le rules consentono la riscrittura al volo delle query (anticipando anche i trigger)
e quindi di rimbalzare una query da un oggetto ad un altro o espandere una query
in piu' di una.

*A differenza di un trigger, una rule può intercettare una ~SELECT~!*
*** Parametri di una rule
Una rule deve specificare:
- un /evento/ ovvero ~SELECT~, ~INSERT~, ~UPDATE~, ~DELETE~;
- la tabella a cui l'evento si applica (ossia su quale tabella il comando è stato eseguito);
- una eventuale /condizione/ che può referenziare ~OLD~ e ~NEW~ come alias delle tabelle originali
  e verso cui rimbalzare la query;
- il /comando/ da eseguire come ~INSTEAD~ o ~ALSO~.

*Le viste sono realizzate come una rule ~INSTEAD~!*
*** Esempio di una rule: DELETE
#+begin_src sql
> CREATE OR REPLACE RULE r_delete_persona
  AS ON DELETE TO persona
  DO INSTEAD
    UPDATE persona
    SET valid = false
    WHERE OLD.pk = pk;
#+end_src
*** Esempio di rule: INSERT
#+begin_src sql
 > CREATE OR REPLACE RULE r_insert_persona
   AS ON INSERT
   TO persona
   DO ALSO
    INSERT INTO log( message )
    VALUES ( 'Inserimento/aggiornamento tupla '
             || NEW.cognome || ' '
             || NEW.nome );
#+end_src
*** Rules "_RETURN"
La rule per una select è speciale e viene denominata ~"_RETURN"~ (ce ne può essere solo una)
e deve essere eseguita su una tabella vuota. E' il modello con il quale PostgreSQL realizza
le viste dinamiche.

Il workflow è:
1. creare una tabella *vuota* con le stesse colonne della tabella finale;
2. definire la rule ~"_RETURN"~ con ~DO INSTEAD~ e ~SELECT~ sulla tabella corretta.

*Nel momento in cui ~"_RETURN"~ viene definita la tabella viene catalogata come vista!**

*** Esempio di rule: "_RETURN"
#+begin_src sql
-- CREATE TABLE maggiorenni() INHERITS( persona );
> CREATE TABLE maggiorenni( LIKE persona );
> CREATE OR REPLACE RULE "_RETURN"
  AS ON SELECT TO maggiorenni
  DO INSTEAD
    SELECT * FROM persona
    WHERE eta >= 18;
#+end_src

*** Esempio di rule: UPDATE
E' possibile /bloccare/ una tabella con una rule ~DO NOTHING~.
#+begin_src sql
> CREATE OR REPLACE RULE r_update_persona
  AS ON update
  TO persona
  DO INSTEAD NOTHING;
#+end_src
* Window Functions & CTE
** Window Functions
*** Cosa è una window function?
Le /Window Functions/ sono funzioni che *effettuano un calcolo su tuple correlate a quella corrente*,
qualcosa idealmente simile ad una funzione di aggregazione ma senza la necessità di aggregre
le tuple. Inoltre una window function può essere eseguita su una partizione delle tuple, non su
tutte le tuple di una query.
*** OVER & PARTITION
Una window function è solitamente seguita da una clausola ~OVER~ che identifica
su quale sottoinsieme di dati effettuare il calcolo. All'interno della clausola
~OVER~ si può specificare:
- ~PARTITION BY~ per indicare quali colonne usare per correlare le tuple (concettualmente
  simile a /group by/);
- ~ORDER BY~ per specificare l'ordinamento per processare le tuple nella funzione di
  correlazione.
*** Esempio di base per le Window Functions
#+begin_src sql
>CREATE TABLE software( pk SERIAL PRIMARY KEY,
   name text,
   version numeric,
   UNIQUE( name, version ),
   CHECK( version > 0 ) );

-- inserimento di un po' di valori...
#+end_src
*** Esempio di Window Function: rank
La funzione ~rank()~ fornisce una classifica dei dati.
*Se non si specifica un ~PARTITION BY~ la funzione non sa come correlare la tupla corrente*, quindi
è come correlarla a sé stessa:
#+begin_src sql
> SELECT name, version,
         rank() OVER ()
  FROM software
  ORDER BY name, version;
 name | version | rank
------+---------+------
 Java |     1.4 |    1
 Java |     1.5 |    1
 Java |     1.6 |    1
 Java |     1.7 |    1
 Java |     1.8 |    1
 Perl |     5.1 |    1
 Perl |    5.20 |    1
 Perl |     5.4 |    1
#+end_src
*** Esempio di Window Function: rank (2)
#+begin_src sql
> SELECT name, version,
  rank() OVER ( PARTITION BY name ORDER BY version)
  FROM software
  ORDER BY name, version;
 name | version | rank
------+---------+------
 Java |     1.4 |    1
 Java |     1.5 |    2
 Java |     1.6 |    3
 Java |     1.7 |    4
 Java |     1.8 |    5
 Perl |     5.1 |    1
 Perl |    5.20 |    2
 Perl |     5.4 |    3
#+end_src
*** Alcune Window Functions comuni
- ~row_number()~ il numero di riga nella /window/ (partizione);
- ~cume_dist()~ numero di righe precedenti divise per il numero totali di righe della partizione;
- ~ntile()~ accetta un intero e cerca di dividere la /window/ in un numero di /bucket/ bilanciati, specificando
  ogni riga a quele bucket appartiene;
- ~lag()~ accetta una colonna, un offset e un valore di default. Calcola la colonna /offset/ righe prima o
  se non esistono, al valore specificato come default;
- ~lead()~ opposto di ~lag()~ (calcola sulle righe in avanti);
- ~first_value()~, ~last_value()~, ~nth_value()~ accettano una colonna e restituiscono il valore
  della tupla all'offset specificato rispettivamente come prima, ultima ed ennesima.
** Common Table Expressions
*** CTE
Una /Common Table Expression (CTE)/ è una forma speciale di statement SQL (~SELECT~, ~INSERT~, ~UPDATE~, ~DELETE~)
che viene /attaccato/ mediante una clausola ~WITH~.

Concettualmente è come definire una tabella temporanea che può essere usata in uno
statement piu' complesso.
*** CTE SELECT
#+begin_src sql
> WITH max_sw AS (
   SELECT max( version ) AS v, name
   FROM software GROUP BY name
  )
 SELECT name, v
  FROM max_sw
  ORDER BY name;
 name |  v
------+-----
 Java | 1.8
 Perl | 5.4
#+end_src
*** CTE UPDATE
#+begin_src sql
> WITH delete_obsolete AS (
    UPDATE software SET valid = false
    WHERE version IN (
        SELECT MIN( version )
        FROM software GROUP BY name )
   RETURNING * )
  SELECT * FROM delete_obsolete;
 pk | name | version | valid
----+------+---------+-------
  1 | Perl |     5.1 | f
  5 | Java |     1.4 | f
#+end_src
*** CTE UPDATE (con piu' CTE)
#+begin_src sql
> WITH min_version AS (
   SELECT name, min( version ) AS v
   FROM software GROUP BY name
  )
  , delete_obsolete AS (
    UPDATE software  SET valid = false
    WHERE version IN ( SELECT v FROM min_version )
    RETURNING *
  )
  SELECT * FROM delete_obsolete;
#+end_src
*** CTE ricorsive
Con la clausola ~RECURSIVE~ è possibile crea una query ricorsiva.

*La query ricorsiva può referenziare se stessa, ovvero usare i risultati costruiti fino a quel momento*
per costruirne di nuovi.

Le query ricorsive possono produrre dei loop infiniti!

Le CTE ricorsive sono composte di due parti:
- una query non ricorsiva (che verrà evaluata per prima);
- una query che referenzia la CTE stessa in ~UNION ALL~.

*** CTE ricorsive: generare una sequenza
#+begin_src sql
> WITH RECURSIVE foo AS (
  SELECT 1 AS f
 UNION ALL
  SELECT 1 + f FROM foo )

SELECT * FROM foo LIMIT 10;
#+end_src
* TODO Foreign Data Wrapper
* TODO Extensions
* Configurazione del Server
** postgresql.conf
Il file principale di configurazione è ~postgresql.conf~, contenuto solitamente
in ~$PGDATA~ (alcune distribuzioni lo inseriscono nell'albero ~/etc~).

Il file contiene dei parametri in formato ~chiave = valore~ con valori
booleani (~on~, ~off~), numerici, stringa.

Il carattere ~#~ identifica un commento.

** Vedere la configurazione a run-time
La vista speciale ~pg_settings~ consente di valutare ogni singolo parametro
con i relativi valori di default, minimo, massimo, descrizione, ecc.

#+begin_src sql
# SELECT name, setting, min_val, max_val, unit,
  sourcefile, sourceline,
  short_desc,
  pending_restart
  FROM pg_settings
  WHERE name like 'shared_buffer%';

-[ RECORD 1 ]---+-------------------------------------------------------------
name            | shared_buffers
setting         | 16384
min_val         | 16
max_val         | 1073741823
unit            | 8kB
sourcefile      | /mnt/data1/pgdata/postgresql.conf
sourceline      | 113
short_desc      | Sets the number of shared memory buffers used by the server.
pending_restart | f
#+end_src
** Vedere la configurazione a run-time: note su pg_settings
I dati sul file di configurazione (~sourcefile~, ~sourceline~) non sono visualizzati per utenti
non amministratori.
Il flag ~pending_restart~ indica se il valore è stato modificato nel file di configurazione
ma non ancora /riletto/ dal sistema (ossia occorre un riavvio).
Il valore ~unit~ indica l'unità di misura del valore corrente ~setting~, nell'esempio
di cui sopra il valore è impostato a:
         ~8 kB * 16384 = 131072 kB = 128 MB~
corrispondente al seguente valore nel file di configurazione:
#+begin_src sh
% sudo grep shared_buffers /mnt/data1/pgdata/postgresql.conf                                                             ~
shared_buffers = 128MB
#+end_src

** Ricarica la configurazione a run-time
Ci sono diversi modi per /forzare un refresh della configurazione/:
- restart del server (non molto pratico);
- *inviare un ~SIGHUP~ al ~postmaster~*;
#+begin_src sql
% sudo kill HUP 1126
#+end_src
- *eseguire, come superutente del database, la stored procedure ~pg_reload_conf~*;
#+begin_src sql
# SELECT pg_reload_conf();
 pg_reload_conf
----------------
 t
#+end_src
- *eseguire, come owner del processo, ~pg_ctl~* che è lo strumento ufficiale per controllare un cluter:
#+begin_src sh
% sudo -u postgres pg_ctl reload -D /mnt/data1/pgdata                                                                    ~
server signaled
#+end_src
- eseguire uno degli script a disposizione del sistema operativo, ad esempio
  ~pg_ctlcluster~ (debian-like):
#+begin_src sql
% sudo pg_ctlcluster 9.5 main reload
#+end_src
* Write Ahead Log
** Introduzione ai WAL
I *Write Ahead Log* sono un componente fondamentale per il funzionamento del database.

L'idea dietro ai ~WAL~ è questa:
- ogni volta che una transazione effettua un ~COMMIT~ i dati *NON* vengono scritti
  immediatamente su disco, per ottimizzare l'I/O.
- il ~COMMIT~ viene registrato nei *WAL* che contengono /le differenze/ (binarie)
  dei dati;
- il WAL viene *reso persistente su disco*.

Siccome il WAL viene usato in modo *sequenziale* l'impatto di I/O è basso e si garantisce
in questo modo di avere uno strato di persistenza.
** Utilizzo dei WAL: crash recovery
I WAL vengono usati principalmente in caso di crash: se il database riparte a seguito di
un crash, *il sistema ripercorre i segmenti di WAL e riapplica le modifiche ai dati*.

Durante questa fase di /recovery/ il database si trova in uno stato /inconsistente/, i WAL
garantiscono appunto l'allineamento dei dati a quanto si trova su memoria persistente
e quindi la /consistenza/ del database.
** Sicurezza dei WAL
I segmenti di WAL sono *fondamentali* per il funzionamento del database, e quindi occorrono alcuni
accorgimenti per assicurare un buon funzionamento dei WAL:
1. la dimensione dei log è fissa (16MB), così come il loro numero (con qualche piccola variazione);
   questo garantisce che lo spazio di archiviazione dei WAL non si riempirà mai!
2. ogni dato nel WAL viene memorizzato come /record/ in linked list al record precedente; questo
   permette di risalire all'ultimo record "buono" nella catena dei segmenti;
3. ogni record inserito nei segmenti ha un checksum CRC32 che ne garantisce l'integrità;
4. i /signals/ sono interrotti durante la scrittura dei WAL, così da garantire che il processo
   non sia interrotto per errore.
** Dove sono i WAL
PostgreSQL memorizza il *Write Ahead Log* nella directory ~pg_xlog~.
*Ogni /segmento/ è di 16 MB e ha un nome in esadecimale*.
#+begin_src sh
% sudo  ls -lh /mnt/data1/pgdata/pg_xlog                                                                                 ~
 16M Oct 27 10:21 000000010000000000000082
 16M Oct 18 10:32 000000010000000000000083
 16M Oct 18 10:32 000000010000000000000084
#+end_src
** Checkpoint
*Un checkpoint è un ponto di consolidamento fra WAL e dati fisici.*

Il sistema non può registrare modifiche indefinitamente nei WAL:
- i segmenti aumenterebbe all'infinito;
- il tempo di recovery (ripercorrere i WAL) aumenterebbe di conseguenza.

Per evitare tali problemi si definiscono degli *istanti periodici detti /checkpoint/*
ove PostgreSQL si preoccupa di consolidare i dati fisici su disco, scartando quindi i
WAL precedenti quel checkpoint.

**** Crash recovery                                            :B_definition:
Di fatto un crash recovery *ripercorre i segmenti di WAL dall'ultimo checkpoint conosciuto*!
**** End of block                                           :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:
** LSN
Come si fa a sapere quali pagine dati sono /sicure/ per essere scaricate su memoria
persistente?
La risposta è *LSN: Log Sequence Number*.

Ogni pagina dati contiene un numero LSN che indica quale segmento di log contiene le modifiche
a quella pagina.
*Una pagina dati non può quindi essere resa persistente se i log fino a quel ~lsn~ non sono stati a loro volta resi persistenti*.
** Regolare i checkpoint
I checkpoint sono configurabili attraverso due parametri:
- ~max_wal_size~ indica quanti segmenti (da 16MB l'uno) sono tollerati fra due checkpoint consecutivi;
- ~checkpoint_timeout~ indica quanti secondi sono tollerati fra due checkpoint consecutivi.

Un checkpoint viene forzato aumaticamente ogni volta che si raggiunge una quantità di /dati sporchi/
pari a ~max_wal_size * 16 MB~ o dopo che ~checkpoint_timeout~ secondi sono trascorsi.
*La prima condizione che si verifica fa scattare un checkpoint*!
** Checkpoint Throttling
Siccome al raggiungimento di un /checkpoint/ il database deve forzare un /flush/ di tutte le pagine dati "sporche",
il sottosistema di I/O viene messo a dura prova.

Per evitare dei colli di bottiglia è stato introdotto un parametro che consente di stabilire entro quanto tempo
il checkpoint deve essere completato: ~checkpoint_completion_target~. Il suo valore è compreso fra 0 e 1 e indica
la frazione di tempo (~checkpoint_timeout~) da usare per completare il checkpoint stesso.
** Comprendere ~checkpoint_completion_target~
L'idea di ~checkpoint_completion_target~ è di *rallentare* l'attività di I/O di scarto delle pagine dati sporche.
In sostanza le pagine dati devono essere tutte scritte entro
   ~checkpoint_completion_target * checkpoint_timeout~ secondi
che con la configurazione di default divente:
  ~0.5 * 5 min = 2.5 min~
e quindi il sistema ha circa 2.5 minuti per completare l'I/O.
** Non forzare la mano a ~checkpoint_completion_target~
Il parametro offre una indicazione di come verrà /sparso/ l'I/O nel tempo, non è una stima esatta.
Ne consegue che valori prossimi a 1 rallenteranno le scritture su disco causando I/O costante (bassa banda), di contro
valori prossimi a 0 forzano un picco di I/O rapido (alta banda). Il rischio è che valori prossimi ad 1 producano
un /inseguimento/ dei checkpoint continuo.
*Il valore corretto dipende dal carico di lavoro!*
** Checkpoint manuali
Un superutente può forzare un checkpoint immediato con il comando ~CHECKPOINT~.
Il comando è pensato per le fasi di archiviazione e recovery, difficilmente
è da usarsi nell'ultilizzo regolare del database.
** Quanti sono i WAL?
Stabilito che i segmenti di WAL sono /riciclati/ dopo un checkpoint, è possibile stimare
l'occupazione della directory ~pg_xlog~ che è pressoché costante nel tempo e vale:
#+begin_src sh
 ( 2 + checkpoint_completion_target ) * checkpoint_segments + 1.
#+end_src
ossia è dominata da ~checkpoint_segments~.
*Durante un uso intenso potrebbe capitare che il numero di segmenti aumenti oltre ~checkpoint_segments~*, ma
il sistema provvederà all'eliminazione del residuo una volta ripristinato l'ordine. e' quindi consigliato
mantenere una certa quota disco per consentire qualche segmento ulteriore a quanto calcolato sopra.
** Livelli di WAL
Il parametro ~wal_level~ specifica quale livello di WAL si vuole usare:
- ~minimal~ (default), è il livello usato per garantire il normale funzionamento del cluster;
- ~archive~ consente di archiviare i WAL su memoria o dispositivo alternativo, utile per
  tecniche di backup avanzate (es. PITR) o per replica /warm standby/;
- ~hot_standby~ consente di rendere le repliche funzionanti da subito (in sola lettura!);
- ~logical~ consente di avviare la /replica logica/.
-
* TODO Point in Time Recovery & Replicatino
** Point in Time Recovery (PITR)
*** Introduzione al PITR
L'idea è abbastanza semplice ma molto potente: *avendo i WAL segments + possibile ripristinare il sistema ad un istante temporale nel passato predefinito!*

In sostanza si simula un /crash/, forzando il sistema a ripercorrere i WAL; invece che
lasciare il sistema terminare di srotolare tutti i WAL lo si ferma ad un istante consistente
nel passato.

#+begin_quote
Utilità (esempi): recuperare il database subito prima una transazione che ha fatto /drop/ di tutto
un database; visualizzare i dati come erano prima di una lunga elaborazione, debug di applicazioni
che possono aver sporcato i dati, ecc.
#+end_quote

**** Istanti temporali 					       :B_definition:
     Se viene specificato un istante nel /futuro/ (ovvero che non è presente nei WAL,
     PostgreSQL effettuerà un normale avvio in recovery.
     *Non si può rompere PostgreSQL per un errore del DBA!*
**** End of block                                           :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:

*** Preparasi al PITR
Le fasi da seguire sono sostanzialmente due:
- eseguire il backup dei file di dati (non importa siano /corrotti/, i WAL aggiusteranno la situazione);
- eseguire il backup dei segmenti di WAL.

Esistono due metodologie di archiviazione per PITR:
- /manuale/: si effettua un backup dei file di dati con strumenti a livello di filesystem,
  ma il cluster deve essere informato dell'inizio e della fine del backup per allineare
  opportunamento i WAL;
- /integrato/: si usa lo strumento ~pg_basebackup~ che consente di ottenere i file di dati
  senza richiedere l'utilizzo di tool a livello di filesystem.
*** Premessa per il PITR: WAL Archiving
Non dipende il modo che si sceglie per effettuare l'archiviazione dell'istanza, la cosa che
realmente conta è che il *WAL Archiving sia abilitato!*

Il /Wal Archiving/ è la tecnica mediante la quale PostgreSQL non ricicla automaticamente i WAL ma li mantiene
/offline/ per elaborazioni future.

Ovviamente questo significa che si deve avere lo spazio di archiviazione (locale, remoto) per mantenere
la quantità di WAL (ossia di dati) da /ri-eseguire/.
*** Come impostare il WAL Archiving
Occorre specificare, nal file ~postgresql.conf~, il comando shell (o lo script, o il programma) da eseguire
ogni volta che un nuovo segmento di WAL viene pronto per l'archiviazione (ossia è stato scritto in ~pg_xlog~).

Il comando può essere un semplice ~cp~ o un complesso programma, tenendo conto che i marcaposto speciali sono
espansi come segue:
- ~%f~ è il nome relativo del file di log da archiviare;
- ~%p~ è il nome del file da archiviare relativo a ~$PGDATA~ (ossia ~pg_xlog/<file>~).

*I file di WAL sono di proprietà dell'utente che esegue il cluster.*
Si tenga presente che i WAL contengono effettivamente i dati contenuti nel database (e quindi è opportuno siano protetti).
*** WAL Archiving: impostazioni pratiche
Si deve definire dove archiviare i WAL (può essere uno spazio locale o remoto):
#+begin_src sh
# mkdir /mnt/data2/wal_archive
  && chown postgres:postgres /mnt/data2/wal_archive
  && chmod 700 /mnt/data2/wal_archive
#+end_src
Poi in ~postgresql.conf~ si abilita l'archiving:
#+begin_src sh
archive_mode = on
# archive_command = 'test ! -f /mnt/server/archivedir/%f && cp %p /mnt/server/archivedir/%f'
archive_command = '/usr/local/bin/my_wal_archiver.sh %f %p'
wal_level = replica
#+end_src
e infine si /riavvia/ il cluster (~wal_level~ richiede un restart).
*** WAL Archiving: semplice script di archiviazione
#+begin_src sh
% cat /usr/local/bin/my_wal_archiver.sh                                                                                  ~
#!/bin/sh

ARCHIVING_PATH=/mnt/data2/wal_archive
LOG=${ARCHIVING_PATH}/log.txt
NOW=$( date -R )

SRC_FILE=$2 # file with path
DST_FILE=${ARCHIVING_PATH}/$1

# non sovrascrivo il file se esiste gia!
if [ -f ${DST_FILE} ]
then
    echo "KO $NOW: $1 esiste gia'" >> $LOG
    exit 1
fi

cp ${SRC_FILE} ${DST_FILE} \
  && echo "OK $NOW: WAL segment $1 copiato" >> $LOG \
  && exit 0
#+end_src
*** Cosa succede a regime?
Man mano che i dati vengono immessi nel database (o un checkpoint viene raggiunto) lo spazio di archiviazione dei WAL
si inizia a popolare:
#+begin_src sh
% sudo -u postgres ls -lh /mnt/data2/wal_archive                                                                         ~
...
-rw-------  1 postgres  postgres    16M Oct 30 15:01 0000000100000001000000B8
-rw-------  1 postgres  postgres    16M Oct 30 15:02 0000000100000001000000B9
-rw-------  1 postgres  postgres    16M Oct 30 15:02 0000000100000001000000BA
-rw-------  1 postgres  postgres   1.4K Oct 30 15:02 log.txt
#+end_src

*** Forzare l'archiviazione
Il database archivia i WAL segment ogni volta che ha terminato di prepararne uno (es. al checkpoint).
Questo può rappresentare un problema poiché se ci sono pochi dati o il tempo fra due checkpoint è alto
si possono perdere dei segmenti di WAL e, conseguentemente, non riuscire a ripristinare tutti i dati (ossia la
granularità dell'ultimo periodo si riduce).

L'opzione ~archive_timeout~ permette di specificare un numero di secondi dopo il quale forzare un nuovo segmento
di WAL (e la conseguente archiviazione).
Ad esempio:
#+begin_src sh
archive_timeout = 20
#+end_src
e i log sono archiviati ogni 20 secondi (circa):
#+begin_src sh
% sudo -u postgres cat /mnt/data2/wal_archive/log.txt
OK Mon, 30 Oct 2017 15:06:35 +0100: WAL segment 0000000100000001000000BD copiato
OK Mon, 30 Oct 2017 15:06:55 +0100: WAL segment 0000000100000001000000BE copiato
OK Mon, 30 Oct 2017 15:07:16 +0100: WAL segment 0000000100000001000000BF copiato
#+end_src
*** Problema di esempio: nuke di una tabella
Si cancellano dei dati da una tabella:
#+begin_src sql
> BEGIN;
> INSERT INTO evento( description )
  SELECT 'Evento ' || generate_series( 1, 2000000 );
> SELECT txid_current(), current_timestamp;
-[ RECORD 1 ]+------------------------------
txid_current | 1577
now          | 2017-10-30 18:34:31.951625+01

> COMMIT;

> BEGIN;
> DROP TABLE evento;
> SELECT txid_current(), current_timestamp;
-[ RECORD 1 ]+------------------------------
txid_current | 1691
now          | 2017-10-30 18:36:30.701021+01

> COMMIT;
#+end_src
*** PITR Manuale
Una volta che *l'archiviazione dei WAL è attiva* occorre:
1. informare il cluster che il backup sta iniziando con ~pg_start_backup()~;
2. effettuare il backup dei file di dati (attenzione a non copiare la configurazione!);
3. informare il cluster che il backup è terminato con ~pg_stop_backup()~.

*Non importa il tempo che passa fra il punto 1 e 2, il comportamento del cluster non viene alterato!*
*** Fase 1: informare il cluster che il backup sta iniziando
Come superutente del cluster avviare il backup:
#+begin_src sql
# SELECT pg_start_backup( 'PITR_BACKUP_MANUAL', true, false );
-[ RECORD 1 ]---+-----------
pg_start_backup | 2/3C000028
#+end_src

I parametri di ~pg_start_backup~ sono:
- una etichetta testuale che identifica il backup (/label/);
- l'avvio immediato (~true~) di un checkpoint senza onorare il ~checkpoint_completion_target~ (e quindi
  usando tutto l'I/O disponibile), se si vuole far usare meglio il database lasciarlo a ~false~;
- l'eventuale indicazione di un backup esclusivo (ossia impedisce la concorrenza di backup).

*** Fase 2: effettuare il backup fisico di PGDATA
E' ora possibile usare lo strumento a livello di filesystem per effettuare la copia:
#+begin_src sh
% sudo -u postgres rsync -a /mnt/data1/pgdata/ /mnt/data3/pgdata/
% sudo -u postgres rm /mnt/data3/pgdata/postmaster.pid \
                      /mnt/data3/pgdata/postmaster.opts
#+end_src
*** Fase 3: informare il cluster che il backup è terminato
Nella stessa connessione come utente amministratore eseguire ~pg_stop_backup~:
#+begin_src sql
# SELECT pg_stop_backup( false );
NOTICE:  pg_stop_backup complete, all required WAL segments have been archived
-[ RECORD 1 ]--+----------------------------------------------------------------------------
pg_stop_backup | (2/3C000130,"START WAL LOCATION: 2/3C000028 (file 00000001000000020000003C)+
               | CHECKPOINT LOCATION: 2/3C000060                                            +
               | BACKUP METHOD: streamed                                                    +
               | BACKUP FROM: master                                                        +
               | START TIME: 2017-10-30 18:31:44 CET                                        +
               | LABEL: PITR_BACKUP_MANUAL                                                  +
               | ","")

#+end_src

Questo produrrà un nuovo WAL segment switch per garantire che anche l'ultimo segmento è stato
reso persistente e archiviato.
*** Fase 3: conseguenze
Nello spazio di archiviazione viene creato un file con suffisso ~.backup~ che contiene le informazioni
riportate da ~pg_stop_backup~ e che sono *vitali* per il backup stesso:
#+begin_src sh
% sudo cat /mnt/data2/wal_archive/00000001000000020000003C.00000028.backup                                               ~
START WAL LOCATION: 2/3C000028 (file 00000001000000020000003C)
STOP WAL LOCATION: 2/3C000130 (file 00000001000000020000003C)
CHECKPOINT LOCATION: 2/3C000060
BACKUP METHOD: streamed
BACKUP FROM: master
START TIME: 2017-10-30 18:31:44 CET
LABEL: PITR_BACKUP_MANUAL
STOP TIME: 2017-10-30 18:32:30 CET
#+end_src
Si noti che il nome file è concatenato dal nome del segmento WAL (~0x3C~), dal punto di inizio del backup
come riportato da ~pg_start_backup~ (~0x3C0000028~).
*** Problema di esempio: nuke di una tabella
Si cancellano dei dati da una tabella:
#+begin_src sql
> BEGIN;
> INSERT INTO evento( description )
  SELECT 'Evento ' || generate_series( 1, 2000000 );
> SELECT txid_current(), current_timestamp;
-[ RECORD 1 ]+------------------------------
txid_current | 1454
now          | 2017-10-30 18:10:25.879821+01

> COMMIT;

> BEGIN;
> DROP TABLE evento;
> SELECT txid_current(), current_timestamp;
-[ RECORD 1 ]+------------------------------
txid_current | 1569
now          | 2017-10-30 18:12:16.851949+01

> COMMIT;
#+end_src
*** Far ripartire un nuovo cluster
Occorre creare un file ~recovery.conf~:
- ~restore_command~ è l'opposto di ~archive_command~ e informa il cluster su come reperire i WAL segment dall'archivio;
- ~recovery_end_command~ viene eseguito una volta che tutti i WAL sono stati riprodotti (ripristino terminato);
- ~recovery_target_time~ o ~recovery_target_xid~ indicano l'istante temporale o il numero di transazione a cui fermare il recovery.

Nello specifico:

#+begin_src sh
restore_command = 'cp /mnt/data2/wal_archive/%f "%p"'
recovery_target_time = '2017-10-30 18:36:00'
#+end_src
*** Avviare il sistema in PITR
#+begin_src sh
% sudo -u postgres pg_ctl -D /mnt/data3/pgdata start                                                                     ~
server starting
LOG:  database system was interrupted; last known up at 2017-10-30 18:31:44 CET                                        ~
LOG:  starting point-in-time recovery to 2017-10-30 18:36:29+01
LOG:  database system was not properly shut down; automatic recovery in progress
LOG:  redo starts at 2/3C000028
LOG:  invalid record length at 2/3C000108: wanted 24, got 0
LOG:  consistent recovery state reached at 2/3C000108
LOG:  restored log file "00000001000000020000003C" from archive
LOG:  restored log file "00000001000000020000003D" from archive
LOG:  restored log file "00000001000000020000003E" from archive
...
LOG:  redo done at 2/57FFE0C8
LOG:  last completed transaction was at log time 2017-10-30 18:36:07.564217+01
#+end_src
*** PITR: risultato
#+begin_src sql
% psql -h localhost -U luca -p 5433 testdb
> SELECT count(*) FROM evento;
-[ RECORD 1 ]--
count | 2000000
#+end_src

Il file ~recovery.conf~ viene rinominato in ~recovery.done~ (per evitare altri avvi in /recovery mode/).
Il file ~backup_label~ viene rimosso.

*** Usare ~pg_basebackup~
E' un programma che realizza il backup in modo quasi automatico, ma richiede una riga di configurazione
nel file ~pg_hba.conf~ per consentire una connessione al database sorgente:
#+begin_src sh
host    replication     postgres  127.0.0.1/32   md5
#+end_src

E' inoltre indispensabile assicurarsi di avere almeno un /WAL Sender/ attivo in
~postgresql.conf~:
#+begin_src sh
max_wal_senders = 1
#+end_src

*** ~pg_basebackup~ in azione
#+begin_src sh
% sudo -u postgres pg_basebackup \
   -D /mnt/data3/pgdata \
   -l 'PITR BACKUP 2' -v \
   -h localhost -p 5432 -U postgres

pg_basebackup: initiating base backup, waiting for checkpoint to complete
pg_basebackup: checkpoint completed
NOTICE:  pg_stop_backup complete, all required WAL segments have been archived
pg_basebackup: base backup completed
#+end_src

*ATTENZIONE: verificare ~postgresql.conf~ e rimuovere ~postmaster.pid~ e ~postmaster.ops~!*

*** ~pg_basebackup~: backup_label
Il file ~backup_label~ contiene le informazioni necessarie per raccapezzarsi con il backup:
#+begin_src sh
% sudo cat /mnt/data3/pgdata/backup_label                                                                                ~
START WAL LOCATION: 2/C000060 (file 00000001000000020000000C)
CHECKPOINT LOCATION: 2/C000098
BACKUP METHOD: streamed
BACKUP FROM: master
START TIME: 2017-10-30 17:52:21 CET
LABEL: PITR BACKUP 2
#+end_src
*** Costruire il ~recovery.conf~
Sapendo l'istante temporale al quale è iniziato il problema si può stabilire che il recovery
si fermi esattamente prima (è meglio cercare di avvicinarsi al tempo del disastro per includere
i risultati):

#+begin_src sh
restore_command = 'cp /mnt/data2/wal_archive/%f "%p"'
recovery_target_time = '2017-10-30 18:12:00'
#+end_src

o se si vuole ragionare per transazioni (escludendo quella problematica):

#+begin_src sh
restore_command = 'cp /mnt/data2/wal_archive/%f "%p"'
recovery_target_xid = 1569
recovery_target_inclusive = false
#+end_src

*** Avviare il sistema in PITR
Dopo aver riposizionato il file ~recovery.conf~ e aver fatto gli aggiustamenti necessari a ~postgresql.conf~
si può avviare l'istanza:
#+begin_src sh
% sudo -u postgres pg_ctl -D /mnt/data3/pgdata start                                                                     ~
server starting
LOG:  database system was interrupted; last known up at 2017-10-30 17:52:21 CET                                        ~
LOG:  starting point-in-time recovery to 2017-10-30 18:12:00+01
LOG:  restored log file "00000001000000020000000C" from archive
LOG:  redo starts at 2/C000060
LOG:  consistent recovery state reached at 2/C000130
LOG:  restored log file "00000001000000020000000D" from archive
...
cp: /mnt/data2/wal_archive/00000001000000020000003A: No such file or directory
LOG:  redo done at 2/39FFCF10
LOG:  last completed transaction was at log time 2017-10-30 18:11:54.465268+01
LOG:  restored log file "000000010000000200000039" from archive
cp: /mnt/data2/wal_archive/00000002.history: No such file or directory
LOG:  selected new timeline ID: 2
cp: /mnt/data2/wal_archive/00000001.history: No such file or directory
LOG:  archive recovery complete
LOG:  MultiXact member wraparound protections are now enabled
LOG:  database system is ready to accept connections
LOG:  autovacuum launcher started
#+end_src
*** PITR: risultato
#+begin_src sql
% psql -h localhost -U luca -p 5433 testdb
> SELECT count(*) FROM evento;
-[ RECORD 1 ]--
count | 2000000
#+end_src

Il file ~recovery.conf~ viene rinominato in ~recovery.done~ (per evitare altri avvi in /recovery mode/).
Il file ~backup_label~ viene rimosso.
** Timelines e considerazioni
*** Lo stato di archiviazione
Man mano che una istanza ripercorre i WAL inserisce nella directory ~pg_xlog/archive_status~
dei file ~.done~ che rappresentano il segmento di WAL ripristinato, nonché da che backup si è partiti:

#+begin_src sh
# ls /mnt/data3/pgdata/pg_xlog/archive_status/
00000001000000020000000C.00000060.backup.done   000000010000000200000045.done
00000001000000020000003C.done                   000000010000000200000046.done
00000001000000020000003D.done                   000000010000000200000047.done
00000001000000020000003E.done                   000000010000000200000048.done
00000001000000020000003F.done                   000000010000000200000049.done
000000010000000200000040.done                   00000001000000020000004A.done
000000010000000200000041.done                   00000001000000020000004B.done
000000010000000200000042.done                   00000001000000020000004C.done
000000010000000200000043.done                   00000001000000020000004D.done
000000010000000200000044.done                   00000001000000020000004E.done
#+end_src

*** Timelines
Quando una istanza finisce di ripercorrere dei segmenti di WAL e diventa nuovamente usabile, essa crea
una nuova /timeline/:

#+begin_src sh
LOG:  selected new timeline ID: 2
#+end_src

L'idea è che da lì in avanti il database deve essere capace di distinguere fra i segmenti di WAL generati
dal cluster (riavviato) e quelli provenienti dal cluster originale.
Per fare questo la /timeline/ fa parte del nome del file di ogni WAL:

#+begin_src sh
ls /mnt/data3/pgdata/pg_xlog/
...
000000020000000200000057
000000020000000200000058
000000020000000200000059
#+end_src

I file con prefisso ~00000002~ appartengono alla seconda timeline, che è un /branch/ della timeline ~00000001~
del primo cluster.

*** Timeline history file
Le timeline sono mantenute nella directory ~pg_xlog~ e sono in formato testo, con suffisso ~.history~. Tali
file contengono le informazioni sulla timeline di partenza e il momento (ossia il segmento di WAL) che ha generato
il branch.
Ad esempio per un recovery:

#+begin_src sh
LOG:  redo done at 2/57FFE0C8
LOG:  last completed transaction was at log time 2017-10-30 18:36:07.564217+01
#+end_src

si ha una timeline history

#+begin_src sh
# cat /mnt/data3/pgdata/pg_xlog/00000002.history
1       2/57FFFDD0      before 2000-01-01 01:00:00+01
#+end_src

*** PITR & Timeline
Il ~recovery.conf~ lavora implicitamente sulla stessa timeline del server di origine.
E' tuttavia possibile specificare una timeline differente.

** Replication
*** Concetti e terminologia
La /replication/ è la capacità di /sincronizzare/ un cluster *master* con uno o piu' *slave*
che replicano i dati (ossia ripetono le transazioni).
*Il nodo master è l'unico che accetta le query DML (ossia l'unico abilitato alle scritture)*.
Gli slave, detti anche /stand-by/, possono funzionare in replica isolata (warm standby) o in replica funzionante (*hot standby*): in questo caso
essi accettano solo query di lettura (e quindi possono essere usati per il bilanciamento del carico).
*** Tipologia di replica
Esistono fondamentalmente tre tipi di /replication/:
1. *log shipping*: il master archivia i WAL segment che lo slave ripercorre indefinitamente;
2. *streaming*: il master invia, su richiesta, i WAL segment allo slave che li richiede. Questo tipo di replica si suddivide ulteriormente in:
   - *sincrona* il master attende che anche lo slave abbia eseguito la transazione (molto sicuro, ma molto "costoso");
   - *asincrona* il master si "fida" che lo slave porterà a termine la transazione.
3. *logica*: non supportata nel core (occorre la versione ~10.0~), consente di replicare gli statement SQL.

**** Cascading Replication                                     :B_definition:
Ogni slave può a sua volta diventare un punto di "avvio" di replicazione per un
successivo slave.
**** End of block                                           :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:
*** Setup della replicazione
La configurazione per la replicazione è simile in tutti gli scenari, ma occorre che vi sia una copia
fisica del cluster master per inizializzare lo slave.

La copia può essere effettuata con il metodo manuale (~pg_start_backup~, copia del filesystem, ~pg_stop_backup~) o con
l'utility ~pg_basebackup~.
** Log Shipping Replication
*** Fase 1: configurazione del master
Occore che il master consenta l'archiviazione dei WAL segment e supporti la connessione per replica (solo se si usa ~pg_basebackup~).
In ~postgresql.conf~:
#+begin_src sh
wal_level       = replica
archive_mode    = on
archive_command = '/usr/local/bin/my_wal_archiver.sh %f %p'
max_wal_senders = 1 # solo per usare pg_basebackup
#+end_src

e se si usa ~pg_basebackup~ in ~pg_hba.conf~:
#+begin_src sh
host  replication  postgres    127.0.0.1/32  trust
#+end_src
*** Fase 2: creazione dello slave
#+begin_src sh
% sudo -u postgres pg_basebackup \                                                                                        ~
   -D /mnt/data3/pgdata \
   -l 'LOG_SHIPPING_REPLICA' -v \
   -h localhost -p 5432 -U postgres
#+end_src

Editare il file ~postgresql.conf~ dello slave affinché:
#+begin_src shell
wal_level       = minimal
archive_mode    = off
max_wal_senders = 0
hot_standby     = on # solo per fare query
port            = 5433 # solo per test locale!!
#+end_src
*** Fase 3: creare il ~recovery.conf~
Anche nel caso di replication occorre generare un file ~recovery.conf~ che
istruisca lo slave su come "riavviarsi":
#+begin_src shell
standby_mode = 'on'
restore_command = 'cp /mnt/data2/wal_archive/%f "%p"'
#+end_src

In sostanza non si specifica a quale istante temporale fermare il recovery e si abilita la funzione ~standby_mode~ che, appunto,
istruisce lo slave a /seguire/ le transazioni del master.
*** Fase 4: avvio dello slave
#+begin_src shell
 sudo -u postgres pg_ctl -D /mnt/data3/pgdata start                                                                      ~
server starting
LOG:  database system was interrupted; last known up at 2017-10-31 08:50:52 CET                                         ~
LOG:  entering standby mode
LOG:  restored log file "00000001000000020000005A" from archive
LOG:  redo starts at 2/5A000060
LOG:  consistent recovery state reached at 2/5A000130
LOG:  database system is ready to accept read only connections
...
#+end_src

Come si nota il database accetta solo query in lettura ed è pronto.
*** Interazione con lo slave
Come già detto, lo slave è in sola lettura:
#+begin_src sql
> INSERT INTO persona( nome, cognome, codice_fiscale )
  VALUES( 'Luca', 'Stantunione', 'SNTLCU02A20F257T' );
ERROR:  cannot execute INSERT in a read-only transaction
#+end_src
*** Perdita di dati sullo slave ?
Sul master:
#+begin_src sql
> CREATE TABLE evento( pk SERIAL PRIMARY KEY, description TEXT);
> INSERT INTO evento( description )
  SELECT 'replication ' || generate_series(1, 2000 );
#+end_src

ma sullo slave non è ancora visibile:

#+begin_src sql
> select * from evento;
ERROR:  relation "evento" does not exist
#+end_src
*** Perdita di dati sullo slave, perché?
*Non è una perdita di dati*: lo slave non ha ancora ricevuto il file WAL da ripercorrere.
#+begin_src shell
cp: /mnt/data2/wal_archive/00000001000000020000005B: No such file or directory
cp: /mnt/data2/wal_archive/00000001000000020000005B: No such file or directory
cp: /mnt/data2/wal_archive/00000001000000020000005B: No such file or directory
cp: /mnt/data2/wal_archive/00000001000000020000005B: No such file or directory
LOG:  restored log file "00000001000000020000005B" from archive
LOG:  restored log file "00000001000000020000005C" from archive
LOG:  restored log file "00000001000000020000005D" from archive
LOG:  restored log file "00000001000000020000005E" from archive
#+end_src

ma quando finalmente il master produce i nuovi WAL allora ecco che lo slave si "allinea":

#+begin_src sql
> select count(*) from evento;
 count
-------
  2000
#+end_src

*** Perdita di dati sullo slave, che fare?
*Non è una perdita di dati*: lo slave rimane indietro dei segmenti di WAL non ancora archiviati.
Occorre allora agire sul master impostando il parametro:

#+begin_src shell
archive_timeout = 10
#+end_src

che forza una archiviazione ogni 10 secondi (ad esempio).

*** Perdita di spazio, che fare?
L'archiviazione dei WAL non può avvenire all'infinito. Il ~recovery.conf~ consente di specificare un comando
da effettuare una volta che il segmento è stato ripercoso (a patto che non serva per altri scopi!). Il comando
~pg_archivecleanup~ effettua la cancellazione dei file recuperati. Nel file ~recovery.conf~ il placeholder ~%r~
indica un segmento recuperato, quindi:

#+begin_src shell
standby_mode = 'on'
restore_command = 'cp /mnt/data2/wal_archive/%f "%p"'
archive_cleanup_command = 'pg_archivecleanup /mnt/data2/wal_archive %r'
#+end_src
** Streaming Replication (asynchronous)
*** Fase 1: configurazione del master
Occorre che il master consenta un numero di processi di invio dei WAL (/WAL Senders/) pari o superiore al numero di slave che si connetteranno.
Inoltre il master deve sapere che i WAL saranno sottoposti a replication, quindi in ~postgresql.conf~:
#+begin_src sh
wal_level       = replica
max_wal_senders = 1 # quanti slave?
#+end_src

Siccome lo slave si collegherà al master, deve essere possibile l'autenticazione, quindi in ~pg_hba.conf~:
#+begin_src sh
host  replication  postgres    127.0.0.1/32  md5
#+end_src
*** Fase 2: creazione dello slave
#+begin_src sh
% sudo -u postgres pg_basebackup \                                                                                        ~
   -D /mnt/data3/pgdata \
   -l 'LOG_SHIPPING_REPLICA' -v \
   -h localhost -p 5432 -U postgres
#+end_src

Editare il file ~postgresql.conf~ dello slave affinché:
#+begin_src shell
wal_level       = minimal
archive_mode    = off
max_wal_senders = 0
hot_standby     = on # solo per fare query
port            = 5433 # solo per test locale!!
#+end_src
*** Fase 3: creare il ~recovery.conf~
Anche nel caso di replication occorre generare un file ~recovery.conf~ che
istruisca lo slave su come "riavviarsi":
#+begin_src shell
standby_mode = 'on'
primary_conninfo = 'host=localhost port=5432 user=postgres password=xxxxx'
#+end_src

In sostanza si specifica a quale server remoto collegarsi per ottenere il *flusso di WAL*.
*** Fase 4: avvio dello slave
#+begin_src shell
% sudo -u postgres pg_ctl -D /mnt/data3/pgdata start                                                                     ~
server starting
LOG:  database system was interrupted; last known up at 2017-10-31 12:44:30 CET                                        ~
LOG:  entering standby mode
LOG:  started streaming WAL from primary at 3/2F000000 on timeline 1
LOG:  redo starts at 3/2F000028
LOG:  consistent recovery state reached at 3/2F0000F8
LOG:  database system is ready to accept read only connections
...
#+end_src

Come si nota il database accetta solo query in lettura ed è pronto.
*** Monitoring
La vista ~pg_stat_replication~ fornisce informazioni utili sullo stato di ogni slave (occorre essere sul nodo master e interrogarla
come superutente):
#+begin_src sql
# SELECT * FROM pg_stat_replication;
-[ RECORD 1 ]----+-----------------------------
pid              | 2112
usesysid         | 10
usename          | postgres
application_name | walreceiver
client_addr      | 127.0.0.1
client_hostname  |
client_port      | 34332
backend_start    | 2017-10-31 13:41:00.38603+01
backend_xmin     |
state            | streaming
sent_location    | 3/D8000060
write_location   | 3/D8000060
flush_location   | 3/D8000060
replay_location  | 3/D8000000
sync_priority    | 0
sync_state       | async
#+end_src
*** Replication Slot
Cosa succede se lo slave si disconnette e il master inizia a riciclare i WAL? Lo slave sarà impossibilitato a recuperare
il suo stato!

Possibili soluzioni:
- archiviazione dei WAL (ma potrebbe richiedere molto spazio);
- replication slot.

I replication slot informano il master di tenere i WAL segment qualora non siano stati inviati agli slave relativi.

*Un replication slot è uno stream ordinato e univoco di modifiche!*
*** Replication Slot: configurazione dello slave
Si deve impostare il nome dello slot nel ~recovery.conf~:
#+begin_src shell
standby_mode = 'on'
primary_conninfo = 'host=localhost port=5432 user=postgres password=xxxxx'
primary_slot_name = 'slave_a_slot'
#+end_src

*** Replication Slot: configurazione del master
Nel file ~postgresql.conf~ si deve specificare quanti slot si vogliono mantenere:
#+begin_src shell
max_replication_slots = 1
#+end_src

e si possono quindi creare gli slot con il nome identico a quello fornito agli slave:
#+begin_src sql
# SELECT *
  FROM pg_create_physical_replication_slot( 'slave_a_slot' );
-[ RECORD 1 ]-+-------------
slot_name     | slave_a_slot
xlog_position |
#+end_src
*** Replication Slot: monitoring
Una volta avviato lo slave è possibile verificare (dal master) in che stato sono i replication slot:
#+begin_src sql
# SELECT * FROM pg_replication_slots;
-[ RECORD 1 ]-------+-------------
slot_name           | slave_a_slot
plugin              |
slot_type           | physical
datoid              |
database            |
active              | t
active_pid          | 2112
xmin                |
catalog_xmin        |
restart_lsn         | 3/D7000000
confirmed_flush_lsn |
#+end_src

** Streaming Replication (Synchronous)
*** Application Name
La replica sincrona passa per il concetto di /application name/.
L'idea è semplice: ogni connessione viene associata ad un /nome applicazione/. Qualora la connessione
(di replica dallo slave) abbia un nome di connessione riconosciuto fra quelli che devono comportarsi come replica
sincrona, il sistema viene istruito di comportarsi come replica sincrona.

*La replica sincrona è costosa: si deve aspettare che ogni slave abbia effettuato la transazione!*

/Nel caso di replica asincrona l'application name di default è ~walreceiver~!/

*** Fase 1: configurazione del master
Il master deve consentire un opportuno numero di slave (e quindi di /WAL Senders/), nonché sapere quali slave si
collegheranno in modo sincrono (ossia la /application name/ deve essere nota fra tutti i sistemi!).
Nel file ~postgresql.conf~:

#+begin_src shell
synchronous_standby_names = 'slave_a, slave_b'
wal_level       = replica
max_wal_senders = 2 # quanti slave?
#+end_src

Come per la replica asincrona, occorre che sia concessa la possibilità di connessione agli slave, quindi in ~pg_hba.conf~:
#+begin_src shell
host  replication  postgres    127.0.0.1/32  md5
#+end_src
e righe relative ai vari slave.
*** Fase 2: creazione dello slave
#+begin_src sh
% sudo -u postgres pg_basebackup \                                                                                        ~
   -D /mnt/data3/pgdata \
   -l 'LOG_SHIPPING_REPLICA' -v \
   -h localhost -p 5432 -U postgres
#+end_src

Editare il file ~postgresql.conf~ dello slave affinché:
#+begin_src shell
wal_level       = minimal
archive_mode    = off
max_wal_senders = 0
hot_standby     = on # solo per fare query
port            = 5433 # solo per test locale!!
#+end_src
*** Fase 3: creare il ~recovery.conf~
L'application name deve essere inserito nella stringa di connessione affinché lo slave si identifichi per la replica sincrona:
#+begin_src shell
standby_mode = 'on'
primary_conninfo = 'host=localhost port=5432 user=postgres password=xxxx application_name=slave_a'
#+end_src
*** Fase 4: avviare lo slave
#+begin_src shell
% sudo -u postgres pg_ctl -D /mnt/data3/pgdata start                                                                     ~
server starting
LOG:  database system was shut down in recovery at 2017-10-31 13:17:10 CET                                             ~
LOG:  entering standby mode
LOG:  redo starts at 3/92000060
LOG:  consistent recovery state reached at 3/9A000000
LOG:  database system is ready to accept read only connections
LOG:  unexpected pageaddr 3/6B000000 in log segment 00000001000000030000009A, offset 0
LOG:  started streaming WAL from primary at 3/9A000000 on timeline 1
#+end_src
*** Monitoring in replica
Su uno slave è possibile vedere l'ultimo segment WAL ricevuto con ~pg_last_xlog_received()~:
#+begin_src sql
> SELECT pg_last_xlog_receive_location();
-[ RECORD 1 ]-----------------+-----------
pg_last_xlog_receive_location | 3/A3000000
#+end_src

mentre sul master ~pg_current_xlog_location()~ indica dove si è:
#+begin_src sql
> SELECT PG_CURRENT_XLOG_LOCATION();
-[ RECORD 1 ]------------+-----------
pg_current_xlog_location | 3/A8000060
#+end_src

*** Monitoring in replica (2)
Sul nodo master, come superutenti, è possibile avere un'idea dei singoli slave collegati:
#+begin_src sql
# SELECT * FROM pg_stat_replication;
-[ RECORD 1 ]----+------------------------------
pid              | 1648
usesysid         | 10
usename          | postgres
application_name | slave_a
client_addr      | 127.0.0.1
client_hostname  |
client_port      | 63390
backend_start    | 2017-10-31 13:23:49.874223+01
backend_xmin     |
state            | streaming
sent_location    | 3/AC000000
write_location   | 3/AC000000
flush_location   | 3/AC000000
replay_location  | 3/AC000000
sync_priority    | 1
sync_state       | sync
#+end_src
** Da slave a master
*** Promote
Uno slave può diventare un master qualora sia necessario.

Diventare master (*promote*) significa che lo slave inizierà a percorrere la sua stessa timeline e si sgancerà dal vecchio master (ossia
sarà completato il recovery).

Ci sono due modi per promuovere uno slave:
- fare una /promote/ esplicita;
- usare un trigger file.

*** Promote esplicita
Usando ~pg_ctl~ si può effettuare il promote di un database:
#+begin_src shell
% sudo -u postgres pg_ctl -D /mnt/data3/pgdata promote                                                                   ~
server promoting
LOG:  received promote request
FATAL:  terminating walreceiver process due to administrator command
LOG:  invalid record length at 3/F7000140: wanted 24, got 0
LOG:  redo done at 3/F7000108
LOG:  selected new timeline ID: 2                                                                                      ~
LOG:  archive recovery complete
LOG:  MultiXact member wraparound protections are now enabled
LOG:  database system is ready to accept connections
LOG:  autovacuum launcher started
#+end_src

*** Promote via trigger file
Si deve specificare un'opzione nel file ~recovery.conf~:
#+begin_src shell
standby_mode = 'on'
primary_conninfo = 'host=localhost port=5432 user=postgres password=postgres'
trigger_file = '/tmp/promote_to_master'
#+end_src

Quando sarà presente il file ~/tmp/promote_to_master~ (non importa il contenuto!) lo slave si sgancerà dal master.

*** Promote via trigger file: esempio
#+begin_src shell
% echo `date` > /tmp/promote_to_master
#+end_src

e lo slave reagisce con

#+begin_src shell
LOG:  trigger file found: /tmp/promote_to_master                                                   ~
FATAL:  terminating walreceiver process due to administrator command
LOG:  invalid record length at 3/F9000060: wanted 24, got 0
LOG:  redo done at 3/F9000028
LOG:  selected new timeline ID: 2
LOG:  archive recovery complete
LOG:  MultiXact member wraparound protections are now enabled
LOG:  database system is ready to accept connections
LOG:  autovacuum launcher started
#+end_src

** Logical Decoding
*** Introduzione
PostgreSQL supporta la replicazione logica dalla versione 10, ma intanto l'infrastruttura
per la /decodifica/ dei WAL da binario a logico (ossia verso statement SQL) è possibile.

La decodifica logica avviene attraverso dei /plugin/.
Ogni plugin è responsabile di operare sui WAL e tradurli nel formato appropriato, ad esempio un formato SQL.

Per interagire con la decodifica logica occorre quindi avere un opportuno plugin per
poter gestire i WAL segment. Uno di questi plugin è ~test_decoding~, usato per
ottenere statement SQL.

L'interazione fra plugin e WAL segment avviene attraverso i /replication slot/.
*** Perché i replication slot?
In PostgreSQL un /replication slot/ è *uno stream univoco di modifiche ordinate* che un /consumer/ può ripercorrere a applicare (o decodificare).

Lo slot non è al corrente di cosa sta facendo il consumer, e neanche di quale consumer vi è attaccato. Ogni consumer è responsabile
di richiedere le modifiche allo slot a partire da un certo punto.

Gli slot usati per la decodifica logica sono leggermente differenti da quelli di streaming replication (detti anche /fisici/): le differenze
sono nel protocollo di scambio di dati, ma concettualmente entrambi rappresentano uno stream ordinato di modifiche.

*** Logical Decoding: passi fondamentali
Per ottenere le informazioni logiche occorre:
1. abilitare il liello ~logical~ per ~wal_level~;
2. usare degli /slot/ di replicazione (quindi occorre abilitare almeno uno slot di replicazione);
3. interfacciarsi con i cataloghi di sistemi o appositi programmi del cluster.

*ATTENZIONE: i comandi DDL non sono decodificati (ma ovviamente /esistono/)!*
*** Configurazione del server
Nel file ~postgresql.conf~:
#+begin_src shell
wal_level = logical
max_replication_slots = 1 # almeno uno!
#+end_src

*** Creazione di uno slot
E' possibile usare il plugin ~test_decoding~:
#+begin_src sql
# SELECT *
  FROM pg_create_logical_replication_slot( 'logical_decoding_slot',
                                           'test_decoding');
-[ RECORD 1 ]-+----------------------
slot_name     | logical_decoding_slot
xlog_position | 3/FB0004F8
#+end_src

/E' possibile creare lo slot anche tramite ~pg_recvlogical~!/

*** Interazione con lo slot e con la decodifica: SQL
#+begin_src sql
# INSERT INTO persona( nome, cognome, codice_fiscale )
  VALUES( 'Mario', 'Rossi', 'RSSMRA71M68F357T' );
#+end_src

e interrogando la vista ~pg_logical_slot_get_changes~ si ottiene:
#+begin_src sql
# SELECT * FROM pg_logical_slot_get_changes('logical_decoding_slot', NULL, NULL);
-[ RECORD 1 ]--------
location | 3/FB000530
xid      | 1950
data     | BEGIN 1950
-[ RECORD 2 ]--------
location | 3/FB000600
xid      | 1950
data     | table public.persona:
           INSERT: pk[integer]:16
           nome[character varying]:'Mario'
           cognome[character varying]:'Rossi'
           codice_fiscale[character varying]:'RSSMRA71M68F357T'
           eta[integer]:null
           valid[boolean]:true
-[ RECORD 3 ]--------
location | 3/FB000B18
xid      | 1950
data     | COMMIT 1950
#+end_src

*** Interazione con lo slot e la decodifica: ~pg_recvlogical~
Da un terminale:
#+begin_src shell
% pg_recvlogical -h localhost \                                                                                          ~
  -d testdb \
  -U postgres \
  --slot=logical_decoding_slot \
  --start -f -
Password:

BEGIN 1951
table public.persona: INSERT:
   pk[integer]:17
   nome[character varying]:'Giovanni'
   cognome[character varying]:'Verdi'
   codice_fiscale[character varying]:'VRDGVN71M18F357K'
   eta[integer]:null
   valid[boolean]:true
COMMIT 1951
#+end_src

che corrisponde allo stament SQL
#+begin_src sql
# INSERT INTO persona( nome, cognome, codice_fiscale )
  VALUES( 'Giovanni', 'Verdi', 'VRDGVN71M18F357K' );
#+end_src
